{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 1: SETUP SEDERHANA - HARDCODED SEMUA\n",
        "# =====================================================================\n",
        "\n",
        "# Mount drive dan import libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DIN IMPLEMENTATION - HARDCODED SIMPLE VERSION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Set seeds\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "# Paths\n",
        "ROOT_PATH = '/content/drive/MyDrive/TA/DIEN/DIEN-tf2/new/dataset'\n",
        "CHECKPOINT_ROOT = '/content/drive/MyDrive/TA/TAOBAO/checkpoints'\n",
        "SAVE_PATH = '/content/drive/MyDrive/TA/TAOBAO/models'\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(CHECKPOINT_ROOT, exist_ok=True)\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# File paths\n",
        "RAW_SAMPLE_PATH = os.path.join(ROOT_PATH, 'raw_sample.csv')\n",
        "AD_FEATURE_PATH = os.path.join(ROOT_PATH, 'ad_feature.csv')\n",
        "USER_PROFILE_PATH = os.path.join(ROOT_PATH, 'user_profile.csv')\n",
        "USER_BEHAVIOR_PATH = os.path.join(ROOT_PATH, 'UserBehavior.csv')\n",
        "\n",
        "# HARDCODED SAMPLING - hanya 2 parameter\n",
        "RAW_SAMPLE_SIZE = 26557961\n",
        "USER_BEHAVIOR_SAMPLE_SIZE = 50000000\n",
        "\n",
        "print(f\"Setup completed\")\n",
        "print(f\"Raw sample size: {RAW_SAMPLE_SIZE:,}\")\n",
        "print(f\"User behavior size: {USER_BEHAVIOR_SAMPLE_SIZE:,}\")\n",
        "print(f\"Models: DIN-DICE, DIN-PReLU, DeepFM, Baseline\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ STEP 1 COMPLETED!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2YDHJg4t8xh",
        "outputId": "fc330c3e-c540-4e14-8eb6-89d61ea98167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "================================================================================\n",
            "DIN IMPLEMENTATION - HARDCODED SIMPLE VERSION\n",
            "================================================================================\n",
            "TensorFlow version: 2.18.0\n",
            "Setup completed\n",
            "Raw sample size: 26,557,961\n",
            "User behavior size: 50,000,000\n",
            "Models: DIN-DICE, DIN-PReLU, DeepFM, Baseline\n",
            "\n",
            "ðŸŽ¯ STEP 1 COMPLETED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "nama_folder = \"tuning_results\"\n",
        "din_dice = 'din_dice'\n",
        "din_prelu = 'din_prelu'\n",
        "deepfm = 'deepfm'\n",
        "baseline = 'baseline'\n",
        "\n",
        "os.makedirs(nama_folder)\n",
        "os.makedirs(os.path.join(nama_folder, din_dice))\n",
        "os.makedirs(os.path.join(nama_folder, din_prelu))\n",
        "os.makedirs(os.path.join(nama_folder, deepfm))\n",
        "os.makedirs(os.path.join(nama_folder, baseline))"
      ],
      "metadata": {
        "id": "kMsa90d3ID2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 2: DATA LOADING DENGAN HEAD INSPECTION\n",
        "# =====================================================================\n",
        "\n",
        "def load_data_simple():\n",
        "    \"\"\"Load data dengan head inspection untuk setiap dataset\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DATA LOADING DENGAN HEAD INSPECTION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        # 1. RAW SAMPLE\n",
        "        print(f\"\\nðŸ“Š 1. LOADING RAW SAMPLE...\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Load dan inspect head\n",
        "        raw_sample = pd.read_csv(RAW_SAMPLE_PATH)\n",
        "        print(f\"ðŸ“‹ Raw Sample Shape: {raw_sample.shape}\")\n",
        "        print(f\"ðŸ“‹ Raw Sample Columns: {list(raw_sample.columns)}\")\n",
        "        print(f\"\\nðŸ” Raw Sample Head (5 rows):\")\n",
        "        print(raw_sample.head())\n",
        "\n",
        "        print(f\"\\nRaw Sample Info:\")\n",
        "        print(f\"    Data types: {raw_sample.dtypes.value_counts().to_dict()}\")\n",
        "        print(f\"    Missing values: {raw_sample.isnull().sum().sum()}\")\n",
        "        if 'clk' in raw_sample.columns:\n",
        "            print(f\"    CTR: {raw_sample['clk'].mean():.4f}\")\n",
        "\n",
        "        # Drop data leakage\n",
        "        if 'nonclk' in raw_sample.columns:\n",
        "            raw_sample = raw_sample.drop('nonclk', axis=1)\n",
        "            print(f\"    Removed nonclk feature\")\n",
        "\n",
        "        # Sampling stratified\n",
        "        if len(raw_sample) > RAW_SAMPLE_SIZE:\n",
        "            ctr = raw_sample['clk'].mean()\n",
        "            pos_data = raw_sample[raw_sample['clk'] == 1]\n",
        "            neg_data = raw_sample[raw_sample['clk'] == 0]\n",
        "\n",
        "            pos_samples = int(RAW_SAMPLE_SIZE * ctr)\n",
        "            neg_samples = RAW_SAMPLE_SIZE - pos_samples\n",
        "\n",
        "            sampled_pos = pos_data.sample(n=min(pos_samples, len(pos_data)), random_state=1234)\n",
        "            sampled_neg = neg_data.sample(n=min(neg_samples, len(neg_data)), random_state=1234)\n",
        "\n",
        "            raw_sample = pd.concat([sampled_pos, sampled_neg], ignore_index=True)\n",
        "            raw_sample = raw_sample.sample(frac=1, random_state=1234).reset_index(drop=True)\n",
        "\n",
        "            print(f\"    Sampled to {RAW_SAMPLE_SIZE:,} rows\")\n",
        "\n",
        "        print(f\"    Final Raw Sample: {raw_sample.shape}, CTR: {raw_sample['clk'].mean():.4f}\")\n",
        "\n",
        "        # 2. AD FEATURES\n",
        "        print(f\"\\nðŸ·ï¸ 2. LOADING AD FEATURES...\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        ad_features = pd.read_csv(AD_FEATURE_PATH)\n",
        "        print(f\"Ad Features Shape: {ad_features.shape}\")\n",
        "        print(f\"Ad Features Columns: {list(ad_features.columns)}\")\n",
        "        print(f\"\\nðŸ” Ad Features Head (5 rows):\")\n",
        "        print(ad_features.head())\n",
        "\n",
        "        print(f\"\\nAd Features Info:\")\n",
        "        print(f\"    Data types: {ad_features.dtypes.value_counts().to_dict()}\")\n",
        "        print(f\"    Missing values: {ad_features.isnull().sum().sum()}\")\n",
        "        print(f\"    Unique items: {ad_features['adgroup_id'].nunique():,}\")\n",
        "        if 'price' in ad_features.columns:\n",
        "            price_stats = ad_features['price'].describe()\n",
        "            print(f\"    Price range: [{price_stats['min']:.2f}, {price_stats['max']:.2f}]\")\n",
        "            print(f\"    Price missing: {ad_features['price'].isnull().sum():,}\")\n",
        "\n",
        "        # 3. USER PROFILES\n",
        "        print(f\"\\nðŸ‘¤ 3. LOADING USER PROFILES...\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        user_profiles = pd.read_csv(USER_PROFILE_PATH)\n",
        "        print(f\"User Profiles Shape: {user_profiles.shape}\")\n",
        "        print(f\"User Profiles Columns: {list(user_profiles.columns)}\")\n",
        "        print(f\"\\nUser Profiles Head (5 rows):\")\n",
        "        print(user_profiles.head())\n",
        "\n",
        "        print(f\"\\nUser Profiles Info:\")\n",
        "        print(f\"    Data types: {user_profiles.dtypes.value_counts().to_dict()}\")\n",
        "        print(f\"    Missing values: {user_profiles.isnull().sum().sum()}\")\n",
        "        print(f\"    Unique users: {user_profiles['userid'].nunique():,}\")\n",
        "\n",
        "        # Gender distribution if available\n",
        "        if 'final_gender_code' in user_profiles.columns:\n",
        "            gender_dist = user_profiles['final_gender_code'].value_counts().head()\n",
        "            print(f\"    Gender distribution: {gender_dist.to_dict()}\")\n",
        "\n",
        "        # Age level distribution if available\n",
        "        if 'age_level' in user_profiles.columns:\n",
        "            age_dist = user_profiles['age_level'].value_counts().head()\n",
        "            print(f\"    Age level distribution: {age_dist.to_dict()}\")\n",
        "\n",
        "        # 4. USER BEHAVIOR\n",
        "        print(f\"\\n4. LOADING USER BEHAVIOR...\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Load first chunk to show head\n",
        "        first_chunk = pd.read_csv(USER_BEHAVIOR_PATH,\n",
        "                                header=None,\n",
        "                                names=['user_id', 'item_id', 'category_id', 'behavior_type', 'timestamp'],\n",
        "                                nrows=10)\n",
        "\n",
        "        print(f\"ðŸ“‹ User Behavior Columns: {list(first_chunk.columns)}\")\n",
        "        print(f\"\\nðŸ” User Behavior Head (5 rows):\")\n",
        "        print(first_chunk.head())\n",
        "\n",
        "        print(f\"\\nðŸ“Š User Behavior Preview Info:\")\n",
        "        print(f\"    Data types: {first_chunk.dtypes.to_dict()}\")\n",
        "        print(f\"    Behavior types: {first_chunk['behavior_type'].value_counts().to_dict()}\")\n",
        "\n",
        "        # Convert sample timestamps\n",
        "        sample_timestamps = first_chunk['timestamp'].head(3)\n",
        "        readable_times = [pd.to_datetime(ts, unit='s').strftime('%Y-%m-%d %H:%M:%S') for ts in sample_timestamps]\n",
        "        print(f\"    Sample timestamps: {readable_times}\")\n",
        "\n",
        "        # Load full behavior data in chunks\n",
        "        print(f\"\\nðŸ”„ Loading full user behavior data...\")\n",
        "        chunks = []\n",
        "        total_rows = 0\n",
        "\n",
        "        for i, chunk in enumerate(pd.read_csv(USER_BEHAVIOR_PATH,\n",
        "                                header=None,\n",
        "                                names=['user_id', 'item_id', 'category_id', 'behavior_type', 'timestamp'],\n",
        "                                chunksize=500000)):\n",
        "            chunks.append(chunk)\n",
        "            total_rows += len(chunk)\n",
        "            print(f\"    Chunk {i+1}: {len(chunk):,} rows (Total: {total_rows:,})\")\n",
        "\n",
        "            if total_rows >= USER_BEHAVIOR_SAMPLE_SIZE:\n",
        "                break\n",
        "\n",
        "        user_behavior = pd.concat(chunks, ignore_index=True)\n",
        "        if len(user_behavior) > USER_BEHAVIOR_SAMPLE_SIZE:\n",
        "            user_behavior = user_behavior.sample(n=USER_BEHAVIOR_SAMPLE_SIZE, random_state=1234).reset_index(drop=True)\n",
        "\n",
        "        print(f\"    Final User Behavior: {user_behavior.shape}\")\n",
        "        print(f\"    Final behavior types: {user_behavior['behavior_type'].value_counts().to_dict()}\")\n",
        "        print(f\"    Unique users: {user_behavior['user_id'].nunique():,}\")\n",
        "        print(f\"    Unique items: {user_behavior['item_id'].nunique():,}\")\n",
        "\n",
        "        # 5. DATASET OVERLAP ANALYSIS\n",
        "        print(f\"\\n5. DATASET OVERLAP ANALYSIS\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Convert IDs to string for consistent comparison\n",
        "        raw_users = set(raw_sample['user'].astype(str))\n",
        "        profile_users = set(user_profiles['userid'].astype(str))\n",
        "        behavior_users = set(user_behavior['user_id'].astype(str))\n",
        "\n",
        "        raw_items = set(raw_sample['adgroup_id'].astype(str))\n",
        "        ad_items = set(ad_features['adgroup_id'].astype(str))\n",
        "        behavior_items = set(user_behavior['item_id'].astype(str))\n",
        "\n",
        "        # User overlaps\n",
        "        raw_profile_overlap = len(raw_users & profile_users)\n",
        "        raw_behavior_overlap = len(raw_users & behavior_users)\n",
        "        all_user_overlap = len(raw_users & profile_users & behavior_users)\n",
        "\n",
        "        print(f\"USER OVERLAPS:\")\n",
        "        print(f\"    Raw sample users: {len(raw_users):,}\")\n",
        "        print(f\"    Profile users: {len(profile_users):,}\")\n",
        "        print(f\"    Behavior users: {len(behavior_users):,}\")\n",
        "        print(f\"    Raw âˆ© Profiles: {raw_profile_overlap:,} ({raw_profile_overlap/len(raw_users)*100:.1f}%)\")\n",
        "        print(f\"    Raw âˆ© Behavior: {raw_behavior_overlap:,} ({raw_behavior_overlap/len(raw_users)*100:.1f}%)\")\n",
        "        print(f\"    All 3 datasets: {all_user_overlap:,} ({all_user_overlap/len(raw_users)*100:.1f}%)\")\n",
        "\n",
        "        # Item overlaps\n",
        "        raw_ad_overlap = len(raw_items & ad_items)\n",
        "        raw_behavior_item_overlap = len(raw_items & behavior_items)\n",
        "\n",
        "        print(f\"\\nITEM OVERLAPS:\")\n",
        "        print(f\"    Raw sample items: {len(raw_items):,}\")\n",
        "        print(f\"    Ad feature items: {len(ad_items):,}\")\n",
        "        print(f\"    Behavior items: {len(behavior_items):,}\")\n",
        "        print(f\"    Raw âˆ© Ad features: {raw_ad_overlap:,} ({raw_ad_overlap/len(raw_items)*100:.1f}%)\")\n",
        "        print(f\"    Raw âˆ© Behavior: {raw_behavior_item_overlap:,} ({raw_behavior_item_overlap/len(raw_items)*100:.1f}%)\")\n",
        "\n",
        "        # 6. SUMMARY\n",
        "        print(f\"\\n6. DATA LOADING SUMMARY\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Raw Sample: {raw_sample.shape} | CTR: {raw_sample['clk'].mean():.4f}\")\n",
        "        print(f\"Ad Features: {ad_features.shape} | Items: {ad_features['adgroup_id'].nunique():,}\")\n",
        "        print(f\"User Profiles: {user_profiles.shape} | Users: {user_profiles['userid'].nunique():,}\")\n",
        "        print(f\"User Behavior: {user_behavior.shape} | Users: {user_behavior['user_id'].nunique():,}\")\n",
        "        print(f\"Data quality: Good overlaps for feature engineering\")\n",
        "\n",
        "        return raw_sample, ad_features, user_profiles, user_behavior\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, None, None\n",
        "\n",
        "# Execute loading with detailed inspection\n",
        "print(\"ðŸš€ Loading data with detailed inspection...\")\n",
        "raw_sample, ad_features, user_profiles, user_behavior = load_data_simple()\n",
        "\n",
        "if raw_sample is not None:\n",
        "    print(f\"\\nSTEP 2 COMPLETED!\")\n",
        "    print(f\"All data loaded with complete head inspection\")\n",
        "    print(f\"Dataset overlaps analyzed\")\n",
        "    print(f\"Data quality verified\")\n",
        "else:\n",
        "    print(f\"âŒ STEP 2 FAILED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjCqtk-QuAEJ",
        "outputId": "9a796c0d-43e4-4d08-8164-a9ff9a1f26ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Loading data with detailed inspection...\n",
            "\n",
            "============================================================\n",
            "DATA LOADING DENGAN HEAD INSPECTION\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š 1. LOADING RAW SAMPLE...\n",
            "----------------------------------------\n",
            "ðŸ“‹ Raw Sample Shape: (26557961, 6)\n",
            "ðŸ“‹ Raw Sample Columns: ['user', 'time_stamp', 'adgroup_id', 'pid', 'nonclk', 'clk']\n",
            "\n",
            "ðŸ” Raw Sample Head (5 rows):\n",
            "     user  time_stamp  adgroup_id          pid  nonclk  clk\n",
            "0  581738  1494137644           1  430548_1007       1    0\n",
            "1  449818  1494638778           3  430548_1007       1    0\n",
            "2  914836  1494650879           4  430548_1007       1    0\n",
            "3  914836  1494651029           5  430548_1007       1    0\n",
            "4  399907  1494302958           8  430548_1007       1    0\n",
            "\n",
            "Raw Sample Info:\n",
            "    Data types: {dtype('int64'): 5, dtype('O'): 1}\n",
            "    Missing values: 0\n",
            "    CTR: 0.0514\n",
            "    Removed nonclk feature\n",
            "    Final Raw Sample: (26557961, 5), CTR: 0.0514\n",
            "\n",
            "ðŸ·ï¸ 2. LOADING AD FEATURES...\n",
            "----------------------------------------\n",
            "Ad Features Shape: (846811, 6)\n",
            "Ad Features Columns: ['adgroup_id', 'cate_id', 'campaign_id', 'customer', 'brand', 'price']\n",
            "\n",
            "ðŸ” Ad Features Head (5 rows):\n",
            "   adgroup_id  cate_id  campaign_id  customer     brand   price\n",
            "0       63133     6406        83237         1   95471.0  170.00\n",
            "1      313401     6406        83237         1   87331.0  199.00\n",
            "2      248909      392        83237         1   32233.0   38.00\n",
            "3      208458      392        83237         1  174374.0  139.00\n",
            "4      110847     7211       135256         2  145952.0   32.99\n",
            "\n",
            "Ad Features Info:\n",
            "    Data types: {dtype('int64'): 4, dtype('float64'): 2}\n",
            "    Missing values: 246330\n",
            "    Unique items: 846,811\n",
            "    Price range: [0.01, 99999999.00]\n",
            "    Price missing: 0\n",
            "\n",
            "ðŸ‘¤ 3. LOADING USER PROFILES...\n",
            "----------------------------------------\n",
            "User Profiles Shape: (1061768, 9)\n",
            "User Profiles Columns: ['userid', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level', 'pvalue_level', 'shopping_level', 'occupation', 'new_user_class_level ']\n",
            "\n",
            "User Profiles Head (5 rows):\n",
            "   userid  cms_segid  cms_group_id  final_gender_code  age_level  \\\n",
            "0     234          0             5                  2          5   \n",
            "1     523          5             2                  2          2   \n",
            "2     612          0             8                  1          2   \n",
            "3    1670          0             4                  2          4   \n",
            "4    2545          0            10                  1          4   \n",
            "\n",
            "   pvalue_level  shopping_level  occupation  new_user_class_level   \n",
            "0           NaN               3           0                    3.0  \n",
            "1           1.0               3           1                    2.0  \n",
            "2           2.0               3           0                    NaN  \n",
            "3           NaN               1           0                    NaN  \n",
            "4           NaN               3           0                    NaN  \n",
            "\n",
            "User Profiles Info:\n",
            "    Data types: {dtype('int64'): 7, dtype('float64'): 2}\n",
            "    Missing values: 920837\n",
            "    Unique users: 1,061,768\n",
            "    Gender distribution: {2: 684251, 1: 377517}\n",
            "    Age level distribution: {3: 307340, 4: 261751, 5: 214462, 2: 189617, 1: 65568}\n",
            "\n",
            "4. LOADING USER BEHAVIOR...\n",
            "----------------------------------------\n",
            "ðŸ“‹ User Behavior Columns: ['user_id', 'item_id', 'category_id', 'behavior_type', 'timestamp']\n",
            "\n",
            "ðŸ” User Behavior Head (5 rows):\n",
            "   user_id  item_id  category_id behavior_type   timestamp\n",
            "0        1  2268318      2520377            pv  1511544070\n",
            "1        1  2333346      2520771            pv  1511561733\n",
            "2        1  2576651       149192            pv  1511572885\n",
            "3        1  3830808      4181361            pv  1511593493\n",
            "4        1  4365585      2520377            pv  1511596146\n",
            "\n",
            "ðŸ“Š User Behavior Preview Info:\n",
            "    Data types: {'user_id': dtype('int64'), 'item_id': dtype('int64'), 'category_id': dtype('int64'), 'behavior_type': dtype('O'), 'timestamp': dtype('int64')}\n",
            "    Behavior types: {'pv': 10}\n",
            "    Sample timestamps: ['2017-11-24 17:21:10', '2017-11-24 22:15:33', '2017-11-25 01:21:25']\n",
            "\n",
            "ðŸ”„ Loading full user behavior data...\n",
            "    Chunk 1: 500,000 rows (Total: 500,000)\n",
            "    Chunk 2: 500,000 rows (Total: 1,000,000)\n",
            "    Chunk 3: 500,000 rows (Total: 1,500,000)\n",
            "    Chunk 4: 500,000 rows (Total: 2,000,000)\n",
            "    Chunk 5: 500,000 rows (Total: 2,500,000)\n",
            "    Chunk 6: 500,000 rows (Total: 3,000,000)\n",
            "    Chunk 7: 500,000 rows (Total: 3,500,000)\n",
            "    Chunk 8: 500,000 rows (Total: 4,000,000)\n",
            "    Chunk 9: 500,000 rows (Total: 4,500,000)\n",
            "    Chunk 10: 500,000 rows (Total: 5,000,000)\n",
            "    Chunk 11: 500,000 rows (Total: 5,500,000)\n",
            "    Chunk 12: 500,000 rows (Total: 6,000,000)\n",
            "    Chunk 13: 500,000 rows (Total: 6,500,000)\n",
            "    Chunk 14: 500,000 rows (Total: 7,000,000)\n",
            "    Chunk 15: 500,000 rows (Total: 7,500,000)\n",
            "    Chunk 16: 500,000 rows (Total: 8,000,000)\n",
            "    Chunk 17: 500,000 rows (Total: 8,500,000)\n",
            "    Chunk 18: 500,000 rows (Total: 9,000,000)\n",
            "    Chunk 19: 500,000 rows (Total: 9,500,000)\n",
            "    Chunk 20: 500,000 rows (Total: 10,000,000)\n",
            "    Chunk 21: 500,000 rows (Total: 10,500,000)\n",
            "    Chunk 22: 500,000 rows (Total: 11,000,000)\n",
            "    Chunk 23: 500,000 rows (Total: 11,500,000)\n",
            "    Chunk 24: 500,000 rows (Total: 12,000,000)\n",
            "    Chunk 25: 500,000 rows (Total: 12,500,000)\n",
            "    Chunk 26: 500,000 rows (Total: 13,000,000)\n",
            "    Chunk 27: 500,000 rows (Total: 13,500,000)\n",
            "    Chunk 28: 500,000 rows (Total: 14,000,000)\n",
            "    Chunk 29: 500,000 rows (Total: 14,500,000)\n",
            "    Chunk 30: 500,000 rows (Total: 15,000,000)\n",
            "    Chunk 31: 500,000 rows (Total: 15,500,000)\n",
            "    Chunk 32: 500,000 rows (Total: 16,000,000)\n",
            "    Chunk 33: 500,000 rows (Total: 16,500,000)\n",
            "    Chunk 34: 500,000 rows (Total: 17,000,000)\n",
            "    Chunk 35: 500,000 rows (Total: 17,500,000)\n",
            "    Chunk 36: 500,000 rows (Total: 18,000,000)\n",
            "    Chunk 37: 500,000 rows (Total: 18,500,000)\n",
            "    Chunk 38: 500,000 rows (Total: 19,000,000)\n",
            "    Chunk 39: 500,000 rows (Total: 19,500,000)\n",
            "    Chunk 40: 500,000 rows (Total: 20,000,000)\n",
            "    Chunk 41: 500,000 rows (Total: 20,500,000)\n",
            "    Chunk 42: 500,000 rows (Total: 21,000,000)\n",
            "    Chunk 43: 500,000 rows (Total: 21,500,000)\n",
            "    Chunk 44: 500,000 rows (Total: 22,000,000)\n",
            "    Chunk 45: 500,000 rows (Total: 22,500,000)\n",
            "    Chunk 46: 500,000 rows (Total: 23,000,000)\n",
            "    Chunk 47: 500,000 rows (Total: 23,500,000)\n",
            "    Chunk 48: 500,000 rows (Total: 24,000,000)\n",
            "    Chunk 49: 500,000 rows (Total: 24,500,000)\n",
            "    Chunk 50: 500,000 rows (Total: 25,000,000)\n",
            "    Chunk 51: 500,000 rows (Total: 25,500,000)\n",
            "    Chunk 52: 500,000 rows (Total: 26,000,000)\n",
            "    Chunk 53: 500,000 rows (Total: 26,500,000)\n",
            "    Chunk 54: 500,000 rows (Total: 27,000,000)\n",
            "    Chunk 55: 500,000 rows (Total: 27,500,000)\n",
            "    Chunk 56: 500,000 rows (Total: 28,000,000)\n",
            "    Chunk 57: 500,000 rows (Total: 28,500,000)\n",
            "    Chunk 58: 500,000 rows (Total: 29,000,000)\n",
            "    Chunk 59: 500,000 rows (Total: 29,500,000)\n",
            "    Chunk 60: 500,000 rows (Total: 30,000,000)\n",
            "    Chunk 61: 500,000 rows (Total: 30,500,000)\n",
            "    Chunk 62: 500,000 rows (Total: 31,000,000)\n",
            "    Chunk 63: 500,000 rows (Total: 31,500,000)\n",
            "    Chunk 64: 500,000 rows (Total: 32,000,000)\n",
            "    Chunk 65: 500,000 rows (Total: 32,500,000)\n",
            "    Chunk 66: 500,000 rows (Total: 33,000,000)\n",
            "    Chunk 67: 500,000 rows (Total: 33,500,000)\n",
            "    Chunk 68: 500,000 rows (Total: 34,000,000)\n",
            "    Chunk 69: 500,000 rows (Total: 34,500,000)\n",
            "    Chunk 70: 500,000 rows (Total: 35,000,000)\n",
            "    Chunk 71: 500,000 rows (Total: 35,500,000)\n",
            "    Chunk 72: 500,000 rows (Total: 36,000,000)\n",
            "    Chunk 73: 500,000 rows (Total: 36,500,000)\n",
            "    Chunk 74: 500,000 rows (Total: 37,000,000)\n",
            "    Chunk 75: 500,000 rows (Total: 37,500,000)\n",
            "    Chunk 76: 500,000 rows (Total: 38,000,000)\n",
            "    Chunk 77: 500,000 rows (Total: 38,500,000)\n",
            "    Chunk 78: 500,000 rows (Total: 39,000,000)\n",
            "    Chunk 79: 500,000 rows (Total: 39,500,000)\n",
            "    Chunk 80: 500,000 rows (Total: 40,000,000)\n",
            "    Chunk 81: 500,000 rows (Total: 40,500,000)\n",
            "    Chunk 82: 500,000 rows (Total: 41,000,000)\n",
            "    Chunk 83: 500,000 rows (Total: 41,500,000)\n",
            "    Chunk 84: 500,000 rows (Total: 42,000,000)\n",
            "    Chunk 85: 500,000 rows (Total: 42,500,000)\n",
            "    Chunk 86: 500,000 rows (Total: 43,000,000)\n",
            "    Chunk 87: 500,000 rows (Total: 43,500,000)\n",
            "    Chunk 88: 500,000 rows (Total: 44,000,000)\n",
            "    Chunk 89: 500,000 rows (Total: 44,500,000)\n",
            "    Chunk 90: 500,000 rows (Total: 45,000,000)\n",
            "    Chunk 91: 500,000 rows (Total: 45,500,000)\n",
            "    Chunk 92: 500,000 rows (Total: 46,000,000)\n",
            "    Chunk 93: 500,000 rows (Total: 46,500,000)\n",
            "    Chunk 94: 500,000 rows (Total: 47,000,000)\n",
            "    Chunk 95: 500,000 rows (Total: 47,500,000)\n",
            "    Chunk 96: 500,000 rows (Total: 48,000,000)\n",
            "    Chunk 97: 500,000 rows (Total: 48,500,000)\n",
            "    Chunk 98: 500,000 rows (Total: 49,000,000)\n",
            "    Chunk 99: 500,000 rows (Total: 49,500,000)\n",
            "    Chunk 100: 500,000 rows (Total: 50,000,000)\n",
            "    Final User Behavior: (50000000, 5)\n",
            "    Final behavior types: {'pv': 44770345, 'cart': 2775654, 'fav': 1449282, 'buy': 1004719}\n",
            "    Unique users: 492,944\n",
            "    Unique items: 3,220,204\n",
            "\n",
            "5. DATASET OVERLAP ANALYSIS\n",
            "----------------------------------------\n",
            "USER OVERLAPS:\n",
            "    Raw sample users: 1,141,729\n",
            "    Profile users: 1,061,768\n",
            "    Behavior users: 492,944\n",
            "    Raw âˆ© Profiles: 1,061,768 (93.0%)\n",
            "    Raw âˆ© Behavior: 492,944 (43.2%)\n",
            "    All 3 datasets: 457,598 (40.1%)\n",
            "\n",
            "ITEM OVERLAPS:\n",
            "    Raw sample items: 846,811\n",
            "    Ad feature items: 846,811\n",
            "    Behavior items: 3,220,204\n",
            "    Raw âˆ© Ad features: 846,811 (100.0%)\n",
            "    Raw âˆ© Behavior: 527,787 (62.3%)\n",
            "\n",
            "6. DATA LOADING SUMMARY\n",
            "----------------------------------------\n",
            "Raw Sample: (26557961, 5) | CTR: 0.0514\n",
            "Ad Features: (846811, 6) | Items: 846,811\n",
            "User Profiles: (1061768, 9) | Users: 1,061,768\n",
            "User Behavior: (50000000, 5) | Users: 492,944\n",
            "Data quality: Good overlaps for feature engineering\n",
            "\n",
            "STEP 2 COMPLETED!\n",
            "All data loaded with complete head inspection\n",
            "Dataset overlaps analyzed\n",
            "Data quality verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # =====================================================================\n",
        "# STEP 3: FEATURE ENGINEERING SEDERHANA\n",
        "# ======================================================================\n",
        "\n",
        "def create_features_simple():\n",
        "    \"\"\"Feature engineering sederhana berdasarkan EDA\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FEATURE ENGINEERING SEDERHANA\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        # Start with raw sample\n",
        "        data = raw_sample.copy()\n",
        "        print(f\"Starting: {data.shape}\")\n",
        "\n",
        "        # 1. TEMPORAL FEATURES\n",
        "        print(f\"\\nCreating temporal features...\")\n",
        "        data['datetime'] = pd.to_datetime(data['time_stamp'], unit='s')\n",
        "        data['hour'] = data['datetime'].dt.hour\n",
        "        data['day_of_week'] = data['datetime'].dt.dayofweek\n",
        "        data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)\n",
        "        data['is_peak_hour'] = data['hour'].isin([20, 17, 18]).astype(int)\n",
        "\n",
        "        # Hour CTR\n",
        "        hour_ctr = data.groupby('hour')['clk'].mean()\n",
        "        data['hour_ctr'] = data['hour'].map(hour_ctr)\n",
        "\n",
        "        print(f\"    Temporal features created\")\n",
        "\n",
        "        # 2. MERGE AD FEATURES (Brand + Category priority dari EDA)\n",
        "        print(f\"\\nMerging ad features...\")\n",
        "        data = data.merge(\n",
        "            ad_features[['adgroup_id', 'cate_id', 'brand', 'price']],\n",
        "            on='adgroup_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # 3. PRICE FEATURES\n",
        "        print(f\"\\nCreating price features...\")\n",
        "        data['price'] = pd.to_numeric(data['price'], errors='coerce')\n",
        "        data['price'] = data['price'].fillna(data['price'].median())\n",
        "        data['price_log'] = np.log1p(data['price'])\n",
        "        data['price_percentile'] = data['price'].rank(pct=True)\n",
        "        data['is_high_price'] = (data['price_percentile'] >= 0.8).astype(int)\n",
        "\n",
        "        # 4. ITEM POPULARITY (EDA high importance)\n",
        "        print(f\"\\nCreating item features...\")\n",
        "        item_stats = data.groupby('adgroup_id').agg({\n",
        "            'clk': ['count', 'sum', 'mean'],\n",
        "            'user': 'nunique'\n",
        "        }).reset_index()\n",
        "        item_stats.columns = ['adgroup_id', 'impressions', 'clicks', 'item_ctr', 'unique_users']\n",
        "        item_stats = item_stats.fillna(0)\n",
        "\n",
        "        # Popularity score\n",
        "        item_stats['popularity_score'] = (\n",
        "            np.log1p(item_stats['clicks']) * 0.4 +\n",
        "            item_stats['item_ctr'] * 0.6\n",
        "        )\n",
        "\n",
        "        # Merge item features\n",
        "        data = data.merge(\n",
        "            item_stats[['adgroup_id', 'item_ctr', 'popularity_score']],\n",
        "            on='adgroup_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # 5. USER PROFILES\n",
        "        print(f\"\\nProcessing user profiles...\")\n",
        "        user_profiles_clean = user_profiles.copy()\n",
        "\n",
        "        # Fill missing\n",
        "        categorical_cols = ['final_gender_code', 'age_level', 'shopping_level']\n",
        "        for col in categorical_cols:\n",
        "            if col in user_profiles_clean.columns:\n",
        "                user_profiles_clean[col] = user_profiles_clean[col].fillna(-1)\n",
        "\n",
        "        if 'pvalue_level' in user_profiles_clean.columns:\n",
        "            user_profiles_clean['pvalue_level'] = user_profiles_clean['pvalue_level'].fillna(\n",
        "                user_profiles_clean['pvalue_level'].median()\n",
        "            )\n",
        "\n",
        "        # Merge profiles\n",
        "        data = data.merge(\n",
        "            user_profiles_clean[['userid', 'final_gender_code', 'age_level', 'shopping_level', 'pvalue_level']],\n",
        "            left_on='user',\n",
        "            right_on='userid',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # 6. USER BEHAVIOR (EDA: 46% overlap)\n",
        "        print(f\"\\nCreating behavior features...\")\n",
        "        overlapping_users = set(data['user'].astype(str)) & set(user_behavior['user_id'].astype(str))\n",
        "        behavior_filtered = user_behavior[user_behavior['user_id'].astype(str).isin(overlapping_users)].copy()\n",
        "\n",
        "        if len(behavior_filtered) > 0:\n",
        "            # Behavior weights\n",
        "            behavior_weights = {'pv': 1.0, 'fav': 2.0, 'cart': 3.0, 'buy': 5.0}\n",
        "            behavior_filtered['behavior_weight'] = behavior_filtered['behavior_type'].map(behavior_weights)\n",
        "\n",
        "            # User aggregation\n",
        "            user_behavior_agg = behavior_filtered.groupby('user_id').agg({\n",
        "                'item_id': 'count',\n",
        "                'category_id': 'nunique',\n",
        "                'behavior_weight': ['sum', 'mean'],\n",
        "                'behavior_type': [\n",
        "                    lambda x: (x == 'buy').sum()\n",
        "                ]\n",
        "            }).reset_index()\n",
        "\n",
        "            user_behavior_agg.columns = [\n",
        "                'user_id', 'total_interactions', 'unique_categories',\n",
        "                'engagement_score', 'avg_behavior_weight', 'buy_count'\n",
        "            ]\n",
        "\n",
        "            # Additional features\n",
        "            user_behavior_agg['conversion_rate'] = user_behavior_agg['buy_count'] / (user_behavior_agg['total_interactions'] + 1)\n",
        "            user_behavior_agg['is_buyer'] = (user_behavior_agg['buy_count'] > 0).astype(int)\n",
        "\n",
        "            # Merge\n",
        "            user_behavior_agg['user_id'] = user_behavior_agg['user_id'].astype(str)\n",
        "            data['user_str'] = data['user'].astype(str)\n",
        "            data = data.merge(user_behavior_agg, left_on='user_str', right_on='user_id', how='left')\n",
        "            data = data.drop(['user_str', 'user_id'], axis=1, errors='ignore')\n",
        "\n",
        "        # Fill missing behavior features\n",
        "        behavior_cols = ['total_interactions', 'engagement_score', 'conversion_rate', 'is_buyer']\n",
        "        for col in behavior_cols:\n",
        "            if col in data.columns:\n",
        "                data[col] = data[col].fillna(0)\n",
        "\n",
        "        # 7. CATEGORICAL ENCODING\n",
        "        print(f\"\\nEncoding categories...\")\n",
        "        categorical_features = ['final_gender_code', 'age_level', 'shopping_level', 'cate_id', 'brand']\n",
        "        label_encoders = {}\n",
        "\n",
        "        for col in categorical_features:\n",
        "            if col in data.columns:\n",
        "                data[col] = data[col].astype(str)\n",
        "                if data[col].nunique() > 1:\n",
        "                    le = LabelEncoder()\n",
        "                    data[col] = le.fit_transform(data[col])\n",
        "                    label_encoders[col] = le\n",
        "\n",
        "        # 8. FINAL SELECTION\n",
        "        print(f\"\\nFinal feature selection...\")\n",
        "        feature_cols = [\n",
        "            'user', 'adgroup_id',  # IDs\n",
        "            'cate_id', 'brand',\n",
        "            'hour', 'is_peak_hour', 'hour_ctr', 'is_weekend', 'day_of_week', 'time_stamp', # Temporal\n",
        "            'price_log', 'is_high_price', 'price_percentile',  # Price\n",
        "            'item_ctr', 'popularity_score',  # Item\n",
        "            'final_gender_code', 'age_level', 'shopping_level', 'pvalue_level',  # Profile\n",
        "            'clk'  # Target\n",
        "        ]\n",
        "\n",
        "        # Add behavior if available\n",
        "        if 'total_interactions' in data.columns:\n",
        "            feature_cols.extend(['total_interactions', 'engagement_score', 'is_buyer', 'conversion_rate', 'unique_categories'])\n",
        "\n",
        "        # Keep only existing\n",
        "        available_cols = [col for col in feature_cols if col in data.columns]\n",
        "        final_data = data[available_cols].copy()\n",
        "\n",
        "        # 9. CLEAN MISSING\n",
        "        print(f\"\\nðŸ§¹ Cleaning missing values...\")\n",
        "        for col in final_data.columns:\n",
        "            if final_data[col].isnull().sum() > 0:\n",
        "                if final_data[col].dtype in ['int64', 'float64']:\n",
        "                    final_data[col] = final_data[col].fillna(0)\n",
        "                else:\n",
        "                    final_data[col] = final_data[col].fillna(-1)\n",
        "\n",
        "        print(f\"    Final shape: {final_data.shape}\")\n",
        "        print(f\"    CTR preserved: {final_data['clk'].mean():.4f}\")\n",
        "\n",
        "        feature_list = [col for col in available_cols if col not in ['user', 'adgroup_id', 'clk']]\n",
        "\n",
        "        return final_data, label_encoders, feature_list\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, None\n",
        "\n",
        "# Execute feature engineering\n",
        "print(\"Creating features...\")\n",
        "feature_data, label_encoders, feature_list = create_features_simple()\n",
        "\n",
        "if feature_data is not None:\n",
        "    print(f\"\\nSTEP 3 COMPLETED!\")\n",
        "    print(f\"Features: {len(feature_list)}\")\n",
        "    print(f\"Shape: {feature_data.shape}\")\n",
        "    print(f\"CTR: {feature_data['clk'].mean():.4f}\")\n",
        "else:\n",
        "    print(f\"âŒ STEP 3 FAILED\")"
      ],
      "metadata": {
        "id": "mXKHYH5ruJEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30e7ece-e76e-4606-a6fc-785255576ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating features...\n",
            "\n",
            "============================================================\n",
            "FEATURE ENGINEERING SEDERHANA\n",
            "============================================================\n",
            "Starting: (26557961, 5)\n",
            "\n",
            "Creating temporal features...\n",
            "    Temporal features created\n",
            "\n",
            "Merging ad features...\n",
            "\n",
            "Creating price features...\n",
            "\n",
            "Creating item features...\n",
            "\n",
            "Processing user profiles...\n",
            "\n",
            "Creating behavior features...\n",
            "\n",
            "Encoding categories...\n",
            "\n",
            "Final feature selection...\n",
            "\n",
            "ðŸ§¹ Cleaning missing values...\n",
            "    Final shape: (26557961, 25)\n",
            "    CTR preserved: 0.0514\n",
            "\n",
            "STEP 3 COMPLETED!\n",
            "Features: 22\n",
            "Shape: (26557961, 25)\n",
            "CTR: 0.0514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 4: MODEL DATA PREPARATION - TEMPORAL SPLIT\n",
        "# =====================================================================\n",
        "\n",
        "def prepare_model_data():\n",
        "    \"\"\"Prepare data dengan temporal split\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MODEL DATA PREPARATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        print(f\"Starting: {feature_data.shape}\")\n",
        "\n",
        "        # 1. SEPARATE TARGET AND FEATURES\n",
        "        y = feature_data['clk'].values.astype(np.float32)\n",
        "        X = feature_data.drop('clk', axis=1).copy()\n",
        "\n",
        "        print(f\"    Target shape: {y.shape}, CTR: {y.mean():.4f}\")\n",
        "\n",
        "        # 2. CREATE ID MAPPINGS\n",
        "        print(f\"\\nCreating ID mappings...\")\n",
        "\n",
        "        # User mappings\n",
        "        unique_users = sorted(X['user'].unique())\n",
        "        user_to_idx = {uid: idx + 1 for idx, uid in enumerate(unique_users)}\n",
        "        user_to_idx[0] = 0  # Unknown\n",
        "\n",
        "        # Item mappings\n",
        "        unique_items = sorted(X['adgroup_id'].unique())\n",
        "        item_to_idx = {iid: idx + 1 for idx, iid in enumerate(unique_items)}\n",
        "        item_to_idx[0] = 0  # Unknown\n",
        "\n",
        "        # Convert\n",
        "        user_ids = np.array([user_to_idx.get(uid, 0) for uid in X['user']], dtype=np.int32)\n",
        "        item_ids = np.array([item_to_idx.get(iid, 0) for iid in X['adgroup_id']], dtype=np.int32)\n",
        "\n",
        "        n_users = len(unique_users) + 1\n",
        "        n_items = len(unique_items) + 1\n",
        "\n",
        "        print(f\"    Users: {n_users:,}, Items: {n_items:,}\")\n",
        "\n",
        "        # 3. CREATE SEQUENCES (simple version)\n",
        "        print(f\"\\nCreating sequences...\")\n",
        "\n",
        "        # Sort by user and timestamp for sequences\n",
        "        sequence_data = X.copy()\n",
        "        sequence_data['user_id_mapped'] = user_ids\n",
        "        sequence_data['item_id_mapped'] = item_ids\n",
        "        sequence_data['target'] = y\n",
        "\n",
        "        if 'time_stamp' in sequence_data.columns:\n",
        "            sequence_data = sequence_data.sort_values(['user', 'time_stamp'])\n",
        "        else:\n",
        "            sequence_data = sequence_data.sort_values(['user'])\n",
        "\n",
        "        # Build sequences\n",
        "        max_seq_len = 8  # Hardcoded\n",
        "        sequences = np.zeros((len(sequence_data), max_seq_len), dtype=np.int32)\n",
        "        seq_lengths = np.ones(len(sequence_data), dtype=np.int32)\n",
        "\n",
        "        user_sequences = {}\n",
        "        for idx, row in sequence_data.iterrows():\n",
        "            user_id = row['user']\n",
        "            item_id = row['item_id_mapped']\n",
        "\n",
        "            if user_id not in user_sequences:\n",
        "                user_sequences[user_id] = []\n",
        "            user_sequences[user_id].append(item_id)\n",
        "\n",
        "        # Fill sequences\n",
        "        for idx, row in sequence_data.iterrows():\n",
        "            user_id = row['user']\n",
        "            current_item = row['item_id_mapped']\n",
        "            user_history = user_sequences[user_id]\n",
        "\n",
        "            try:\n",
        "                current_pos = user_history.index(current_item)\n",
        "                history = user_history[:current_pos] if current_pos > 0 else [current_item]\n",
        "            except ValueError:\n",
        "                history = [current_item]\n",
        "\n",
        "            seq_len = min(len(history), max_seq_len)\n",
        "            if seq_len > 0:\n",
        "                sequences[idx, :seq_len] = history[-seq_len:]\n",
        "                seq_lengths[idx] = seq_len\n",
        "\n",
        "        print(f\"    Sequences: {sequences.shape}, avg length: {seq_lengths.mean():.2f}\")\n",
        "\n",
        "        # 4. DENSE FEATURES\n",
        "        print(f\"\\nPreparing dense features...\")\n",
        "        dense_feature_cols = [col for col in X.columns\n",
        "                             if col not in ['user', 'adgroup_id', 'time_stamp', 'datetime', 'userid']\n",
        "                             and X[col].dtype in ['int64', 'float64']]\n",
        "\n",
        "        dense_features = X[dense_feature_cols].values.astype(np.float32)\n",
        "        dense_features = np.nan_to_num(dense_features, nan=0.0)\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        dense_features = scaler.fit_transform(dense_features)\n",
        "\n",
        "        print(f\"    Dense features: {dense_features.shape}\")\n",
        "\n",
        "        # 5. TEMPORAL SPLIT (EDA recommended: 80/10/10)\n",
        "        print(f\"\\nCreating temporal split...\")\n",
        "\n",
        "        # Sort by timestamp for temporal split\n",
        "        if 'time_stamp' in feature_data.columns:\n",
        "            sorted_data = feature_data.sort_values('time_stamp').reset_index(drop=True)\n",
        "            sorted_indices = sorted_data.index.values\n",
        "\n",
        "            # Get original order back\n",
        "            original_order = np.argsort(sequence_data.index)\n",
        "            user_ids = user_ids[original_order]\n",
        "            item_ids = item_ids[original_order]\n",
        "            sequences = sequences[original_order]\n",
        "            seq_lengths = seq_lengths[original_order]\n",
        "            dense_features = dense_features[original_order]\n",
        "            y = y[original_order]\n",
        "\n",
        "            # Create temporal split\n",
        "            n_samples = len(y)\n",
        "            train_end = int(0.80 * n_samples)\n",
        "            val_end = int(0.90 * n_samples)\n",
        "\n",
        "            train_idx = np.arange(0, train_end)\n",
        "            val_idx = np.arange(train_end, val_end)\n",
        "            test_idx = np.arange(val_end, n_samples)\n",
        "\n",
        "            print(f\"    Temporal split: {len(train_idx)}/{len(val_idx)}/{len(test_idx)}\")\n",
        "\n",
        "        else:\n",
        "            # Fallback to stratified split\n",
        "            indices = np.arange(len(y))\n",
        "            temp_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=1234, stratify=y)\n",
        "            train_idx, val_idx = train_test_split(temp_idx, test_size=0.125, random_state=1234, stratify=y[temp_idx])\n",
        "\n",
        "            print(f\"    Stratified split: {len(train_idx)}/{len(val_idx)}/{len(test_idx)}\")\n",
        "\n",
        "        def get_split_data(idx):\n",
        "            return {\n",
        "                'user_ids': user_ids[idx],\n",
        "                'item_ids': item_ids[idx],\n",
        "                'sequences': sequences[idx],\n",
        "                'seq_lengths': seq_lengths[idx],\n",
        "                'dense_features': dense_features[idx],\n",
        "                'labels': y[idx].reshape(-1, 1)\n",
        "            }\n",
        "\n",
        "        splits = {\n",
        "            'train': get_split_data(train_idx),\n",
        "            'val': get_split_data(val_idx),\n",
        "            'test': get_split_data(test_idx)\n",
        "        }\n",
        "\n",
        "        # Verify splits\n",
        "        for split_name, split_data in splits.items():\n",
        "            split_ctr = split_data['labels'].mean()\n",
        "            print(f\"    {split_name}: {len(split_data['labels']):,} samples, CTR: {split_ctr:.4f}\")\n",
        "\n",
        "        # 6. CREATE TF DATASETS\n",
        "        print(f\"\\nCreating TensorFlow datasets...\")\n",
        "\n",
        "        def create_tf_dataset(split_data, batch_size=256, shuffle=True):\n",
        "            dataset = tf.data.Dataset.from_tensor_slices({\n",
        "                'user_id': split_data['user_ids'],\n",
        "                'item_id': split_data['item_ids'],\n",
        "                'sequence': split_data['sequences'],\n",
        "                'seq_length': split_data['seq_lengths'],\n",
        "                'dense_features': split_data['dense_features'],\n",
        "                'label': split_data['labels']\n",
        "            })\n",
        "\n",
        "            if shuffle:\n",
        "                dataset = dataset.shuffle(5000, seed=1234)\n",
        "\n",
        "            dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "            dataset = dataset.prefetch(2)\n",
        "            return dataset\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = create_tf_dataset(splits['train'], batch_size=256, shuffle=True)\n",
        "        val_dataset = create_tf_dataset(splits['val'], batch_size=256, shuffle=False)\n",
        "        test_dataset = create_tf_dataset(splits['test'], batch_size=256, shuffle=False)\n",
        "\n",
        "        # Verify pipeline\n",
        "        sample_batch = next(iter(train_dataset))\n",
        "        print(f\"    Batch shapes:\")\n",
        "        for key, value in sample_batch.items():\n",
        "            print(f\"      {key}: {value.shape}\")\n",
        "\n",
        "        return {\n",
        "            'train_dataset': train_dataset,\n",
        "            'val_dataset': val_dataset,\n",
        "            'test_dataset': test_dataset,\n",
        "            'splits': splits,\n",
        "            'model_params': {\n",
        "                'n_users': n_users,\n",
        "                'n_items': n_items,\n",
        "                'dense_feature_dim': dense_features.shape[1],\n",
        "                'max_sequence_length': max_seq_len,\n",
        "                'embedding_dim': 32,  # Hardcoded\n",
        "                'hidden_units': [64, 32],  # Hardcoded\n",
        "            },\n",
        "            'preprocessing': {\n",
        "                'user_to_idx': user_to_idx,\n",
        "                'item_to_idx': item_to_idx,\n",
        "                'scaler': scaler,\n",
        "                'dense_feature_cols': dense_feature_cols,\n",
        "                'label_encoders': label_encoders\n",
        "            }\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Execute model preparation\n",
        "print(\"Preparing model data...\")\n",
        "model_data = prepare_model_data()\n",
        "splits = model_data['splits']\n",
        "if model_data is not None:\n",
        "    print(f\"\\n COMPLETED!\")\n",
        "    print(f\"Temporal split created\")\n",
        "    print(f\"TensorFlow datasets ready\")\n",
        "    print(f\"Users: {model_data['model_params']['n_users']:,}\")\n",
        "    print(f\"Items: {model_data['model_params']['n_items']:,}\")\n",
        "    print(f\"Dense features: {model_data['model_params']['dense_feature_dim']}\")\n",
        "else:\n",
        "    print(f\"âŒ STEP 4 FAILED\")"
      ],
      "metadata": {
        "id": "FdDn1UmEvZG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b18b91-cb84-4cbb-f4d6-d3c5db404f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing model data...\n",
            "\n",
            "============================================================\n",
            "MODEL DATA PREPARATION\n",
            "============================================================\n",
            "Starting: (26557961, 25)\n",
            "    Target shape: (26557961,), CTR: 0.0514\n",
            "\n",
            "Creating ID mappings...\n",
            "    Users: 1,141,730, Items: 846,812\n",
            "\n",
            "Creating sequences...\n",
            "    Sequences: (26557961, 8), avg length: 6.64\n",
            "\n",
            "Preparing dense features...\n",
            "    Dense features: (26557961, 19)\n",
            "\n",
            "Creating temporal split...\n",
            "    Temporal split: 21246368/2655796/2655797\n",
            "    train: 21,246,368 samples, CTR: 0.0515\n",
            "    val: 2,655,796 samples, CTR: 0.0511\n",
            "    test: 2,655,797 samples, CTR: 0.0516\n",
            "\n",
            "Creating TensorFlow datasets...\n",
            "    Batch shapes:\n",
            "      user_id: (256,)\n",
            "      item_id: (256,)\n",
            "      sequence: (256, 8)\n",
            "      seq_length: (256,)\n",
            "      dense_features: (256, 19)\n",
            "      label: (256, 1)\n",
            "\n",
            " COMPLETED!\n",
            "Temporal split created\n",
            "TensorFlow datasets ready\n",
            "Users: 1,141,730\n",
            "Items: 846,812\n",
            "Dense features: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 5: LAYER DEFINITIONS ONLY\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LAYER DEFINITIONS ONLY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "class DiceActivation(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    DICE activation dari paper DIN dengan parameter optimal dari tuning\n",
        "\n",
        "    Paper: Deep Interest Network for Click-Through Rate Prediction\n",
        "    Formula: Dice(x) = p(x) * x + (1 - p(x)) * Î± * x\n",
        "    dimana p(x) = sigmoid((x - E[x]) / sqrt(Var[x] + Îµ) * Î²)\n",
        "    \"\"\"\n",
        "    def __init__(self, axis=-1, epsilon=8.84e-09, alpha_init=0.4515, beta_init=1.6703, **kwargs):\n",
        "        super(DiceActivation, self).__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha_init = alpha_init  # Store alpha_init parameter\n",
        "        self.beta_init = beta_init    # Store beta_init parameter\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        param_shape = input_shape[1:]\n",
        "\n",
        "        # Alpha: parameter untuk mengontrol negative part\n",
        "        self.alpha = self.add_weight(\n",
        "            name='alpha',\n",
        "            shape=param_shape,\n",
        "            initializer=tf.keras.initializers.Constant(self.alpha_init),  # Use the parameter\n",
        "            trainable=True,\n",
        "            constraint=tf.keras.constraints.NonNeg()\n",
        "        )\n",
        "\n",
        "        # Beta: parameter untuk scaling normalization\n",
        "        self.beta = self.add_weight(\n",
        "            name='beta',\n",
        "            shape=param_shape,\n",
        "            initializer=tf.keras.initializers.Constant(self.beta_init),  # Use the parameter\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        super(DiceActivation, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # Compute batch statistics\n",
        "        if training:\n",
        "            mean = tf.reduce_mean(inputs, axis=0, keepdims=True)\n",
        "            variance = tf.reduce_mean(\n",
        "                tf.square(inputs - mean),\n",
        "                axis=0,\n",
        "                keepdims=True\n",
        "            )\n",
        "        else:\n",
        "            mean = tf.reduce_mean(inputs, axis=0, keepdims=True)\n",
        "            variance = tf.reduce_mean(\n",
        "                tf.square(inputs - mean),\n",
        "                axis=0,\n",
        "                keepdims=True\n",
        "            )\n",
        "\n",
        "        # Normalize dengan epsilon optimal\n",
        "        normalized = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
        "        scaled = normalized * self.beta\n",
        "        prob = tf.nn.sigmoid(scaled)\n",
        "\n",
        "        # DICE output\n",
        "        output = prob * inputs + (1.0 - prob) * self.alpha * inputs\n",
        "        return output\n",
        "\n",
        "class DINAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    DIN Attention mechanism dengan dukungan untuk DICE dan PReLU activations\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_units=16, max_seq_len=8, activation_type='dice',\n",
        "                 dice_alpha_init=0.4515, dice_beta_init=1.6703, dice_epsilon=8.84e-09,\n",
        "                 prelu_alpha_init=0.4515, **kwargs):\n",
        "        super(DINAttention, self).__init__(**kwargs)\n",
        "        self.hidden_units = hidden_units\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.activation_type = activation_type\n",
        "\n",
        "        # Parameter untuk DICE\n",
        "        self.dice_alpha_init = dice_alpha_init\n",
        "        self.dice_beta_init = dice_beta_init\n",
        "        self.dice_epsilon = dice_epsilon\n",
        "\n",
        "        # Parameter untuk PReLU\n",
        "        self.prelu_alpha_init = prelu_alpha_init\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Dense layer tanpa aktivasi\n",
        "        self.attention_dense = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(self.hidden_units, activation=None),\n",
        "            name='attention_dense_td'\n",
        "        )\n",
        "\n",
        "        # Inisialisasi activation layer berdasarkan jenis\n",
        "        if self.activation_type.lower() == 'dice':\n",
        "            self.activation = DiceActivation(\n",
        "                alpha_init=self.dice_alpha_init,\n",
        "                beta_init=self.dice_beta_init,\n",
        "                epsilon=self.dice_epsilon,\n",
        "                name='attention_dice'\n",
        "            )\n",
        "        else:  # Default to PReLU if not DICE\n",
        "            self.activation = tf.keras.layers.PReLU(\n",
        "                alpha_initializer=tf.keras.initializers.Constant(self.prelu_alpha_init),\n",
        "                name='attention_prelu'\n",
        "            )\n",
        "\n",
        "        # Output layer\n",
        "        self.attention_output = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(1),\n",
        "            name='attention_output_td'\n",
        "        )\n",
        "        super(DINAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        sequence_emb, target_item_emb = inputs\n",
        "\n",
        "        # Create custom layer for tile operation\n",
        "        class TileLayer(tf.keras.layers.Layer):\n",
        "            def __init__(self, max_seq_len):\n",
        "                super().__init__()\n",
        "                self.max_seq_len = max_seq_len\n",
        "\n",
        "            def call(self, x):\n",
        "                return tf.tile(\n",
        "                    tf.expand_dims(x, axis=1),\n",
        "                    [1, self.max_seq_len, 1]\n",
        "                )\n",
        "\n",
        "        tile_layer = TileLayer(self.max_seq_len)\n",
        "        target_expanded = tile_layer(target_item_emb)\n",
        "\n",
        "        # Element-wise operations\n",
        "        element_wise_product = tf.keras.layers.Multiply()([sequence_emb, target_expanded])\n",
        "        element_wise_diff = tf.keras.layers.Subtract()([sequence_emb, target_expanded])\n",
        "\n",
        "        # Concatenate features\n",
        "        attention_input = tf.keras.layers.Concatenate(axis=-1)([\n",
        "            sequence_emb,\n",
        "            target_expanded,\n",
        "            element_wise_product,\n",
        "            element_wise_diff\n",
        "        ])\n",
        "\n",
        "        # Apply attention network dengan aktivasi yang dipilih\n",
        "        attention_hidden = self.attention_dense(attention_input)\n",
        "        attention_hidden = self.activation(attention_hidden)  # Menggunakan activation layer\n",
        "        attention_scores = self.attention_output(attention_hidden)\n",
        "\n",
        "        return attention_scores, sequence_emb\n",
        "\n",
        "class SequencePooling(tf.keras.layers.Layer):\n",
        "    \"\"\"Pooling layer untuk sequence dengan attention weights\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SequencePooling, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention_scores, sequence_emb, seq_lengths = inputs\n",
        "\n",
        "        max_seq_len = tf.shape(attention_scores)[1]\n",
        "\n",
        "        # Create sequence mask\n",
        "        seq_mask = tf.sequence_mask(seq_lengths, max_seq_len, dtype=tf.float32)\n",
        "        seq_mask = tf.expand_dims(seq_mask, axis=-1)\n",
        "\n",
        "        # Apply mask to attention scores\n",
        "        masked_scores = attention_scores + (1.0 - seq_mask) * (-1e9)\n",
        "\n",
        "        # Softmax normalization\n",
        "        attention_weights = tf.nn.softmax(masked_scores, axis=1)\n",
        "\n",
        "        # Weighted sum\n",
        "        attended_sequence = tf.reduce_sum(sequence_emb * attention_weights, axis=1)\n",
        "\n",
        "        return attended_sequence\n",
        "\n",
        "print(f\"LAYER DEFINITIONS COMPLETED!\")"
      ],
      "metadata": {
        "id": "jV422avAwM0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc1dd6a-7ce3-4ae6-c186-6983903c3578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "LAYER DEFINITIONS ONLY\n",
            "============================================================\n",
            "LAYER DEFINITIONS COMPLETED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6A: CREATE DIN-DICE MODEL (OPTIMIZED)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATE DIN-DICE MODEl\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_din_dice_model():\n",
        "\n",
        "    # Model parameters from tuning\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = [64, 32]\n",
        "    attention_hidden = 16\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = 0.5445\n",
        "    l2_reg = 0.0001305\n",
        "    l2_dense = 4.86e-05\n",
        "    dice_alpha_init = 0.4515\n",
        "    dice_beta_init = 1.6703\n",
        "    dice_epsilon = 8.84e-09\n",
        "\n",
        "    print(f\"    Users: {n_users:,}\")\n",
        "    print(f\"    Items: {n_items:,}\")\n",
        "    print(f\"    Embedding dim: {embedding_dim}\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Attention hidden: {attention_hidden}\")\n",
        "    print(f\"    Max seq len: {max_seq_len}\")\n",
        "    print(f\"    Dense features: {dense_feature_dim}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 regularization (embedding): {l2_reg:.6f}\")\n",
        "    print(f\"    L2 regularization (dense): {l2_dense:.6f}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "    seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    target_item_emb = item_embedding_layer(item_input)\n",
        "    sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "    # DIN Attention mechanism dengan attention_hidden optimal\n",
        "    attention_scores, attended_emb = DINAttention(\n",
        "        hidden_units=attention_hidden,\n",
        "        max_seq_len=max_seq_len,\n",
        "        activation_type='dice',\n",
        "        dice_alpha_init=dice_alpha_init,  # Dari parameter tuning\n",
        "        dice_beta_init=dice_beta_init,    # Dari parameter tuning\n",
        "        dice_epsilon=dice_epsilon,        # Dari parameter tuning\n",
        "        name='din_attention'\n",
        "    )([sequence_emb, target_item_emb])\n",
        "\n",
        "    # Sequence pooling\n",
        "    pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "        [attention_scores, attended_emb, seq_length_input]\n",
        "    )\n",
        "\n",
        "    # Feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        target_item_emb,\n",
        "        pooled_sequence,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK dengan DICE activation\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "\n",
        "        # DICE activation dari tuning\n",
        "        x = DiceActivation(name=f'dice_{i+1}')(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='din_dice_optimized'  # Renamed to reflect optimization\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DIN-DICE model\n",
        "print(f\"Creating DIN-DICE model...\")\n",
        "try:\n",
        "    din_dice_model = create_din_dice_model()\n",
        "\n",
        "    # COMPILE SETTINGS\n",
        "    learning_rate = 5.95e-05\n",
        "    label_smoothing = 0.1462\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-8,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    # LOSS dengan label smoothing\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "\n",
        "    din_dice_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(f\"DIN-DICE model created successfully !\")\n",
        "    print(f\"Model summary:\")\n",
        "    print(f\"    Total parameters: {din_dice_model.count_params():,}\")\n",
        "    print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in din_dice_model.trainable_weights]):,}\")\n",
        "\n",
        "    print(f\"\\nCONFIGURATION APPLIED:\")\n",
        "    print(f\"    Learning rate: {learning_rate:.6f}\")\n",
        "    print(f\"    Dropout rate: {0.5445:.4f}\")\n",
        "    print(f\"    L2 embedding: {0.0001305:.6f}\")\n",
        "    print(f\"    L2 dense: {4.86e-05:.6f}\")\n",
        "    print(f\"    DICE Î±_init: 0.4515\")\n",
        "    print(f\"    DICE Î²_init: 1.6703\")\n",
        "    print(f\"    DICE Îµ: 8.84e-09\")\n",
        "    print(f\"    Label smoothing: {0.1462:.4f}\")\n",
        "\n",
        "    # Test model dengan sample batch\n",
        "    print(f\"\\nðŸ§ª Testing OPTIMIZED DIN-DICE model...\")\n",
        "    test_batch = {\n",
        "        'user_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'item_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'sequence': tf.constant([[1, 2, 0, 0, 0, 0, 0, 0], [1, 2, 3, 0, 0, 0, 0, 0]], dtype=tf.int32),\n",
        "        'seq_length': tf.constant([2, 3], dtype=tf.int32),\n",
        "        'dense_features': tf.random.normal((2, model_data['model_params']['dense_feature_dim']))\n",
        "    }\n",
        "\n",
        "    test_output = din_dice_model(test_batch, training=False)\n",
        "    print(f\"    Model test successful!\")\n",
        "    print(f\"    Input batch size: 2\")\n",
        "    print(f\"    Output shape: {test_output.shape}\")\n",
        "    print(f\"    Output range: [{float(tf.reduce_min(test_output)):.4f}, {float(tf.reduce_max(test_output)):.4f}]\")\n",
        "\n",
        "    # Model architecture summary\n",
        "    print(f\"\\nFULLY DIN-DICE Architecture Summary:\")\n",
        "    din_dice_model.summary(show_trainable=False)\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to create DIN-DICE model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    din_dice_model = None\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "24hBL2DQwU4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77b01af2-843f-42da-e91f-8a22cd33f5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATE DIN-DICE MODEl\n",
            "============================================================\n",
            "Creating DIN-DICE model...\n",
            "    Users: 1,141,730\n",
            "    Items: 846,812\n",
            "    Embedding dim: 32\n",
            "    Hidden units: [64, 32]\n",
            "    Attention hidden: 16\n",
            "    Max seq len: 8\n",
            "    Dense features: 19\n",
            "    Dropout rate: 0.5445\n",
            "    L2 regularization (embedding): 0.000131\n",
            "    L2 regularization (dense): 0.000049\n",
            "DIN-DICE model created successfully !\n",
            "Model summary:\n",
            "    Total parameters: 63,645,794\n",
            "    Trainable parameters: 63,645,602\n",
            "\n",
            "CONFIGURATION APPLIED:\n",
            "    Learning rate: 0.000060\n",
            "    Dropout rate: 0.5445\n",
            "    L2 embedding: 0.000131\n",
            "    L2 dense: 0.000049\n",
            "    DICE Î±_init: 0.4515\n",
            "    DICE Î²_init: 1.6703\n",
            "    DICE Îµ: 8.84e-09\n",
            "    Label smoothing: 0.1462\n",
            "\n",
            "ðŸ§ª Testing OPTIMIZED DIN-DICE model...\n",
            "    Model test successful!\n",
            "    Input batch size: 2\n",
            "    Output shape: (2, 1)\n",
            "    Output range: [0.4629, 0.4737]\n",
            "\n",
            "FULLY DIN-DICE Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"din_dice_optimized\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"din_dice_optimized\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚ \u001b[38;5;34m27,097,984\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚ sequence[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ din_attention       â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m),    â”‚      \u001b[38;5;34m2,337\u001b[0m â”‚ item_embedding[\u001b[38;5;34m1\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDINAttention\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)]    â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ seq_length          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m36,535,360\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence_pooling    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ din_attention[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mSequencePooling\u001b[0m)   â”‚                   â”‚            â”‚ din_attention[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ seq_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ sequence_poolingâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m7,424\u001b[0m â”‚ feature_concat[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dice_1              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mDiceActivation\u001b[0m)    â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dice_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dice_2              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚         \u001b[38;5;34m64\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mDiceActivation\u001b[0m)    â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dice_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,097,984</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚ sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ din_attention       â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>),    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,337</span> â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DINAttention</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]    â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ seq_length          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">36,535,360</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence_pooling    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ din_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequencePooling</span>)   â”‚                   â”‚            â”‚ din_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ seq_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ sequence_poolingâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,424</span> â”‚ feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dice_1              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiceActivation</span>)    â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dice_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dice_2              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiceActivation</span>)    â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dice_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,645,794\u001b[0m (242.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,645,794</span> (242.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,645,602\u001b[0m (242.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,645,602</span> (242.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6B: CREATE DIN-PRELU MODEL (OPTIMIZED)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATE DIN-PRELU MODEL (FULLY OPTIMIZED)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_din_prelu_model():\n",
        "    \"\"\"Create DIN model dengan PReLU activation dan parameter optimal dari tuning\"\"\"\n",
        "\n",
        "    # Model parameters from tuning\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = [64, 32]\n",
        "    attention_hidden = 16\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = 0.5445\n",
        "    l2_reg = 0.0001305\n",
        "    l2_dense = 4.86e-05\n",
        "    prelu_alpha_init = 0.4515\n",
        "\n",
        "    print(f\"    Users: {n_users:,}\")\n",
        "    print(f\"    Items: {n_items:,}\")\n",
        "    print(f\"    Embedding dim: {embedding_dim}\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Attention hidden: {attention_hidden}\")\n",
        "    print(f\"    Max seq len: {max_seq_len}\")\n",
        "    print(f\"    Dense features: {dense_feature_dim}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 regularization (embedding): {l2_reg:.6f}\")\n",
        "    print(f\"    L2 regularization (dense): {l2_dense:.6f}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "    seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    target_item_emb = item_embedding_layer(item_input)\n",
        "    sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "    # DIN Attention mechanism\n",
        "    attention_scores, attended_emb = DINAttention(\n",
        "        hidden_units=attention_hidden,\n",
        "        max_seq_len=max_seq_len,\n",
        "        activation_type='prelu',\n",
        "        prelu_alpha_init=prelu_alpha_init,  # Dari parameter tuning\n",
        "        name='din_attention'\n",
        "    )([sequence_emb, target_item_emb])\n",
        "\n",
        "    # Sequence pooling\n",
        "    pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "        [attention_scores, attended_emb, seq_length_input]\n",
        "    )\n",
        "\n",
        "    # Feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        target_item_emb,\n",
        "        pooled_sequence,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK dengan PReLU activation\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "\n",
        "        # PReLU activation dengan alpha init sama dengan DICE alpha\n",
        "        x = tf.keras.layers.PReLU(\n",
        "            alpha_initializer=tf.keras.initializers.Constant(0.4948),\n",
        "            name=f'prelu_{i+1}'\n",
        "        )(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='din_prelu_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DIN-PReLU model\n",
        "print(f\"Creating DIN-PReLU model with OPTIMAL TUNING PARAMETERS...\")\n",
        "try:\n",
        "    din_prelu_model = create_din_prelu_model()\n",
        "\n",
        "    # COMPILE SETTINGS\n",
        "    learning_rate = 5.95e-05\n",
        "    label_smoothing = 0.1462\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-8,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    # LOSS dengan label smoothing\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "\n",
        "    din_prelu_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(f\"DIN-PReLU model created successfully!\")\n",
        "    print(f\"Model summary:\")\n",
        "    print(f\"    Total parameters: {din_prelu_model.count_params():,}\")\n",
        "    print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in din_prelu_model.trainable_weights]):,}\")\n",
        "\n",
        "    print(f\"\\nFULLY OPTIMIZED CONFIGURATION APPLIED FROM TUNING:\")\n",
        "    print(f\"    Learning rate: {learning_rate:.6f}\")\n",
        "    print(f\"    Dropout rate: {0.5445:.4f} \")\n",
        "    print(f\"    L2 embedding: {0.0001305:.6f} L\")\n",
        "    print(f\"    L2 dense: {4.86e-05:.6f} \")\n",
        "    print(f\"    PReLU Î±_init: 0.4515\")\n",
        "    print(f\"    Label smoothing: {0.1462:.4f}L\")\n",
        "    print(f\"    Batch size: 4096\")\n",
        "\n",
        "    # Test model dengan sample batch\n",
        "    print(f\"\\nTesting OPTIMIZED DIN-PReLU model...\")\n",
        "    test_batch = {\n",
        "        'user_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'item_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'sequence': tf.constant([[1, 2, 0, 0, 0, 0, 0, 0], [1, 2, 3, 0, 0, 0, 0, 0]], dtype=tf.int32),\n",
        "        'seq_length': tf.constant([2, 3], dtype=tf.int32),\n",
        "        'dense_features': tf.random.normal((2, model_data['model_params']['dense_feature_dim']))\n",
        "    }\n",
        "\n",
        "    test_output = din_prelu_model(test_batch, training=False)\n",
        "    print(f\"    Model test successful!\")\n",
        "    print(f\"    Input batch size: 2\")\n",
        "    print(f\"    Output shape: {test_output.shape}\")\n",
        "    print(f\"    Output range: [{float(tf.reduce_min(test_output)):.4f}, {float(tf.reduce_max(test_output)):.4f}]\")\n",
        "\n",
        "    # Model architecture summary\n",
        "    print(f\"\\nðŸ“‹ FULLY DIN-PReLU Architecture Summary:\")\n",
        "    din_prelu_model.summary(show_trainable=False)\n",
        "\n",
        "    # Compare dengan DIN-DICE\n",
        "    if 'din_dice_model' in globals() and din_dice_model is not None:\n",
        "        print(f\"\\nComparison with DIN-DICE:\")\n",
        "        print(f\"    DIN-DICE params: {din_dice_model.count_params():,}\")\n",
        "        print(f\"    DIN-PReLU params: {din_prelu_model.count_params():,}\")\n",
        "        if din_prelu_model.count_params() == din_dice_model.count_params():\n",
        "            print(f\"    Same parameter count - perfect for fair comparison!\")\n",
        "        else:\n",
        "            diff = din_prelu_model.count_params() - din_dice_model.count_params()\n",
        "            print(f\"    Parameter difference: {diff:+,}\")\n",
        "\n",
        "        print(f\"\\nACTIVATION COMPARISON:\")\n",
        "        print(f\"    DIN-DICE: DICE activation with Î±_init=0.4948, Î²_init=1.6584, Îµ=3.95e-09\")\n",
        "        print(f\"    DIN-PReLU: PReLU activation with Î±_init=0.4948\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to create DIN-PReLU model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    din_prelu_model = None\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "dVWcvw1f1phG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8face5d5-1f91-4165-9ab0-727a72e78fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATE DIN-PRELU MODEL (FULLY OPTIMIZED)\n",
            "============================================================\n",
            "Creating DIN-PReLU model with OPTIMAL TUNING PARAMETERS...\n",
            "    Users: 1,141,730\n",
            "    Items: 846,812\n",
            "    Embedding dim: 32\n",
            "    Hidden units: [64, 32]\n",
            "    Attention hidden: 16\n",
            "    Max seq len: 8\n",
            "    Dense features: 19\n",
            "    Dropout rate: 0.5445\n",
            "    L2 regularization (embedding): 0.000131\n",
            "    L2 regularization (dense): 0.000049\n",
            "DIN-PReLU model created successfully!\n",
            "Model summary:\n",
            "    Total parameters: 63,645,570\n",
            "    Trainable parameters: 63,645,378\n",
            "\n",
            "FULLY OPTIMIZED CONFIGURATION APPLIED FROM TUNING:\n",
            "    Learning rate: 0.000060\n",
            "    Dropout rate: 0.5445 \n",
            "    L2 embedding: 0.000131 L\n",
            "    L2 dense: 0.000049 \n",
            "    PReLU Î±_init: 0.4515\n",
            "    Label smoothing: 0.1462L\n",
            "    Batch size: 4096\n",
            "\n",
            "Testing OPTIMIZED DIN-PReLU model...\n",
            "    Model test successful!\n",
            "    Input batch size: 2\n",
            "    Output shape: (2, 1)\n",
            "    Output range: [0.5215, 0.5841]\n",
            "\n",
            "ðŸ“‹ FULLY DIN-PReLU Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"din_prelu_optimized\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"din_prelu_optimized\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚ \u001b[38;5;34m27,097,984\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚ sequence[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ din_attention       â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m),    â”‚      \u001b[38;5;34m2,209\u001b[0m â”‚ item_embedding[\u001b[38;5;34m1\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDINAttention\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)]    â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ seq_length          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m36,535,360\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence_pooling    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ din_attention[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mSequencePooling\u001b[0m)   â”‚                   â”‚            â”‚ din_attention[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ seq_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ sequence_poolingâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m7,424\u001b[0m â”‚ feature_concat[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ prelu_1 (\u001b[38;5;33mPReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚         \u001b[38;5;34m64\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ prelu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ prelu_2 (\u001b[38;5;33mPReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚         \u001b[38;5;34m32\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ prelu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,097,984</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚ sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ din_attention       â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>),    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,209</span> â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DINAttention</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]    â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ seq_length          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">36,535,360</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence_pooling    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ din_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequencePooling</span>)   â”‚                   â”‚            â”‚ din_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ seq_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ sequence_poolingâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,424</span> â”‚ feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ prelu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ prelu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ prelu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ prelu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,645,570\u001b[0m (242.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,645,570</span> (242.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,645,378\u001b[0m (242.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,645,378</span> (242.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison with DIN-DICE:\n",
            "    DIN-DICE params: 63,645,794\n",
            "    DIN-PReLU params: 63,645,570\n",
            "    Parameter difference: -224\n",
            "\n",
            "ACTIVATION COMPARISON:\n",
            "    DIN-DICE: DICE activation with Î±_init=0.4948, Î²_init=1.6584, Îµ=3.95e-09\n",
            "    DIN-PReLU: PReLU activation with Î±_init=0.4948\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6C: CREATE DEEPFM MODEL\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATE DEEPFM MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_deepfm_model():\n",
        "    \"\"\"Create DeepFM model dengan optimal parameters - tanpa sequence features\"\"\"\n",
        "\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = [128, 64, 32]\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "\n",
        "    print(f\"ðŸ”§ Creating DeepFM model with OPTIMAL parameters...\")\n",
        "    print(f\"    Users: {n_users:,}\")\n",
        "    print(f\"    Items: {n_items:,}\")\n",
        "    print(f\"    Embedding dim: {embedding_dim}\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Dense features: {dense_feature_dim}\")\n",
        "    print(f\"    Note: No sequence features (DeepFM baseline)\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "    # FM PART: Factorization Machine component\n",
        "    print(f\"    Building FM component...\")\n",
        "\n",
        "    # âœ… OPTIMAL LINEAR PART dengan L2 regularization\n",
        "    user_linear = tf.keras.layers.Dense(1, use_bias=False, name='user_linear',\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(0.005))(user_emb)\n",
        "    item_linear = tf.keras.layers.Dense(1, use_bias=False, name='item_linear',\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(0.005))(item_emb)\n",
        "    dense_linear = tf.keras.layers.Dense(1, use_bias=False, name='dense_linear',\n",
        "                                        kernel_regularizer=tf.keras.regularizers.l2(0.005))(dense_input)\n",
        "\n",
        "    # INTERACTION PART dengan L2 regularization\n",
        "    # User-Item interaction\n",
        "    user_item_interaction = tf.keras.layers.Multiply(name='user_item_mult')([user_emb, item_emb])\n",
        "\n",
        "    # User-Dense interaction\n",
        "    user_dense_proj = tf.keras.layers.Dense(embedding_dim, name='user_dense_proj',\n",
        "                                           kernel_regularizer=tf.keras.regularizers.l2(0.005))(dense_input)\n",
        "    user_dense_interaction = tf.keras.layers.Multiply(name='user_dense_mult')([user_emb, user_dense_proj])\n",
        "\n",
        "    # Item-Dense interaction\n",
        "    item_dense_proj = tf.keras.layers.Dense(embedding_dim, name='item_dense_proj',\n",
        "                                           kernel_regularizer=tf.keras.regularizers.l2(0.005))(dense_input)\n",
        "    item_dense_interaction = tf.keras.layers.Multiply(name='item_dense_mult')([item_emb, item_dense_proj])\n",
        "\n",
        "    # Sum all interactions\n",
        "    fm_interactions = tf.keras.layers.Add(name='fm_interactions')([\n",
        "        user_item_interaction,\n",
        "        user_dense_interaction,\n",
        "        item_dense_interaction\n",
        "    ])\n",
        "    fm_interaction_sum = tf.keras.layers.Dense(1, name='fm_interaction_sum',\n",
        "                                              kernel_regularizer=tf.keras.regularizers.l2(0.005))(fm_interactions)\n",
        "\n",
        "    # FM output\n",
        "    fm_output = tf.keras.layers.Add(name='fm_output')([\n",
        "        user_linear,\n",
        "        item_linear,\n",
        "        dense_linear,\n",
        "        fm_interaction_sum\n",
        "    ])\n",
        "\n",
        "    # DEEP PART: Deep Neural Network component\n",
        "    print(f\"    Building Deep component...\")\n",
        "\n",
        "    # Concatenate all features untuk deep part\n",
        "    deep_features = tf.keras.layers.Concatenate(name='deep_features')([\n",
        "        user_emb,\n",
        "        item_emb,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK\n",
        "    x = deep_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation='relu',\n",
        "            name=f'deep_dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.005)\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(0.5, name=f'deep_dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'deep_bn_{i+1}')(x)\n",
        "\n",
        "    # DEEP OUTPUT\n",
        "    deep_output = tf.keras.layers.Dense(1, name='deep_output',\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(0.0005))(x)\n",
        "\n",
        "    # COMBINE FM + DEEP\n",
        "    print(f\"    Combining FM + Deep components...\")\n",
        "    combined_output = tf.keras.layers.Add(name='fm_deep_combine')([fm_output, deep_output])\n",
        "\n",
        "    # Final activation\n",
        "    final_output = tf.keras.layers.Activation('sigmoid', name='final_output')(combined_output)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, dense_input],\n",
        "        outputs=final_output,\n",
        "        name='deepfm'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Dataset adapter for DeepFM (remove sequence features)\n",
        "def create_deepfm_dataset():\n",
        "    \"\"\"Create dataset untuk DeepFM (tanpa sequence features)\"\"\"\n",
        "\n",
        "    # Get original splits\n",
        "    splits = model_data['splits']\n",
        "\n",
        "    # Create new splits without sequence features\n",
        "    deepfm_splits = {}\n",
        "\n",
        "    for split_name in ['train', 'val', 'test']:\n",
        "        deepfm_splits[split_name] = {\n",
        "            'user_ids': splits[split_name]['user_ids'],\n",
        "            'item_ids': splits[split_name]['item_ids'],\n",
        "            'dense_features': splits[split_name]['dense_features'],\n",
        "            'labels': splits[split_name]['labels']\n",
        "        }\n",
        "\n",
        "    print(f\"ðŸ“Š DeepFM dataset created:\")\n",
        "    for split_name, split_data in deepfm_splits.items():\n",
        "        print(f\"    {split_name}: {len(split_data['labels']):,} samples\")\n",
        "\n",
        "    return deepfm_splits\n",
        "\n",
        "# Create DeepFM model\n",
        "print(f\"ðŸš€ Creating DeepFM model...\")\n",
        "try:\n",
        "    deepfm_model = create_deepfm_model()\n",
        "\n",
        "    # Create DeepFM dataset\n",
        "    deepfm_data = create_deepfm_dataset()\n",
        "\n",
        "    # COMPILE SETTINGS\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.0001,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-8,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    # LOSS dengan label smoothing\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)\n",
        "\n",
        "    deepfm_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(f\"DeepFM model created successfully with OPTIMAL parameters!\")\n",
        "    print(f\"Model summary:\")\n",
        "    print(f\"    Total parameters: {deepfm_model.count_params():,}\")\n",
        "    print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in deepfm_model.trainable_weights]):,}\")\n",
        "\n",
        "    print(f\"\\nOPTIMAL CONFIGURATION APPLIED:\")\n",
        "    print(f\"    Learning rate: 0.0001\")\n",
        "    print(f\"    Dropout: 0.5 \")\n",
        "    print(f\"    L2 embedding: 0.0005 \")\n",
        "    print(f\"    L2 dense: 0.005 \")\n",
        "    print(f\"    L2 output: 0.0005 \")\n",
        "    print(f\"    Gradient clip: 0.5\")\n",
        "    print(f\"    Label smoothing: 0.1\")\n",
        "\n",
        "    # Test model dengan sample batch\n",
        "    print(f\"\\nTesting DeepFM model...\")\n",
        "    test_batch = {\n",
        "        'user_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'item_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'dense_features': tf.random.normal((2, model_data['model_params']['dense_feature_dim']))\n",
        "    }\n",
        "\n",
        "    test_output = deepfm_model(test_batch, training=False)\n",
        "    print(f\"    Model test successful!\")\n",
        "    print(f\"    Input batch size: 2\")\n",
        "    print(f\"    Output shape: {test_output.shape}\")\n",
        "    print(f\"    Output range: [{float(tf.reduce_min(test_output)):.4f}, {float(tf.reduce_max(test_output)):.4f}]\")\n",
        "\n",
        "    # Model architecture summary\n",
        "    print(f\"\\nDeepFM Architecture Summary:\")\n",
        "    deepfm_model.summary(show_trainable=False)\n",
        "\n",
        "    # Compare dengan DIN models\n",
        "    print(f\"\\nComparison with DIN models:\")\n",
        "    if 'din_dice_model' in globals() and din_dice_model is not None:\n",
        "        print(f\"    DIN-DICE params: {din_dice_model.count_params():,}\")\n",
        "    if 'din_prelu_model' in globals() and din_prelu_model is not None:\n",
        "        print(f\"    DIN-PReLU params: {din_prelu_model.count_params():,}\")\n",
        "    print(f\"    DeepFM params: {deepfm_model.count_params():,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to create DeepFM model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    deepfm_model = None\n",
        "    deepfm_data = None\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "SXIccZkA91vx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61d1e27e-8bac-4f00-8e71-03f2d484e031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATE DEEPFM MODEL\n",
            "============================================================\n",
            "ðŸš€ Creating DeepFM model...\n",
            "ðŸ”§ Creating DeepFM model with OPTIMAL parameters...\n",
            "    Users: 1,141,730\n",
            "    Items: 846,812\n",
            "    Embedding dim: 32\n",
            "    Hidden units: [128, 64, 32]\n",
            "    Dense features: 19\n",
            "    Note: No sequence features (DeepFM baseline)\n",
            "    Building FM component...\n",
            "    Building Deep component...\n",
            "    Combining FM + Deep components...\n",
            "ðŸ“Š DeepFM dataset created:\n",
            "    train: 21,246,368 samples\n",
            "    val: 2,655,796 samples\n",
            "    test: 2,655,797 samples\n",
            "DeepFM model created successfully with OPTIMAL parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,656,757\n",
            "    Trainable parameters: 63,656,309\n",
            "\n",
            "OPTIMAL CONFIGURATION APPLIED:\n",
            "    Learning rate: 0.0001\n",
            "    Dropout: 0.5 \n",
            "    L2 embedding: 0.0005 \n",
            "    L2 dense: 0.005 \n",
            "    L2 output: 0.0005 \n",
            "    Gradient clip: 0.5\n",
            "    Label smoothing: 0.1\n",
            "\n",
            "Testing DeepFM model...\n",
            "    Model test successful!\n",
            "    Input batch size: 2\n",
            "    Output shape: (2, 1)\n",
            "    Output range: [0.5827, 0.7174]\n",
            "\n",
            "DeepFM Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"deepfm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"deepfm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m36,535,360\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m27,097,984\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_features       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m10,752\u001b[0m â”‚ deep_features[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ deep_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ deep_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_2        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ deep_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ deep_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_dense_proj     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m640\u001b[0m â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_dense_proj     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m640\u001b[0m â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ deep_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_item_mult      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_dense_mult     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ user_dense_proj[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_dense_mult     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ item_dense_proj[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_3        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ deep_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_interactions     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_item_mult[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ user_dense_mult[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ item_dense_mult[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_3      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ deep_dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_linear (\u001b[38;5;33mDense\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m32\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_linear (\u001b[38;5;33mDense\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m32\u001b[0m â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_linear        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m19\u001b[0m â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_interaction_sum  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ fm_interactions[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ deep_dropout_3[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_output (\u001b[38;5;33mAdd\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_linear[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ item_linear[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_linear[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ fm_interaction_sâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_output (\u001b[38;5;33mDense\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ deep_bn_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_deep_combine     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fm_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ deep_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ final_output        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fm_deep_combine[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">36,535,360</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,097,984</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_features       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,752</span> â”‚ deep_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ deep_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ deep_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_2        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ deep_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ deep_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_dense_proj     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_dense_proj     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ deep_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_item_mult      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_dense_mult     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ user_dense_proj[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_dense_mult     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ item_dense_proj[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_3        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ deep_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_interactions     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_item_mult[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ user_dense_mult[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ item_dense_mult[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_3      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ deep_dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_linear (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_linear (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_linear        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_interaction_sum  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ fm_interactions[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ deep_dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_linear[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ item_linear[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_linear[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ fm_interaction_sâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ deep_bn_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_deep_combine     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fm_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ deep_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ final_output        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fm_deep_combine[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,656,757\u001b[0m (242.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,656,757</span> (242.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,656,309\u001b[0m (242.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,656,309</span> (242.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison with DIN models:\n",
            "    DIN-DICE params: 63,645,794\n",
            "    DIN-PReLU params: 63,645,570\n",
            "    DeepFM params: 63,656,757\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6D: CREATE BASELINE MODEL\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATE BASELINE MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_baseline_model():\n",
        "    \"\"\"Create simple baseline model dengan optimal parameters - basic feedforward network\"\"\"\n",
        "\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = [128, 64, 32]\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "\n",
        "    print(f\"ðŸ”§ Creating Baseline model with OPTIMAL parameters...\")\n",
        "    print(f\"    Users: {n_users:,}\")\n",
        "    print(f\"    Items: {n_items:,}\")\n",
        "    print(f\"    Embedding dim: {embedding_dim}\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Dense features: {dense_feature_dim}\")\n",
        "    print(f\"    Note: Simple feedforward network (no FM, no attention)\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "    # Simple feature concatenation\n",
        "    print(f\"    Building simple concatenation...\")\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        item_emb,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # FEEDFORWARD NETWORK\n",
        "    print(f\"    ðŸ”§ Building feedforward network...\")\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation='relu',\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.005)\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(0.5, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(0.0005))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='baseline'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Dataset adapter for Baseline\n",
        "def create_baseline_dataset():\n",
        "    \"\"\"Create dataset untuk Baseline (tanpa sequence features)\"\"\"\n",
        "\n",
        "    # Get original splits\n",
        "    splits = model_data['splits']\n",
        "\n",
        "    # Create new splits without sequence features\n",
        "    baseline_splits = {}\n",
        "\n",
        "    for split_name in ['train', 'val', 'test']:\n",
        "        baseline_splits[split_name] = {\n",
        "            'user_ids': splits[split_name]['user_ids'],\n",
        "            'item_ids': splits[split_name]['item_ids'],\n",
        "            'dense_features': splits[split_name]['dense_features'],\n",
        "            'labels': splits[split_name]['labels']\n",
        "        }\n",
        "\n",
        "    print(f\"Baseline dataset created:\")\n",
        "    for split_name, split_data in baseline_splits.items():\n",
        "        print(f\"    {split_name}: {len(split_data['labels']):,} samples\")\n",
        "\n",
        "    return baseline_splits\n",
        "\n",
        "# TRAINING CONFIGURATION\n",
        "def get_simple_training_config():\n",
        "    \"\"\"Get optimal training configuration untuk baseline models\"\"\"\n",
        "    return {\n",
        "        'epochs': 20,\n",
        "        'batch_size': 2048,\n",
        "        'validation_freq': 1,\n",
        "        'callbacks': [\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_auc',\n",
        "                patience=4,\n",
        "                mode='max',\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_auc',\n",
        "                factor=0.5,\n",
        "                patience=3,\n",
        "                mode='max',\n",
        "                min_lr=1e-6,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "    }\n",
        "\n",
        "# Create Baseline model\n",
        "print(f\"Creating Baseline model...\")\n",
        "try:\n",
        "    baseline_model = create_baseline_model()\n",
        "\n",
        "    # Create Baseline dataset\n",
        "    baseline_data = create_baseline_dataset()\n",
        "\n",
        "    # Get training configuration\n",
        "    baseline_config = get_simple_training_config()\n",
        "\n",
        "    # âœ… OPTIMAL COMPILE SETTINGS\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.0001,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-8,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    # LOSS dengan label smoothing\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)\n",
        "\n",
        "    baseline_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(f\"Baseline model created successfully!\")\n",
        "    print(f\"Model summary:\")\n",
        "    print(f\"    Total parameters: {baseline_model.count_params():,}\")\n",
        "    print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in baseline_model.trainable_weights]):,}\")\n",
        "\n",
        "\n",
        "    # Test model dengan sample batch\n",
        "    print(f\"\\nTesting Baseline model...\")\n",
        "    test_batch = {\n",
        "        'user_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'item_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'dense_features': tf.random.normal((2, model_data['model_params']['dense_feature_dim']))\n",
        "    }\n",
        "\n",
        "    test_output = baseline_model(test_batch, training=False)\n",
        "    print(f\"    Model test successful!\")\n",
        "    print(f\"    Input batch size: 2\")\n",
        "    print(f\"    Output shape: {test_output.shape}\")\n",
        "    print(f\"    Output range: [{float(tf.reduce_min(test_output)):.4f}, {float(tf.reduce_max(test_output)):.4f}]\")\n",
        "\n",
        "    # Model architecture summary\n",
        "    print(f\"\\nBaseline Architecture Summary:\")\n",
        "    baseline_model.summary(show_trainable=False)\n",
        "\n",
        "    # Training configuration summary\n",
        "    print(f\"\\nOPTIMAL Training Configuration:\")\n",
        "    print(f\"    Epochs: {baseline_config['epochs']}\")\n",
        "    print(f\"    Batch size: {baseline_config['batch_size']} (optimized)\")\n",
        "    print(f\"    Early stopping: val_auc (patience=4)\")\n",
        "    print(f\"    LR reduction: val_auc (patience=3, factor=0.5)\")\n",
        "\n",
        "    # Final comparison dengan all models\n",
        "    print(f\"\\nALL MODELS PARAMETER COMPARISON:\")\n",
        "    if 'din_dice_model' in globals() and din_dice_model is not None:\n",
        "        print(f\"    DIN-DICE:  {din_dice_model.count_params():,} params\")\n",
        "    if 'din_prelu_model' in globals() and din_prelu_model is not None:\n",
        "        print(f\"    DIN-PReLU: {din_prelu_model.count_params():,} params\")\n",
        "    if 'deepfm_model' in globals() and deepfm_model is not None:\n",
        "        print(f\"    DeepFM:    {deepfm_model.count_params():,} params\")\n",
        "    print(f\"    Baseline:  {baseline_model.count_params():,} params\")\n",
        "\n",
        "    print(f\"\\nBASELINE MODEL READY FOR TRAINING!\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to create Baseline model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    baseline_model = None\n",
        "    baseline_data = None\n",
        "    baseline_config = None\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "ry9m6i1A93i6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08628692-6298-49ac-a99b-d9dfe2c794cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATE BASELINE MODEL\n",
            "============================================================\n",
            "Creating Baseline model...\n",
            "ðŸ”§ Creating Baseline model with OPTIMAL parameters...\n",
            "    Users: 1,141,730\n",
            "    Items: 846,812\n",
            "    Embedding dim: 32\n",
            "    Hidden units: [128, 64, 32]\n",
            "    Dense features: 19\n",
            "    Note: Simple feedforward network (no FM, no attention)\n",
            "    Building simple concatenation...\n",
            "    ðŸ”§ Building feedforward network...\n",
            "Baseline dataset created:\n",
            "    train: 21,246,368 samples\n",
            "    val: 2,655,796 samples\n",
            "    test: 2,655,797 samples\n",
            "Baseline model created successfully!\n",
            "Model summary:\n",
            "    Total parameters: 63,655,361\n",
            "    Trainable parameters: 63,654,913\n",
            "\n",
            "Testing Baseline model...\n",
            "    Model test successful!\n",
            "    Input batch size: 2\n",
            "    Output shape: (2, 1)\n",
            "    Output range: [0.4111, 0.4461]\n",
            "\n",
            "Baseline Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"baseline\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"baseline\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m36,535,360\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m27,097,984\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m10,752\u001b[0m â”‚ feature_concat[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_3                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ bn_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">36,535,360</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,097,984</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,752</span> â”‚ feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_3                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ bn_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,655,361\u001b[0m (242.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,655,361</span> (242.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,654,913\u001b[0m (242.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,654,913</span> (242.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OPTIMAL Training Configuration:\n",
            "    Epochs: 20\n",
            "    Batch size: 2048 (optimized)\n",
            "    Early stopping: val_auc (patience=4)\n",
            "    LR reduction: val_auc (patience=3, factor=0.5)\n",
            "\n",
            "ALL MODELS PARAMETER COMPARISON:\n",
            "    DIN-DICE:  63,645,794 params\n",
            "    DIN-PReLU: 63,645,570 params\n",
            "    DeepFM:    63,656,757 params\n",
            "    Baseline:  63,655,361 params\n",
            "\n",
            "BASELINE MODEL READY FOR TRAINING!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6E: TRAINING FUNCTIONS DEFINITIONS (TEST ONLY AT END)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING FUNCTIONS DEFINITIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def manual_training_loop_din_dice(model=None, batch_size=2048, epochs=15, early_stopping_patience=4, save_csv=False):\n",
        "    \"\"\"Custom training loop for DIN-DICE model with test set evaluation only at the end\"\"\"\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"STARTING DIN-DICE TRAINING:\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
        "\n",
        "    # If no model is provided, use the global model\n",
        "    if model is None:\n",
        "        model = din_dice_model\n",
        "\n",
        "    # Get data from global splits\n",
        "    train_x = {\n",
        "        'user_id': splits['train']['user_ids'],\n",
        "        'item_id': splits['train']['item_ids'],\n",
        "        'sequence': splits['train']['sequences'],\n",
        "        'seq_length': splits['train']['seq_lengths'],\n",
        "        'dense_features': splits['train']['dense_features']\n",
        "    }\n",
        "    val_x = {\n",
        "        'user_id': splits['val']['user_ids'],\n",
        "        'item_id': splits['val']['item_ids'],\n",
        "        'sequence': splits['val']['sequences'],\n",
        "        'seq_length': splits['val']['seq_lengths'],\n",
        "        'dense_features': splits['val']['dense_features']\n",
        "    }\n",
        "    test_x = {\n",
        "        'user_id': splits['test']['user_ids'],\n",
        "        'item_id': splits['test']['item_ids'],\n",
        "        'sequence': splits['test']['sequences'],\n",
        "        'seq_length': splits['test']['seq_lengths'],\n",
        "        'dense_features': splits['test']['dense_features']\n",
        "    }\n",
        "\n",
        "    train_y = splits['train']['labels'].flatten()\n",
        "    val_y = splits['val']['labels'].flatten()\n",
        "    test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "    # Setup optimizer, loss and metrics\n",
        "    optimizer = tf.keras.optimizers.Adam(clipnorm=0.5)\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "    train_loss_metric = tf.keras.metrics.Mean()\n",
        "    train_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "    val_loss_metric = tf.keras.metrics.Mean()\n",
        "    val_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "    # History tracking\n",
        "    history = {\n",
        "        'loss': [],\n",
        "        'auc': [],\n",
        "        'val_loss': [],\n",
        "        'val_auc': []\n",
        "    }\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_auc = 0.0\n",
        "    patience_counter = 0\n",
        "    best_epoch = 0\n",
        "    best_weights = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Reset metrics\n",
        "        train_loss_metric.reset_state()\n",
        "        train_auc_metric.reset_state()\n",
        "        val_loss_metric.reset_state()\n",
        "        val_auc_metric.reset_state()\n",
        "\n",
        "        # Training phase\n",
        "        n_train_batches = (len(train_y) + batch_size - 1) // batch_size\n",
        "        indices = np.random.permutation(len(train_y))\n",
        "\n",
        "        for batch_idx in range(n_train_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(train_y))\n",
        "            batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "            # Create batch\n",
        "            batch_x = {k: tf.convert_to_tensor(v[batch_indices]) for k, v in train_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(train_y[batch_indices])\n",
        "\n",
        "            # Training step\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = model(batch_x, training=True)\n",
        "                predictions = tf.squeeze(predictions)\n",
        "                loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "            # Apply gradients\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            # Update metrics\n",
        "            train_loss_metric.update_state(loss)\n",
        "            train_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # Print progress\n",
        "            if (batch_idx + 1) % 100 == 0:\n",
        "                print(f\"  Batch {batch_idx + 1}/{n_train_batches}\")\n",
        "\n",
        "        # Validation phase\n",
        "        n_val_batches = (len(val_y) + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in range(n_val_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(val_y))\n",
        "\n",
        "            # Create batch\n",
        "            batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in val_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(val_y[start_idx:end_idx])\n",
        "\n",
        "            # Validation step\n",
        "            predictions = model(batch_x, training=False)\n",
        "            predictions = tf.squeeze(predictions)\n",
        "            loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "            # Update metrics\n",
        "            val_loss_metric.update_state(loss)\n",
        "            val_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "        # Get epoch results\n",
        "        epoch_train_loss = train_loss_metric.result().numpy()\n",
        "        epoch_train_auc = train_auc_metric.result().numpy()\n",
        "        epoch_val_loss = val_loss_metric.result().numpy()\n",
        "        epoch_val_auc = val_auc_metric.result().numpy()\n",
        "\n",
        "        # Store history\n",
        "        history['loss'].append(epoch_train_loss)\n",
        "        history['auc'].append(epoch_train_auc)\n",
        "        history['val_loss'].append(epoch_val_loss)\n",
        "        history['val_auc'].append(epoch_val_auc)\n",
        "\n",
        "        # Print results (only train and validation)\n",
        "        print(f\"  Train Loss: {epoch_train_loss:.4f}, AUC: {epoch_train_auc:.4f}\")\n",
        "        print(f\"  Val   Loss: {epoch_val_loss:.4f}, AUC: {epoch_val_auc:.4f}\")\n",
        "\n",
        "        # Check early stopping\n",
        "        if epoch_val_auc > best_val_auc:\n",
        "            best_val_auc = epoch_val_auc\n",
        "            best_epoch = epoch\n",
        "            patience_counter = 0\n",
        "            best_weights = model.get_weights()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "            break\n",
        "\n",
        "    # Restore best weights\n",
        "    if best_weights is not None:\n",
        "        model.set_weights(best_weights)\n",
        "\n",
        "    # NOW EVALUATE ON TEST SET (only once, after training is complete)\n",
        "    print(f\"\\nTraining completed. Evaluating final model on test set...\")\n",
        "\n",
        "    test_auc_metric = tf.keras.metrics.AUC()\n",
        "    all_test_preds = []\n",
        "    all_test_labels = []\n",
        "\n",
        "    n_test_batches = (len(test_y) + batch_size - 1) // batch_size\n",
        "    for batch_idx in range(n_test_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min(start_idx + batch_size, len(test_y))\n",
        "\n",
        "        # Create batch\n",
        "        batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in test_x.items()}\n",
        "        batch_y = tf.convert_to_tensor(test_y[start_idx:end_idx])\n",
        "\n",
        "        # Test step\n",
        "        predictions = model(batch_x, training=False)\n",
        "        predictions = tf.squeeze(predictions)\n",
        "\n",
        "        # Update metrics\n",
        "        test_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "        # Store predictions for log loss calculation\n",
        "        all_test_preds.append(predictions.numpy())\n",
        "        all_test_labels.append(batch_y.numpy())\n",
        "\n",
        "    # Calculate test metrics\n",
        "    best_test_auc = test_auc_metric.result().numpy()\n",
        "    all_test_preds = np.concatenate(all_test_preds)\n",
        "    all_test_labels = np.concatenate(all_test_labels)\n",
        "    best_test_logloss = log_loss(all_test_labels, all_test_preds)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nFINAL RESULTS:\")\n",
        "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
        "    print(f\"  Best validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"  Test AUC: {best_test_auc:.4f}\")\n",
        "    print(f\"  Test log loss: {best_test_logloss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "    # Create history plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['auc'], label='Train AUC')\n",
        "    plt.plot(history['val_auc'], label='Val AUC')\n",
        "    plt.axhline(y=best_test_auc, color='r', linestyle='--', label='Test AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('AUC Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.axhline(y=best_test_logloss, color='r', linestyle='--', label='Test LogLoss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('din_dice_training_history.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to CSV\n",
        "    if save_csv:\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame({\n",
        "            'epoch': range(1, len(history['loss']) + 1),\n",
        "            'train_loss': history['loss'],\n",
        "            'train_auc': history['auc'],\n",
        "            'val_loss': history['val_loss'],\n",
        "            'val_auc': history['val_auc'],\n",
        "        })\n",
        "\n",
        "        # Add test results only for best epoch\n",
        "        results_df['test_auc'] = np.nan\n",
        "        results_df['test_logloss'] = np.nan\n",
        "        results_df.loc[best_epoch, 'test_auc'] = best_test_auc\n",
        "        results_df.loc[best_epoch, 'test_logloss'] = best_test_logloss\n",
        "\n",
        "        results_df.to_csv('din_dice_training_results.csv', index=False)\n",
        "        print(f\"Training results saved to din_dice_training_results.csv\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'success': True,\n",
        "        'best_epoch': best_epoch + 1,\n",
        "        'best_val_auc': best_val_auc,\n",
        "        'best_test_auc': best_test_auc,\n",
        "        'best_test_logloss': best_test_logloss,\n",
        "        'history': {\n",
        "            'loss': history['loss'],\n",
        "            'auc': history['auc'],\n",
        "            'val_loss': history['val_loss'],\n",
        "            'val_auc': history['val_auc'],\n",
        "            'test_auc': best_test_auc,  # Just the final value\n",
        "            'test_logloss': best_test_logloss  # Just the final value\n",
        "        },\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "def manual_training_loop_din_prelu(model=None, batch_size=2048, epochs=15, early_stopping_patience=4, save_csv=False):\n",
        "    \"\"\"Custom training loop for DIN-PReLU model with test set evaluation only at the end\"\"\"\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"STARTING DIN-PReLU TRAINING:\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
        "    print(f\"  Test set evaluation: Only at end of training\")\n",
        "\n",
        "    # If no model is provided, use the global model\n",
        "    if model is None:\n",
        "        model = din_prelu_model\n",
        "\n",
        "    # Get data from global splits\n",
        "    train_x = {\n",
        "        'user_id': splits['train']['user_ids'],\n",
        "        'item_id': splits['train']['item_ids'],\n",
        "        'sequence': splits['train']['sequences'],\n",
        "        'seq_length': splits['train']['seq_lengths'],\n",
        "        'dense_features': splits['train']['dense_features']\n",
        "    }\n",
        "    val_x = {\n",
        "        'user_id': splits['val']['user_ids'],\n",
        "        'item_id': splits['val']['item_ids'],\n",
        "        'sequence': splits['val']['sequences'],\n",
        "        'seq_length': splits['val']['seq_lengths'],\n",
        "        'dense_features': splits['val']['dense_features']\n",
        "    }\n",
        "    test_x = {\n",
        "        'user_id': splits['test']['user_ids'],\n",
        "        'item_id': splits['test']['item_ids'],\n",
        "        'sequence': splits['test']['sequences'],\n",
        "        'seq_length': splits['test']['seq_lengths'],\n",
        "        'dense_features': splits['test']['dense_features']\n",
        "    }\n",
        "\n",
        "    train_y = splits['train']['labels'].flatten()\n",
        "    val_y = splits['val']['labels'].flatten()\n",
        "    test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "    # Setup optimizer, loss and metrics\n",
        "    optimizer = tf.keras.optimizers.Adam(clipnorm=0.5)\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "    train_loss_metric = tf.keras.metrics.Mean()\n",
        "    train_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "    val_loss_metric = tf.keras.metrics.Mean()\n",
        "    val_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "    # History tracking\n",
        "    history = {\n",
        "        'loss': [],\n",
        "        'auc': [],\n",
        "        'val_loss': [],\n",
        "        'val_auc': []\n",
        "    }\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_auc = 0.0\n",
        "    patience_counter = 0\n",
        "    best_epoch = 0\n",
        "    best_weights = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Reset metrics\n",
        "        train_loss_metric.reset_state()\n",
        "        train_auc_metric.reset_state()\n",
        "        val_loss_metric.reset_state()\n",
        "        val_auc_metric.reset_state()\n",
        "\n",
        "        # Training phase\n",
        "        n_train_batches = (len(train_y) + batch_size - 1) // batch_size\n",
        "        indices = np.random.permutation(len(train_y))\n",
        "\n",
        "        for batch_idx in range(n_train_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(train_y))\n",
        "            batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "            # Create batch\n",
        "            batch_x = {k: tf.convert_to_tensor(v[batch_indices]) for k, v in train_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(train_y[batch_indices])\n",
        "\n",
        "            # Training step\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = model(batch_x, training=True)\n",
        "                predictions = tf.squeeze(predictions)\n",
        "                loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "            # Apply gradients\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            # Update metrics\n",
        "            train_loss_metric.update_state(loss)\n",
        "            train_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # Print progress\n",
        "            if (batch_idx + 1) % 100 == 0:\n",
        "                print(f\"  Batch {batch_idx + 1}/{n_train_batches}\")\n",
        "\n",
        "        # Validation phase\n",
        "        n_val_batches = (len(val_y) + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in range(n_val_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(val_y))\n",
        "\n",
        "            # Create batch\n",
        "            batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in val_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(val_y[start_idx:end_idx])\n",
        "\n",
        "            # Validation step\n",
        "            predictions = model(batch_x, training=False)\n",
        "            predictions = tf.squeeze(predictions)\n",
        "            loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "            # Update metrics\n",
        "            val_loss_metric.update_state(loss)\n",
        "            val_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "        # Get epoch results\n",
        "        epoch_train_loss = train_loss_metric.result().numpy()\n",
        "        epoch_train_auc = train_auc_metric.result().numpy()\n",
        "        epoch_val_loss = val_loss_metric.result().numpy()\n",
        "        epoch_val_auc = val_auc_metric.result().numpy()\n",
        "\n",
        "        # Store history\n",
        "        history['loss'].append(epoch_train_loss)\n",
        "        history['auc'].append(epoch_train_auc)\n",
        "        history['val_loss'].append(epoch_val_loss)\n",
        "        history['val_auc'].append(epoch_val_auc)\n",
        "\n",
        "        # Print results (only train and validation)\n",
        "        print(f\"  Train Loss: {epoch_train_loss:.4f}, AUC: {epoch_train_auc:.4f}\")\n",
        "        print(f\"  Val   Loss: {epoch_val_loss:.4f}, AUC: {epoch_val_auc:.4f}\")\n",
        "\n",
        "        # Check early stopping\n",
        "        if epoch_val_auc > best_val_auc:\n",
        "            best_val_auc = epoch_val_auc\n",
        "            best_epoch = epoch\n",
        "            patience_counter = 0\n",
        "            best_weights = model.get_weights()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "            break\n",
        "\n",
        "    # Restore best weights\n",
        "    if best_weights is not None:\n",
        "        model.set_weights(best_weights)\n",
        "\n",
        "    # NOW EVALUATE ON TEST SET (only once, after training is complete)\n",
        "    print(f\"\\nTraining completed. Evaluating final model on test set...\")\n",
        "\n",
        "    test_auc_metric = tf.keras.metrics.AUC()\n",
        "    all_test_preds = []\n",
        "    all_test_labels = []\n",
        "\n",
        "    n_test_batches = (len(test_y) + batch_size - 1) // batch_size\n",
        "    for batch_idx in range(n_test_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min(start_idx + batch_size, len(test_y))\n",
        "\n",
        "        # Create batch\n",
        "        batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in test_x.items()}\n",
        "        batch_y = tf.convert_to_tensor(test_y[start_idx:end_idx])\n",
        "\n",
        "        # Test step\n",
        "        predictions = model(batch_x, training=False)\n",
        "        predictions = tf.squeeze(predictions)\n",
        "\n",
        "        # Update metrics\n",
        "        test_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "        # Store predictions for log loss calculation\n",
        "        all_test_preds.append(predictions.numpy())\n",
        "        all_test_labels.append(batch_y.numpy())\n",
        "\n",
        "    # Calculate test metrics\n",
        "    best_test_auc = test_auc_metric.result().numpy()\n",
        "    all_test_preds = np.concatenate(all_test_preds)\n",
        "    all_test_labels = np.concatenate(all_test_labels)\n",
        "    best_test_logloss = log_loss(all_test_labels, all_test_preds)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nFINAL RESULTS:\")\n",
        "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
        "    print(f\"  Best validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"  Test AUC: {best_test_auc:.4f}\")\n",
        "    print(f\"  Test log loss: {best_test_logloss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "    # Create history plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['auc'], label='Train AUC')\n",
        "    plt.plot(history['val_auc'], label='Val AUC')\n",
        "    plt.axhline(y=best_test_auc, color='r', linestyle='--', label='Test AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('AUC Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.axhline(y=best_test_logloss, color='r', linestyle='--', label='Test LogLoss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('din_prelu_training_history.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to CSV\n",
        "    if save_csv:\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame({\n",
        "            'epoch': range(1, len(history['loss']) + 1),\n",
        "            'train_loss': history['loss'],\n",
        "            'train_auc': history['auc'],\n",
        "            'val_loss': history['val_loss'],\n",
        "            'val_auc': history['val_auc'],\n",
        "        })\n",
        "\n",
        "        # Add test results only for best epoch\n",
        "        results_df['test_auc'] = np.nan\n",
        "        results_df['test_logloss'] = np.nan\n",
        "        results_df.loc[best_epoch, 'test_auc'] = best_test_auc\n",
        "        results_df.loc[best_epoch, 'test_logloss'] = best_test_logloss\n",
        "\n",
        "        results_df.to_csv('din_prelu_training_results.csv', index=False)\n",
        "        print(f\"Training results saved to din_prelu_training_results.csv\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'success': True,\n",
        "        'best_epoch': best_epoch + 1,\n",
        "        'best_val_auc': best_val_auc,\n",
        "        'best_test_auc': best_test_auc,\n",
        "        'best_test_logloss': best_test_logloss,\n",
        "        'history': {\n",
        "            'loss': history['loss'],\n",
        "            'auc': history['auc'],\n",
        "            'val_loss': history['val_loss'],\n",
        "            'val_auc': history['val_auc'],\n",
        "            'test_auc': best_test_auc,  # Just the final value\n",
        "            'test_logloss': best_test_logloss  # Just the final value\n",
        "        },\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "def create_deepfm_dataset():\n",
        "    \"\"\"Create dataset for DeepFM model\"\"\"\n",
        "    print(f\"Creating DeepFM dataset...\")\n",
        "\n",
        "    # Use global splits\n",
        "    deepfm_train_x = {\n",
        "        'user_id': splits['train']['user_ids'],\n",
        "        'item_id': splits['train']['item_ids'],\n",
        "        'dense_features': splits['train']['dense_features']\n",
        "    }\n",
        "    deepfm_val_x = {\n",
        "        'user_id': splits['val']['user_ids'],\n",
        "        'item_id': splits['val']['item_ids'],\n",
        "        'dense_features': splits['val']['dense_features']\n",
        "    }\n",
        "    deepfm_test_x = {\n",
        "        'user_id': splits['test']['user_ids'],\n",
        "        'item_id': splits['test']['item_ids'],\n",
        "        'dense_features': splits['test']['dense_features']\n",
        "    }\n",
        "\n",
        "    deepfm_train_y = splits['train']['labels'].flatten()\n",
        "    deepfm_val_y = splits['val']['labels'].flatten()\n",
        "    deepfm_test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "    # Return dataset\n",
        "    return {\n",
        "        'train_x': deepfm_train_x,\n",
        "        'train_y': deepfm_train_y,\n",
        "        'val_x': deepfm_val_x,\n",
        "        'val_y': deepfm_val_y,\n",
        "        'test_x': deepfm_test_x,\n",
        "        'test_y': deepfm_test_y\n",
        "    }\n",
        "\n",
        "def train_deepfm_model(model=None, batch_size=2048, epochs=15, early_stopping_patience=4, save_csv=False):\n",
        "    \"\"\"Train DeepFM model with test set evaluation only at the end\"\"\"\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"STARTING DEEPFM TRAINING:\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
        "    print(f\"  Test set evaluation: Only at end of training\")\n",
        "\n",
        "    # If no model is provided, use the global model\n",
        "    if model is None:\n",
        "        model = deepfm_model\n",
        "\n",
        "    # Get dataset\n",
        "    dataset = create_deepfm_dataset()\n",
        "\n",
        "    # Create custom callback to avoid test set evaluation during training\n",
        "    class NoTestCallback(tf.keras.callbacks.Callback):\n",
        "        def __init__(self):\n",
        "            super(NoTestCallback, self).__init__()\n",
        "            self.best_val_auc = 0\n",
        "            self.best_weights = None\n",
        "            self.patience_counter = 0\n",
        "            self.best_epoch = 0\n",
        "            self.patience = early_stopping_patience\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            current_val_auc = logs.get('val_auc')\n",
        "            if current_val_auc > self.best_val_auc:\n",
        "                self.best_val_auc = current_val_auc\n",
        "                self.best_epoch = epoch\n",
        "                self.patience_counter = 0\n",
        "                self.best_weights = self.model.get_weights()\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            if self.patience_counter >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "\n",
        "        def on_train_end(self, logs=None):\n",
        "            # Restore best weights\n",
        "            if self.best_weights is not None:\n",
        "                self.model.set_weights(self.best_weights)\n",
        "                print(f\"Restored best weights from epoch {self.best_epoch + 1}\")\n",
        "\n",
        "    # Custom callback\n",
        "    no_test_callback = NoTestCallback()\n",
        "\n",
        "    # Fit model\n",
        "    history = model.fit(\n",
        "        x=dataset['train_x'],\n",
        "        y=dataset['train_y'],\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(dataset['val_x'], dataset['val_y']),\n",
        "        callbacks=[no_test_callback],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # NOW EVALUATE ON TEST SET (only once, after training is complete)\n",
        "    print(f\"\\nTraining completed. Evaluating final model on test set...\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_results = model.evaluate(\n",
        "        x=dataset['test_x'],\n",
        "        y=dataset['test_y'],\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Calculate test log loss\n",
        "    test_preds = model.predict(dataset['test_x'], batch_size=batch_size)\n",
        "    test_logloss = log_loss(dataset['test_y'], test_preds)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Get best values\n",
        "    best_epoch = no_test_callback.best_epoch\n",
        "    best_val_auc = no_test_callback.best_val_auc\n",
        "    best_test_auc = test_results[1]  # AUC is the second metric\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nFINAL RESULTS:\")\n",
        "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
        "    print(f\"  Best validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"  Test AUC: {best_test_auc:.4f}\")\n",
        "    print(f\"  Test Log Loss: {test_logloss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "    # Create history plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['auc'], label='Train AUC')\n",
        "    plt.plot(history.history['val_auc'], label='Val AUC')\n",
        "    plt.axhline(y=best_test_auc, color='r', linestyle='--', label='Test AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('AUC Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.axhline(y=test_logloss, color='r', linestyle='--', label='Test LogLoss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('deepfm_training_history.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to CSV\n",
        "    if save_csv:\n",
        "        # Create results DataFrame\n",
        "        epochs_completed = len(history.history['loss'])\n",
        "        results_df = pd.DataFrame({\n",
        "            'epoch': range(1, epochs_completed + 1),\n",
        "            'train_loss': history.history['loss'],\n",
        "            'train_auc': history.history['auc'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'val_auc': history.history['val_auc']\n",
        "        })\n",
        "\n",
        "        # Add test results only for best epoch\n",
        "        results_df['test_auc'] = np.nan\n",
        "        results_df['test_logloss'] = np.nan\n",
        "        results_df.loc[best_epoch, 'test_auc'] = best_test_auc\n",
        "        results_df.loc[best_epoch, 'test_logloss'] = test_logloss\n",
        "\n",
        "        results_df.to_csv('deepfm_training_results.csv', index=False)\n",
        "        print(f\"Training results saved to deepfm_training_results.csv\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'success': True,\n",
        "        'best_epoch': best_epoch + 1,\n",
        "        'best_val_auc': best_val_auc,\n",
        "        'best_test_auc': best_test_auc,\n",
        "        'best_test_logloss': test_logloss,\n",
        "        'history': {\n",
        "            'loss': history.history['loss'],\n",
        "            'auc': history.history['auc'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'val_auc': history.history['val_auc'],\n",
        "            'test_auc': best_test_auc,  # Just the final value\n",
        "            'test_logloss': test_logloss  # Just the final value\n",
        "        },\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "def create_baseline_dataset():\n",
        "    \"\"\"Create dataset for Baseline model\"\"\"\n",
        "    print(f\"Creating Baseline dataset...\")\n",
        "\n",
        "    # Use global splits\n",
        "    baseline_train_x = {\n",
        "        'user_id': splits['train']['user_ids'],\n",
        "        'item_id': splits['train']['item_ids'],\n",
        "        'dense_features': splits['train']['dense_features']\n",
        "    }\n",
        "    baseline_val_x = {\n",
        "        'user_id': splits['val']['user_ids'],\n",
        "        'item_id': splits['val']['item_ids'],\n",
        "        'dense_features': splits['val']['dense_features']\n",
        "    }\n",
        "    baseline_test_x = {\n",
        "        'user_id': splits['test']['user_ids'],\n",
        "        'item_id': splits['test']['item_ids'],\n",
        "        'dense_features': splits['test']['dense_features']\n",
        "    }\n",
        "\n",
        "    baseline_train_y = splits['train']['labels'].flatten()\n",
        "    baseline_val_y = splits['val']['labels'].flatten()\n",
        "    baseline_test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "    # Return dataset\n",
        "    return {\n",
        "        'train_x': baseline_train_x,\n",
        "        'train_y': baseline_train_y,\n",
        "        'val_x': baseline_val_x,\n",
        "        'val_y': baseline_val_y,\n",
        "        'test_x': baseline_test_x,\n",
        "        'test_y': baseline_test_y\n",
        "    }\n",
        "\n",
        "def train_baseline_model(model=None, batch_size=2048, epochs=15, early_stopping_patience=4, save_csv=False):\n",
        "    \"\"\"Train Baseline model with test set evaluation only at the end\"\"\"\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"STARTING BASELINE TRAINING:\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
        "    print(f\"  Test set evaluation: Only at end of training\")\n",
        "\n",
        "    # If no model is provided, use the global model\n",
        "    if model is None:\n",
        "        model = baseline_model\n",
        "\n",
        "    # Get dataset\n",
        "    dataset = create_baseline_dataset()\n",
        "\n",
        "    # Create custom callback to avoid test set evaluation during training\n",
        "    class NoTestCallback(tf.keras.callbacks.Callback):\n",
        "        def __init__(self):\n",
        "            super(NoTestCallback, self).__init__()\n",
        "            self.best_val_auc = 0\n",
        "            self.best_weights = None\n",
        "            self.patience_counter = 0\n",
        "            self.best_epoch = 0\n",
        "            self.patience = early_stopping_patience\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            current_val_auc = logs.get('val_auc')\n",
        "            if current_val_auc > self.best_val_auc:\n",
        "                self.best_val_auc = current_val_auc\n",
        "                self.best_epoch = epoch\n",
        "                self.patience_counter = 0\n",
        "                self.best_weights = self.model.get_weights()\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            if self.patience_counter >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "\n",
        "        def on_train_end(self, logs=None):\n",
        "            # Restore best weights\n",
        "            if self.best_weights is not None:\n",
        "                self.model.set_weights(self.best_weights)\n",
        "                print(f\"Restored best weights from epoch {self.best_epoch + 1}\")\n",
        "\n",
        "    # Custom callback\n",
        "    no_test_callback = NoTestCallback()\n",
        "\n",
        "    # Fit model\n",
        "    history = model.fit(\n",
        "        x=dataset['train_x'],\n",
        "        y=dataset['train_y'],\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(dataset['val_x'], dataset['val_y']),\n",
        "        callbacks=[no_test_callback],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # NOW EVALUATE ON TEST SET (only once, after training is complete)\n",
        "    print(f\"\\nTraining completed. Evaluating final model on test set...\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_results = model.evaluate(\n",
        "        x=dataset['test_x'],\n",
        "        y=dataset['test_y'],\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Calculate test log loss\n",
        "    test_preds = model.predict(dataset['test_x'], batch_size=batch_size)\n",
        "    test_logloss = log_loss(dataset['test_y'], test_preds)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Get best values\n",
        "    best_epoch = no_test_callback.best_epoch\n",
        "    best_val_auc = no_test_callback.best_val_auc\n",
        "    best_test_auc = test_results[1]  # AUC is the second metric\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nFINAL RESULTS:\")\n",
        "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
        "    print(f\"  Best validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"  Test AUC: {best_test_auc:.4f}\")\n",
        "    print(f\"  Test Log Loss: {test_logloss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "    # Create history plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['auc'], label='Train AUC')\n",
        "    plt.plot(history.history['val_auc'], label='Val AUC')\n",
        "    plt.axhline(y=best_test_auc, color='r', linestyle='--', label='Test AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('AUC Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.axhline(y=test_logloss, color='r', linestyle='--', label='Test LogLoss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('baseline_training_history.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to CSV\n",
        "    if save_csv:\n",
        "        # Create results DataFrame\n",
        "        epochs_completed = len(history.history['loss'])\n",
        "        results_df = pd.DataFrame({\n",
        "            'epoch': range(1, epochs_completed + 1),\n",
        "            'train_loss': history.history['loss'],\n",
        "            'train_auc': history.history['auc'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'val_auc': history.history['val_auc']\n",
        "        })\n",
        "\n",
        "        # Add test results only for best epoch\n",
        "        results_df['test_auc'] = np.nan\n",
        "        results_df['test_logloss'] = np.nan\n",
        "        results_df.loc[best_epoch, 'test_auc'] = best_test_auc\n",
        "        results_df.loc[best_epoch, 'test_logloss'] = test_logloss\n",
        "\n",
        "        results_df.to_csv('baseline_training_results.csv', index=False)\n",
        "        print(f\"Training results saved to baseline_training_results.csv\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'success': True,\n",
        "        'best_epoch': best_epoch + 1,\n",
        "        'best_val_auc': best_val_auc,\n",
        "        'best_test_auc': best_test_auc,\n",
        "        'best_test_logloss': test_logloss,\n",
        "        'history': {\n",
        "            'loss': history.history['loss'],\n",
        "            'auc': history.history['auc'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'val_auc': history.history['val_auc'],\n",
        "            'test_auc': best_test_auc,  # Just the final value\n",
        "            'test_logloss': test_logloss  # Just the final value\n",
        "        },\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "print(f\"Training functions defined successfully!\")"
      ],
      "metadata": {
        "id": "WDMS2kAgimRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5821627d-ce41-42fd-b022-ed1b03d6af58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING FUNCTIONS DEFINITIONS\n",
            "============================================================\n",
            "Training functions defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna -q"
      ],
      "metadata": {
        "id": "nV_CWrXdh0hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2799e9-2be5-4675-be53-f7ea026b6cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/242.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6F-OPTUNA: HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import random\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "import optuna  # Import optuna library\n",
        "\n",
        "class ModelTuner:\n",
        "    \"\"\"Framework untuk hyperparameter tuning dengan evaluasi di validation dan test set\"\"\"\n",
        "\n",
        "    def __init__(self, model_type, model_data, subsample_fraction=None, random_seed=42,\n",
        "                 save_dir='tuning_results', current_user=\"heryyy\", current_time=\"-\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_type: String ('DIN-DICE', 'DIN-PReLU', 'DeepFM', 'Baseline')\n",
        "            model_data: Dictionary dengan train, val, test datasets\n",
        "            subsample_fraction: Fraksi data training yang digunakan untuk tuning (None = full dataset)\n",
        "            random_seed: Random seed untuk subsample reproducibility\n",
        "            save_dir: Direktori untuk menyimpan hasil tuning\n",
        "        \"\"\"\n",
        "        self.model_type = model_type\n",
        "        self.original_model_data = model_data\n",
        "        self.subsample_fraction = subsample_fraction\n",
        "        self.random_seed = random_seed\n",
        "        self.save_dir = save_dir\n",
        "        self.results = []\n",
        "        self.best_params = None\n",
        "        self.best_val_auc = 0\n",
        "        self.best_test_auc = 0\n",
        "        self.best_test_logloss = float('inf')\n",
        "        self.current_user = current_user\n",
        "        self.current_time = current_time\n",
        "        self.optuna_study = None\n",
        "\n",
        "        # Buat direktori jika belum ada\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # CSV file untuk tracking hasil trial\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.csv_path = os.path.join(save_dir, f'{model_type}_tuning_results_{timestamp}.csv')\n",
        "\n",
        "        # Inisialisasi parameter search space\n",
        "        self._init_search_space()\n",
        "\n",
        "        # Siapkan data (subsampled jika diperlukan)\n",
        "        self.model_data = self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        \"\"\"Prepare data for tuning - create subsample if requested\"\"\"\n",
        "        if self.subsample_fraction is None or self.subsample_fraction >= 1.0:\n",
        "            return self.original_model_data\n",
        "\n",
        "        # Create subsample dari data training\n",
        "        subsampled_data = {\n",
        "            'splits': {\n",
        "                'train': {},\n",
        "                'val': self.original_model_data['splits']['val'],\n",
        "                'test': self.original_model_data['splits']['test']\n",
        "            },\n",
        "            'model_params': self.original_model_data['model_params']\n",
        "        }\n",
        "\n",
        "        # Ambil info dari data training\n",
        "        train_data = self.original_model_data['splits']['train']\n",
        "        n_samples = len(train_data['labels'])\n",
        "        subsample_size = int(n_samples * self.subsample_fraction)\n",
        "\n",
        "        print(f\"Creating {self.subsample_fraction*100:.1f}% subsample of training data...\")\n",
        "        print(f\"  Original training samples: {n_samples:,}\")\n",
        "        print(f\"  Subsampled training size: {subsample_size:,}\")\n",
        "\n",
        "        # Set random seed untuk reproducibility\n",
        "        np.random.seed(self.random_seed)\n",
        "\n",
        "        # Generate random indices\n",
        "        indices = np.random.choice(n_samples, subsample_size, replace=False)\n",
        "        indices.sort()  # Sort untuk efisiensi akses\n",
        "\n",
        "        # Subsample setiap komponen data training\n",
        "        for key, value in train_data.items():\n",
        "            if isinstance(value, np.ndarray):\n",
        "                subsampled_data['splits']['train'][key] = value[indices]\n",
        "            elif isinstance(value, list):\n",
        "                subsampled_data['splits']['train'][key] = [value[i] for i in indices]\n",
        "            else:\n",
        "                # Copy langsung jika bukan array atau list\n",
        "                subsampled_data['splits']['train'][key] = value\n",
        "\n",
        "        # Verifikasi hasil subsample\n",
        "        orig_pos_rate = np.mean(train_data['labels'])\n",
        "        new_pos_rate = np.mean(subsampled_data['splits']['train']['labels'])\n",
        "\n",
        "        print(f\"  Original positive rate: {orig_pos_rate:.4f}\")\n",
        "        print(f\"  Subsampled positive rate: {new_pos_rate:.4f}\")\n",
        "        print(f\"âœ… Subsample created successfully\")\n",
        "\n",
        "        return subsampled_data\n",
        "\n",
        "    def _init_search_space(self):\n",
        "        \"\"\"Inisialisasi search space berdasarkan tipe model\"\"\"\n",
        "        if self.model_type == 'DIN-DICE':\n",
        "            self.search_space = {\n",
        "                'learning_rate': [1e-4, 5e-5, 1e-5],\n",
        "                'batch_size': [2048, 4096, 8192],\n",
        "                'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
        "                'l2_reg': [1e-4, 5e-5, 1e-5],\n",
        "                'l2_dense': [1e-4, 5e-5, 1e-5],\n",
        "                'dice_alpha_init': [0.3, 0.4, 0.5],\n",
        "                'dice_beta_init': [1.0, 1.5, 2.0],\n",
        "                'dice_epsilon': [1e-8, 1e-9, 1e-10],\n",
        "                'attention_hidden': [8, 16, 32],\n",
        "                'label_smoothing': [0.0, 0.1, 0.2]\n",
        "            }\n",
        "        elif self.model_type == 'DIN-PReLU':\n",
        "            self.search_space = {\n",
        "                'learning_rate': [1e-4, 5e-5, 1e-5],\n",
        "                'batch_size': [2048, 4096, 8192],\n",
        "                'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
        "                'l2_reg': [1e-4, 5e-5, 1e-5],\n",
        "                'l2_dense': [1e-4, 5e-5, 1e-5],\n",
        "                'prelu_alpha_init': [0.2, 0.3, 0.4],\n",
        "                'attention_hidden': [8, 16, 32],\n",
        "                'label_smoothing': [0.0, 0.1, 0.2]\n",
        "            }\n",
        "        elif self.model_type == 'DeepFM':\n",
        "            self.search_space = {\n",
        "                'learning_rate': [1e-3, 1e-4, 5e-5],\n",
        "                'batch_size': [2048, 4096, 8192],\n",
        "                'dropout_rate': [0.3, 0.5, 0.7],\n",
        "                'l2_reg': [1e-3, 1e-4, 1e-5],\n",
        "                'l2_dense': [1e-3, 1e-4, 1e-5],\n",
        "                'hidden_units': [[128, 64, 32], [256, 128, 64], [64, 32, 16]],\n",
        "                'label_smoothing': [0.0, 0.1, 0.2]\n",
        "            }\n",
        "        elif self.model_type == 'Baseline':\n",
        "            self.search_space = {\n",
        "                'learning_rate': [1e-3, 1e-4, 5e-5],\n",
        "                'batch_size': [2048, 4096, 8192],\n",
        "                'dropout_rate': [0.3, 0.5, 0.7],\n",
        "                'l2_reg': [1e-3, 1e-4, 1e-5],\n",
        "                'l2_dense': [1e-3, 1e-4, 1e-5],\n",
        "                'hidden_units': [[128, 64], [64, 32], [256, 128]],\n",
        "                'label_smoothing': [0.0, 0.1, 0.2]\n",
        "            }\n",
        "        else:\n",
        "            raise ValueError(f\"Model type {self.model_type} not supported\")\n",
        "\n",
        "    # Optuna objective function\n",
        "    def _optuna_objective(self, trial):\n",
        "        \"\"\"Objective function for Optuna optimization using only categorical parameters\"\"\"\n",
        "        # Sample hyperparameters using Optuna's categorical API\n",
        "        if self.model_type == 'DIN-DICE':\n",
        "        # Sample hyperparameters using Optuna's categorical API\n",
        "            hidden_units_options = [\n",
        "                [64, 32],        # Dangkal, Sempit\n",
        "                [128, 64],       # Dangkal, Sedang\n",
        "                [256, 128],      # Dangkal, Lebar\n",
        "                [128, 64, 32]    # Dalam, Sedang\n",
        "            ]\n",
        "            hidden_units_idx = trial.suggest_categorical('hidden_units_idx', list(range(len(hidden_units_options))))\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [2048, 4096, 8192]),\n",
        "                'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.4, 0.5, 0.6]),\n",
        "                'l2_reg': trial.suggest_categorical('l2_reg', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'l2_dense': trial.suggest_categorical('l2_dense', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'dice_alpha_init': trial.suggest_categorical('dice_alpha_init', [0.3, 0.35, 0.4, 0.45, 0.5]),\n",
        "                'dice_beta_init': trial.suggest_categorical('dice_beta_init', [1.0, 1.2, 1.5, 1.8, 2.0]),\n",
        "                'dice_epsilon': trial.suggest_categorical('dice_epsilon', [1e-8, 1e-9, 1e-10]),\n",
        "                'attention_hidden': trial.suggest_categorical('attention_hidden', [8, 16, 32]),\n",
        "                'label_smoothing': trial.suggest_categorical('label_smoothing', [0.0, 0.05, 0.1, 0.15, 0.2]),\n",
        "                'hidden_units': hidden_units_options[hidden_units_idx]\n",
        "            }\n",
        "        elif self.model_type == 'DIN-PReLU':\n",
        "            hidden_units_options = [\n",
        "                [64, 32],        # Dangkal, Sempit\n",
        "                [128, 64],       # Dangkal, Sedang\n",
        "                [256, 128],      # Dangkal, Lebar\n",
        "                [128, 64, 32]    # Dalam, Sedang\n",
        "            ]\n",
        "            hidden_units_idx = trial.suggest_categorical('hidden_units_idx', list(range(len(hidden_units_options))))\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [2048, 4096, 8192]),\n",
        "                'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.4, 0.5, 0.6]),\n",
        "                'l2_reg': trial.suggest_categorical('l2_reg', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'l2_dense': trial.suggest_categorical('l2_dense', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'prelu_alpha_init': trial.suggest_categorical('prelu_alpha_init', [0.2, 0.25, 0.3, 0.35, 0.4]),\n",
        "                'attention_hidden': trial.suggest_categorical('attention_hidden', [8, 16, 32]),\n",
        "                'label_smoothing': trial.suggest_categorical('label_smoothing', [0.0, 0.05, 0.1, 0.15, 0.2]),\n",
        "                'hidden_units': hidden_units_options[hidden_units_idx]\n",
        "            }\n",
        "        elif self.model_type == 'DeepFM':\n",
        "            hidden_units_options = [[128, 64, 32], [256, 128, 64], [64, 32, 16]]\n",
        "            hidden_units_idx = trial.suggest_categorical('hidden_units_idx', list(range(len(hidden_units_options))))\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [2048, 4096, 8192]),\n",
        "                'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.4, 0.5, 0.6, 0.7]),\n",
        "                'l2_reg': trial.suggest_categorical('l2_reg', [1e-5, 1e-4, 1e-3]),\n",
        "                'l2_dense': trial.suggest_categorical('l2_dense', [1e-5, 1e-4, 1e-3]),\n",
        "                'hidden_units': hidden_units_options[hidden_units_idx],\n",
        "                'label_smoothing': trial.suggest_categorical('label_smoothing', [0.0, 0.05, 0.1, 0.15, 0.2]),\n",
        "            }\n",
        "        elif self.model_type == 'Baseline':\n",
        "            hidden_units_options = [[128, 64], [64, 32], [256, 128]]\n",
        "            hidden_units_idx = trial.suggest_categorical('hidden_units_idx', list(range(len(hidden_units_options))))\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [2048, 4096, 8192]),\n",
        "                'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.4, 0.5, 0.6, 0.7]),\n",
        "                'l2_reg': trial.suggest_categorical('l2_reg', [1e-5, 1e-4, 1e-3]),\n",
        "                'l2_dense': trial.suggest_categorical('l2_dense', [1e-5, 1e-4, 1e-3]),\n",
        "                'hidden_units': hidden_units_options[hidden_units_idx],\n",
        "                'label_smoothing': trial.suggest_categorical('label_smoothing', [0.0, 0.05, 0.1, 0.15, 0.2])\n",
        "            }\n",
        "\n",
        "        # Run trial with these parameters\n",
        "        trial_results = self.run_trial(params)\n",
        "\n",
        "        # Return validation AUC for Optuna to maximize\n",
        "        if 'val_auc' not in trial_results:\n",
        "            return 0.0  # In case of error\n",
        "\n",
        "        return trial_results['val_auc']\n",
        "\n",
        "    def _sample_hyperparameters(self):\n",
        "        \"\"\"Sample hyperparameters dari search space\"\"\"\n",
        "        params = {}\n",
        "        for param_name, param_values in self.search_space.items():\n",
        "            params[param_name] = random.choice(param_values)\n",
        "        return params\n",
        "\n",
        "    def run_trial(self, params=None):\n",
        "        \"\"\"Run single tuning trial dengan parameter tertentu\"\"\"\n",
        "        if params is None:\n",
        "            params = self._sample_hyperparameters()\n",
        "\n",
        "        # Add subsample info to output if applicable\n",
        "        subsample_info = \"\"\n",
        "        if self.subsample_fraction is not None and self.subsample_fraction < 1.0:\n",
        "            subsample_info = f\" (USING {self.subsample_fraction*100:.1f}% DATA)\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"RUNNING TRIAL FOR {self.model_type}{subsample_info}\")\n",
        "        print(f\"Parameters: {params}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Create model\n",
        "        try:\n",
        "            # Setup data\n",
        "            splits = self.model_data['splits']\n",
        "\n",
        "            # Prepare data berdasarkan tipe model\n",
        "            if self.model_type in ['DIN-DICE', 'DIN-PReLU']:\n",
        "                # DIN membutuhkan sequence\n",
        "                train_x = {\n",
        "                    'user_id': splits['train']['user_ids'],\n",
        "                    'item_id': splits['train']['item_ids'],\n",
        "                    'sequence': splits['train']['sequences'],\n",
        "                    'seq_length': splits['train']['seq_lengths'],\n",
        "                    'dense_features': splits['train']['dense_features']\n",
        "                }\n",
        "                val_x = {\n",
        "                    'user_id': splits['val']['user_ids'],\n",
        "                    'item_id': splits['val']['item_ids'],\n",
        "                    'sequence': splits['val']['sequences'],\n",
        "                    'seq_length': splits['val']['seq_lengths'],\n",
        "                    'dense_features': splits['val']['dense_features']\n",
        "                }\n",
        "                test_x = {\n",
        "                    'user_id': splits['test']['user_ids'],\n",
        "                    'item_id': splits['test']['item_ids'],\n",
        "                    'sequence': splits['test']['sequences'],\n",
        "                    'seq_length': splits['test']['seq_lengths'],\n",
        "                    'dense_features': splits['test']['dense_features']\n",
        "                }\n",
        "            else:\n",
        "                # DeepFM dan Baseline tidak membutuhkan sequence\n",
        "                train_x = {\n",
        "                    'user_id': splits['train']['user_ids'],\n",
        "                    'item_id': splits['train']['item_ids'],\n",
        "                    'dense_features': splits['train']['dense_features']\n",
        "                }\n",
        "                val_x = {\n",
        "                    'user_id': splits['val']['user_ids'],\n",
        "                    'item_id': splits['val']['item_ids'],\n",
        "                    'dense_features': splits['val']['dense_features']\n",
        "                }\n",
        "                test_x = {\n",
        "                    'user_id': splits['test']['user_ids'],\n",
        "                    'item_id': splits['test']['item_ids'],\n",
        "                    'dense_features': splits['test']['dense_features']\n",
        "                }\n",
        "\n",
        "            train_y = splits['train']['labels'].flatten()\n",
        "            val_y = splits['val']['labels'].flatten()\n",
        "            test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "            # Create and compile model\n",
        "            if self.model_type == 'DIN-DICE':\n",
        "                model = self._create_din_dice_model(params)\n",
        "            elif self.model_type == 'DIN-PReLU':\n",
        "                model = self._create_din_prelu_model(params)\n",
        "            elif self.model_type == 'DeepFM':\n",
        "                model = self._create_deepfm_model(params)\n",
        "            elif self.model_type == 'Baseline':\n",
        "                model = self._create_baseline_model(params)\n",
        "            else:\n",
        "                raise ValueError(f\"Model type {self.model_type} not supported\")\n",
        "\n",
        "            # Compile model\n",
        "            label_smoothing = params['label_smoothing']\n",
        "            learning_rate = params['learning_rate']\n",
        "\n",
        "            optimizer = tf.keras.optimizers.Adam(\n",
        "                learning_rate=learning_rate,\n",
        "                clipnorm=0.5\n",
        "            )\n",
        "            loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "            metrics = [tf.keras.metrics.AUC(name='auc')]\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            # Callbacks\n",
        "            early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_auc',\n",
        "                patience=3,\n",
        "                mode='max',\n",
        "                restore_best_weights=True\n",
        "            )\n",
        "\n",
        "            # Train model\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Custom training loop atau keras fit\n",
        "            if self.model_type in ['DIN-DICE', 'DIN-PReLU']:\n",
        "                # Truncated custom training loop for tuning\n",
        "                val_auc, test_auc, test_logloss, history = self._train_din_custom(\n",
        "                    model, train_x, train_y, val_x, val_y, test_x, test_y, params\n",
        "                )\n",
        "            else:\n",
        "                # Standard Keras training untuk DeepFM dan Baseline\n",
        "                batch_size = params['batch_size']\n",
        "\n",
        "                history = model.fit(\n",
        "                    x=train_x,\n",
        "                    y=train_y,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=8,  # Kurangi epochs untuk tuning\n",
        "                    validation_data=(val_x, val_y),\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "                # Evaluasi pada validation set\n",
        "                val_result = model.evaluate(val_x, val_y, verbose=0)\n",
        "                val_auc = val_result[1]  # Indeks 1 adalah AUC\n",
        "\n",
        "                # Evaluasi pada test set (PENTING: ini hanya untuk tracking)\n",
        "                test_result = model.evaluate(test_x, test_y, verbose=0)\n",
        "                test_auc = test_result[1]  # Indeks 1 adalah AUC\n",
        "\n",
        "                # Calculate log loss on test set\n",
        "                test_pred = model.predict(test_x, batch_size=batch_size, verbose=0)\n",
        "                test_pred = test_pred.flatten()\n",
        "                test_logloss = log_loss(test_y, test_pred)\n",
        "\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            # Capture results\n",
        "            trial_results = {\n",
        "                'model_type': self.model_type,\n",
        "                'trial_time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                'val_auc': val_auc,\n",
        "                'test_auc': test_auc,\n",
        "                'test_logloss': test_logloss,\n",
        "                'training_time': training_time,\n",
        "                'subsample_fraction': self.subsample_fraction,\n",
        "                **params  # Include all hyperparameters\n",
        "            }\n",
        "\n",
        "            # Add to results list\n",
        "            self.results.append(trial_results)\n",
        "\n",
        "            # Check if this is the best model (based on validation AUC)\n",
        "            if val_auc > self.best_val_auc:\n",
        "                self.best_val_auc = val_auc\n",
        "                self.best_test_auc = test_auc\n",
        "                self.best_test_logloss = test_logloss\n",
        "                self.best_params = params.copy()\n",
        "\n",
        "                print(f\"\\nâœ… NEW BEST MODEL!\")\n",
        "                print(f\"Validation AUC: {self.best_val_auc:.4f}\")\n",
        "                print(f\"Test AUC: {self.best_test_auc:.4f}\")\n",
        "                print(f\"Test Log Loss: {self.best_test_logloss:.4f}\")\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.DataFrame(self.results)\n",
        "            results_df.to_csv(self.csv_path, index=False)\n",
        "\n",
        "            print(f\"\\nTRIAL RESULTS:\")\n",
        "            print(f\"Validation AUC: {val_auc:.4f}\")\n",
        "            print(f\"Test AUC: {test_auc:.4f}\")\n",
        "            print(f\"Test Log Loss: {test_logloss:.4f}\")\n",
        "            print(f\"Training Time: {training_time:.1f}s\")\n",
        "            print(f\"Results saved to {self.csv_path}\")\n",
        "\n",
        "            return trial_results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error in trial: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Log failed trial\n",
        "            trial_results = {\n",
        "                'model_type': self.model_type,\n",
        "                'trial_time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                'error': str(e),\n",
        "                'status': 'failed',\n",
        "                'subsample_fraction': self.subsample_fraction,\n",
        "                **params  # Include all hyperparameters\n",
        "            }\n",
        "\n",
        "            self.results.append(trial_results)\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.DataFrame(self.results)\n",
        "            results_df.to_csv(self.csv_path, index=False)\n",
        "\n",
        "            return trial_results\n",
        "\n",
        "    def _train_din_custom(self, model, train_x, train_y, val_x, val_y, test_x, test_y, params):\n",
        "        \"\"\"Simplified custom training loop for DIN models during tuning\"\"\"\n",
        "        # TRUNCATED VERSION FOR TUNING - fewer epochs and simplified\n",
        "        batch_size = params['batch_size']\n",
        "        epochs = 8  # Reduced for tuning\n",
        "\n",
        "        # Set up optimizer and loss\n",
        "        learning_rate = params['learning_rate']\n",
        "        label_smoothing = params['label_smoothing']\n",
        "\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=0.5)\n",
        "        loss_fn = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "\n",
        "        # Metrics\n",
        "        train_loss_metric = tf.keras.metrics.Mean()\n",
        "        train_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "        val_loss_metric = tf.keras.metrics.Mean()\n",
        "        val_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "        # History tracking\n",
        "        history = {\n",
        "            'loss': [],\n",
        "            'auc': [],\n",
        "            'val_loss': [],\n",
        "            'val_auc': []\n",
        "        }\n",
        "\n",
        "        # Early stopping tracking\n",
        "        best_val_auc = 0.0\n",
        "        patience_counter = 0\n",
        "        best_weights = None\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "            # Reset metrics\n",
        "            train_loss_metric.reset_state()\n",
        "            train_auc_metric.reset_state()\n",
        "            val_loss_metric.reset_state()\n",
        "            val_auc_metric.reset_state()\n",
        "\n",
        "            # TRAINING PHASE\n",
        "            n_train_batches = (len(train_y) + batch_size - 1) // batch_size\n",
        "            indices = np.random.permutation(len(train_y))\n",
        "\n",
        "            for batch_idx in range(n_train_batches):\n",
        "                start_idx = batch_idx * batch_size\n",
        "                end_idx = min(start_idx + batch_size, len(train_y))\n",
        "                batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "                batch_x = {k: tf.convert_to_tensor(v[batch_indices]) for k, v in train_x.items()}\n",
        "                batch_y = tf.convert_to_tensor(train_y[batch_indices])\n",
        "\n",
        "                with tf.GradientTape() as tape:\n",
        "                    predictions = model(batch_x, training=True)\n",
        "                    predictions = tf.squeeze(predictions)\n",
        "                    loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "                gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "                # Update metrics\n",
        "                train_loss_metric.update_state(loss)\n",
        "                train_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # VALIDATION PHASE\n",
        "            n_val_batches = (len(val_y) + batch_size - 1) // batch_size\n",
        "\n",
        "            for batch_idx in range(n_val_batches):\n",
        "                start_idx = batch_idx * batch_size\n",
        "                end_idx = min(start_idx + batch_size, len(val_y))\n",
        "\n",
        "                batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in val_x.items()}\n",
        "                batch_y = tf.convert_to_tensor(val_y[start_idx:end_idx])\n",
        "\n",
        "                predictions = model(batch_x, training=False)\n",
        "                predictions = tf.squeeze(predictions)\n",
        "                loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "                val_loss_metric.update_state(loss)\n",
        "                val_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # Get epoch results\n",
        "            epoch_train_loss = train_loss_metric.result().numpy()\n",
        "            epoch_train_auc = train_auc_metric.result().numpy()\n",
        "            epoch_val_loss = val_loss_metric.result().numpy()\n",
        "            epoch_val_auc = val_auc_metric.result().numpy()\n",
        "\n",
        "            # Store history\n",
        "            history['loss'].append(epoch_train_loss)\n",
        "            history['auc'].append(epoch_train_auc)\n",
        "            history['val_loss'].append(epoch_val_loss)\n",
        "            history['val_auc'].append(epoch_val_auc)\n",
        "\n",
        "            # Print results (only train and validation metrics)\n",
        "            print(f\"  Train - Loss: {epoch_train_loss:.4f}, AUC: {epoch_train_auc:.4f}\")\n",
        "            print(f\"  Val   - Loss: {epoch_val_loss:.4f}, AUC: {epoch_val_auc:.4f}\")\n",
        "\n",
        "            # Check early stopping\n",
        "            if epoch_val_auc > best_val_auc:\n",
        "                best_val_auc = epoch_val_auc\n",
        "                patience_counter = 0\n",
        "                best_weights = model.get_weights()\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= 3:  # Lower patience for tuning\n",
        "                print(f\"  Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "        # Restore best weights\n",
        "        if best_weights is not None:\n",
        "            model.set_weights(best_weights)\n",
        "\n",
        "        # Final evaluation\n",
        "        # Get final validation AUC\n",
        "        final_val_auc = best_val_auc\n",
        "\n",
        "        # ONLY NOW evaluate on test set (after training is complete)\n",
        "        print(f\"  Evaluating on test set...\")\n",
        "        test_auc_metric = tf.keras.metrics.AUC()\n",
        "        test_predictions = []\n",
        "        test_labels = []\n",
        "\n",
        "        n_test_batches = (len(test_y) + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in range(n_test_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(test_y))\n",
        "\n",
        "            batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in test_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(test_y[start_idx:end_idx])\n",
        "\n",
        "            predictions = model(batch_x, training=False)\n",
        "            predictions = tf.squeeze(predictions)\n",
        "\n",
        "            test_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # Collect predictions and labels for log loss calculation\n",
        "            test_predictions.append(predictions.numpy())\n",
        "            test_labels.append(batch_y.numpy())\n",
        "\n",
        "        final_test_auc = test_auc_metric.result().numpy()\n",
        "\n",
        "        # Calculate log loss on test set\n",
        "        test_predictions = np.concatenate(test_predictions)\n",
        "        test_labels = np.concatenate(test_labels)\n",
        "        test_logloss = log_loss(test_labels, test_predictions)\n",
        "\n",
        "        return final_val_auc, final_test_auc, test_logloss, history\n",
        "\n",
        "    # The rest of the methods remain unchanged\n",
        "    def _create_din_dice_model(self, params):\n",
        "        \"\"\"Create DIN-DICE model dengan parameter dari tuning\"\"\"\n",
        "        # Kode ini menyesuaikan dengan create_din_dice_model() yang ada\n",
        "\n",
        "        # Model parameters\n",
        "        n_users = self.model_data['model_params']['n_users']\n",
        "        n_items = self.model_data['model_params']['n_items']\n",
        "        embedding_dim = 32\n",
        "        hidden_units = params['hidden_units']\n",
        "        attention_hidden = params['attention_hidden']\n",
        "        max_seq_len = 8\n",
        "        dense_feature_dim = self.model_data['model_params']['dense_feature_dim']\n",
        "        dropout_rate = params['dropout_rate']\n",
        "        l2_reg = params['l2_reg']\n",
        "        l2_dense = params['l2_dense']\n",
        "        dice_alpha_init = params['dice_alpha_init']\n",
        "        dice_beta_init = params['dice_beta_init']\n",
        "        dice_epsilon = params['dice_epsilon']\n",
        "\n",
        "        # Input layers\n",
        "        user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "        item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "        sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "        seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "        dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        user_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_users, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='user_embedding'\n",
        "        )\n",
        "        item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_items, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='item_embedding'\n",
        "        )\n",
        "\n",
        "        # Apply embeddings\n",
        "        user_emb = user_embedding_layer(user_input)\n",
        "        target_item_emb = item_embedding_layer(item_input)\n",
        "        sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "        # DIN Attention mechanism\n",
        "        attention_scores, attended_emb = DINAttention(\n",
        "            hidden_units=attention_hidden,\n",
        "            max_seq_len=max_seq_len,\n",
        "            activation_type='dice',\n",
        "            dice_alpha_init=params['dice_alpha_init'],\n",
        "            dice_beta_init=params['dice_beta_init'],\n",
        "            dice_epsilon=params['dice_epsilon'],\n",
        "            name='din_attention'\n",
        "        )([sequence_emb, target_item_emb])\n",
        "\n",
        "        # Sequence pooling\n",
        "        pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "            [attention_scores, attended_emb, seq_length_input]\n",
        "        )\n",
        "\n",
        "        # Feature concatenation\n",
        "        all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "            user_emb,\n",
        "            target_item_emb,\n",
        "            pooled_sequence,\n",
        "            dense_input\n",
        "        ])\n",
        "\n",
        "        # DEEP NETWORK dengan DICE activation\n",
        "        x = all_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            x = tf.keras.layers.Dense(\n",
        "                units,\n",
        "                name=f'dense_{i+1}',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "            )(x)\n",
        "\n",
        "            # DICE activation dari tuning\n",
        "            x = DiceActivation(\n",
        "                name=f'dice_{i+1}',\n",
        "                alpha_init=dice_alpha_init,\n",
        "                beta_init=dice_beta_init,\n",
        "                epsilon=dice_epsilon\n",
        "            )(x)\n",
        "\n",
        "            x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "            x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "        # OUTPUT LAYER\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "        # Create model\n",
        "        model = tf.keras.Model(\n",
        "            inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "            outputs=output,\n",
        "            name='din_dice_tuning'\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    # Methods _create_din_prelu_model, _create_deepfm_model, _create_baseline_model unchanged\n",
        "    def _create_din_prelu_model(self, params):\n",
        "        \"\"\"Create DIN-PReLU model dengan parameter dari tuning\"\"\"\n",
        "        # Model parameters\n",
        "        n_users = self.model_data['model_params']['n_users']\n",
        "        n_items = self.model_data['model_params']['n_items']\n",
        "        embedding_dim = 32\n",
        "        hidden_units = params['hidden_units']\n",
        "        attention_hidden = params['attention_hidden']\n",
        "        max_seq_len = 8\n",
        "        dense_feature_dim = self.model_data['model_params']['dense_feature_dim']\n",
        "        dropout_rate = params['dropout_rate']\n",
        "        l2_reg = params['l2_reg']\n",
        "        l2_dense = params['l2_dense']\n",
        "        prelu_alpha_init = params['prelu_alpha_init']\n",
        "\n",
        "        # Input layers\n",
        "        user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "        item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "        sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "        seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "        dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        user_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_users, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='user_embedding'\n",
        "        )\n",
        "        item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_items, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='item_embedding'\n",
        "        )\n",
        "\n",
        "        # Apply embeddings\n",
        "        user_emb = user_embedding_layer(user_input)\n",
        "        target_item_emb = item_embedding_layer(item_input)\n",
        "        sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "        # DIN Attention mechanism\n",
        "        attention_scores, attended_emb = DINAttention(\n",
        "            hidden_units=attention_hidden,\n",
        "            max_seq_len=max_seq_len,\n",
        "            activation_type='prelu',  # Gunakan PReLU\n",
        "            prelu_alpha_init=params['prelu_alpha_init'],\n",
        "            name='din_attention'\n",
        "        )([sequence_emb, target_item_emb])\n",
        "\n",
        "        # Sequence pooling\n",
        "        pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "            [attention_scores, attended_emb, seq_length_input]\n",
        "        )\n",
        "\n",
        "        # Feature concatenation\n",
        "        all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "            user_emb,\n",
        "            target_item_emb,\n",
        "            pooled_sequence,\n",
        "            dense_input\n",
        "        ])\n",
        "\n",
        "        # DEEP NETWORK dengan PReLU activation\n",
        "        x = all_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            x = tf.keras.layers.Dense(\n",
        "                units,\n",
        "                name=f'dense_{i+1}',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "            )(x)\n",
        "\n",
        "            # PReLU activation dari tuning\n",
        "            x = tf.keras.layers.PReLU(\n",
        "                alpha_initializer=tf.keras.initializers.Constant(prelu_alpha_init),\n",
        "                name=f'prelu_{i+1}'\n",
        "            )(x)\n",
        "\n",
        "            x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "            x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "        # OUTPUT LAYER\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "        # Create model\n",
        "        model = tf.keras.Model(\n",
        "            inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "            outputs=output,\n",
        "            name='din_prelu_tuning'\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _create_deepfm_model(self, params):\n",
        "        \"\"\"Create DeepFM model dengan parameter dari tuning\"\"\"\n",
        "        # Model parameters\n",
        "        n_users = self.model_data['model_params']['n_users']\n",
        "        n_items = self.model_data['model_params']['n_items']\n",
        "        embedding_dim = 32\n",
        "        hidden_units = params['hidden_units']\n",
        "        dense_feature_dim = self.model_data['model_params']['dense_feature_dim']\n",
        "        dropout_rate = params['dropout_rate']\n",
        "        l2_reg = params['l2_reg']\n",
        "        l2_dense = params['l2_dense']\n",
        "\n",
        "        # Input layers\n",
        "        user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "        item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "        dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        user_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_users, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='user_embedding'\n",
        "        )\n",
        "        item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_items, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='item_embedding'\n",
        "        )\n",
        "\n",
        "        # Apply embeddings\n",
        "        user_emb = user_embedding_layer(user_input)\n",
        "        item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "        # FM PART: Factorization Machine component\n",
        "\n",
        "        # LINEAR PART\n",
        "        user_linear = tf.keras.layers.Dense(1, use_bias=False, name='user_linear',\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(user_emb)\n",
        "        item_linear = tf.keras.layers.Dense(1, use_bias=False, name='item_linear',\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(item_emb)\n",
        "        dense_linear = tf.keras.layers.Dense(1, use_bias=False, name='dense_linear',\n",
        "                                          kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "\n",
        "        # INTERACTION PART\n",
        "        # User-Item interaction\n",
        "        user_item_interaction = tf.keras.layers.Multiply(name='user_item_mult')([user_emb, item_emb])\n",
        "\n",
        "        # User-Dense interaction\n",
        "        user_dense_proj = tf.keras.layers.Dense(embedding_dim, name='user_dense_proj',\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "        user_dense_interaction = tf.keras.layers.Multiply(name='user_dense_mult')([user_emb, user_dense_proj])\n",
        "\n",
        "        # Item-Dense interaction\n",
        "        item_dense_proj = tf.keras.layers.Dense(embedding_dim, name='item_dense_proj',\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "        item_dense_interaction = tf.keras.layers.Multiply(name='item_dense_mult')([item_emb, item_dense_proj])\n",
        "\n",
        "        # Sum all interactions\n",
        "        fm_interactions = tf.keras.layers.Add(name='fm_interactions')([\n",
        "            user_item_interaction,\n",
        "            user_dense_interaction,\n",
        "            item_dense_interaction\n",
        "        ])\n",
        "        fm_interaction_sum = tf.keras.layers.Dense(1, name='fm_interaction_sum',\n",
        "                                                kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(fm_interactions)\n",
        "\n",
        "        # FM output\n",
        "        fm_output = tf.keras.layers.Add(name='fm_output')([\n",
        "            user_linear,\n",
        "            item_linear,\n",
        "            dense_linear,\n",
        "            fm_interaction_sum\n",
        "        ])\n",
        "\n",
        "        # DEEP PART: Deep Neural Network component\n",
        "\n",
        "        # Concatenate all features untuk deep part\n",
        "        deep_features = tf.keras.layers.Concatenate(name='deep_features')([\n",
        "            user_emb,\n",
        "            item_emb,\n",
        "            dense_input\n",
        "        ])\n",
        "\n",
        "        # DEEP NETWORK\n",
        "        x = deep_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            x = tf.keras.layers.Dense(\n",
        "                units,\n",
        "                activation='relu',\n",
        "                name=f'deep_dense_{i+1}',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "            )(x)\n",
        "            x = tf.keras.layers.Dropout(dropout_rate, name=f'deep_dropout_{i+1}')(x)\n",
        "            x = tf.keras.layers.BatchNormalization(name=f'deep_bn_{i+1}')(x)\n",
        "\n",
        "        # DEEP OUTPUT\n",
        "        deep_output = tf.keras.layers.Dense(1, name='deep_output',\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "        # COMBINE FM + DEEP\n",
        "        combined_output = tf.keras.layers.Add(name='fm_deep_combine')([fm_output, deep_output])\n",
        "\n",
        "        # Final activation\n",
        "        final_output = tf.keras.layers.Activation('sigmoid', name='final_output')(combined_output)\n",
        "\n",
        "        # Create model\n",
        "        model = tf.keras.Model(\n",
        "            inputs=[user_input, item_input, dense_input],\n",
        "            outputs=final_output,\n",
        "            name='deepfm_tuning'\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _create_baseline_model(self, params):\n",
        "        \"\"\"Create Baseline model dengan parameter dari tuning\"\"\"\n",
        "        # Model parameters\n",
        "        n_users = self.model_data['model_params']['n_users']\n",
        "        n_items = self.model_data['model_params']['n_items']\n",
        "        embedding_dim = 32\n",
        "        hidden_units = params['hidden_units']\n",
        "        dense_feature_dim = self.model_data['model_params']['dense_feature_dim']\n",
        "        dropout_rate = params['dropout_rate']\n",
        "        l2_reg = params['l2_reg']\n",
        "        l2_dense = params['l2_dense']\n",
        "\n",
        "        # Input layers\n",
        "        user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "        item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "        dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        user_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_users, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='user_embedding'\n",
        "        )\n",
        "        item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_items, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='item_embedding'\n",
        "        )\n",
        "\n",
        "        # Apply embeddings\n",
        "        user_emb = user_embedding_layer(user_input)\n",
        "        item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "        # Simple feature concatenation\n",
        "        all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "            user_emb,\n",
        "            item_emb,\n",
        "            dense_input\n",
        "        ])\n",
        "\n",
        "        # FEEDFORWARD NETWORK\n",
        "        x = all_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            x = tf.keras.layers.Dense(\n",
        "                units,\n",
        "                activation='relu',\n",
        "                name=f'dense_{i+1}',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "            )(x)\n",
        "            x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "            x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "        # OUTPUT LAYER\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "        # Create model\n",
        "        model = tf.keras.Model(\n",
        "            inputs=[user_input, item_input, dense_input],\n",
        "            outputs=output,\n",
        "            name='baseline_tuning'\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def run_tuning(self, n_trials=10):\n",
        "        \"\"\"Run hyperparameter tuning dengan n trials menggunakan Optuna\"\"\"\n",
        "        # Add subsample info to output if applicable\n",
        "        subsample_info = \"\"\n",
        "        if self.subsample_fraction is not None and self.subsample_fraction < 1.0:\n",
        "            subsample_info = f\" (USING {self.subsample_fraction*100:.1f}% DATA)\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"STARTING HYPERPARAMETER TUNING FOR {self.model_type}{subsample_info} USING OPTUNA\")\n",
        "        print(f\"Number of trials: {n_trials}\")\n",
        "        print(f\"User: {self.current_user}\")\n",
        "        print(f\"Time: {self.current_time}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Create Optuna study\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "\n",
        "        # Run optimization\n",
        "        study.optimize(self._optuna_objective, n_trials=n_trials)\n",
        "\n",
        "        # Store the study for later analysis\n",
        "        self.optuna_study = study\n",
        "\n",
        "        # Get best parameters from Optuna\n",
        "        self.best_params = study.best_params\n",
        "\n",
        "        # For DeepFM and Baseline, convert hidden_units_idx to actual hidden_units\n",
        "        if self.model_type == 'DIN-DICE' and 'hidden_units_idx' in self.best_params:\n",
        "            # Pastikan list ini SAMA PERSIS dengan yang ada di _optuna_objective\n",
        "            hidden_units_options = [\n",
        "                [64, 32],\n",
        "                [128, 64],\n",
        "                [256, 128],\n",
        "                [128, 64, 32]\n",
        "            ]\n",
        "            idx = self.best_params.pop('hidden_units_idx') # Ambil dan hapus idx\n",
        "            self.best_params['hidden_units'] = hidden_units_options[idx] # Tambahkan list-nya\n",
        "\n",
        "        elif self.model_type == 'DIN-PReLU' and 'hidden_units_idx' in self.best_params:\n",
        "            # Pastikan list ini SAMA PERSIS dengan yang ada di _optuna_objective\n",
        "            hidden_units_options = [\n",
        "                [64, 32],\n",
        "                [128, 64],\n",
        "                [256, 128],\n",
        "                [128, 64, 32]\n",
        "            ]\n",
        "            idx = self.best_params.pop('hidden_units_idx') # Ambil dan hapus idx\n",
        "            self.best_params['hidden_units'] = hidden_units_options[idx] # Tambahkan list-nya\n",
        "\n",
        "        elif self.model_type == 'DeepFM' and 'hidden_units_idx' in self.best_params:\n",
        "            hidden_units_options = [[128, 64, 32], [256, 128, 64], [64, 32, 16]]\n",
        "            idx = self.best_params.pop('hidden_units_idx')\n",
        "            self.best_params['hidden_units'] = hidden_units_options[idx]\n",
        "\n",
        "        elif self.model_type == 'Baseline' and 'hidden_units_idx' in self.best_params:\n",
        "            hidden_units_options = [[128, 64], [64, 32], [256, 128]]\n",
        "            idx = self.best_params.pop('hidden_units_idx')\n",
        "            self.best_params['hidden_units'] = hidden_units_options[idx]\n",
        "\n",
        "        # Get best metrics from results list\n",
        "        best_trial_results = None\n",
        "        for result in self.results:\n",
        "            if 'error' in result:  # Skip failed trials\n",
        "                continue\n",
        "\n",
        "            # Find the trial with the best validation AUC\n",
        "            if result.get('val_auc', 0) > self.best_val_auc:\n",
        "                self.best_val_auc = result.get('val_auc', 0)\n",
        "                self.best_test_auc = result.get('test_auc', 0)\n",
        "                self.best_test_logloss = result.get('test_logloss', float('inf'))\n",
        "                best_trial_results = result\n",
        "\n",
        "        tuning_time = time.time() - start_time\n",
        "\n",
        "        # Print optimization plot info\n",
        "        print(f\"\\nOptuna Study Statistics:\")\n",
        "        print(f\"  Best Value: {study.best_value:.4f}\")\n",
        "        print(f\"  Best Trial: {study.best_trial.number}\")\n",
        "\n",
        "        # Get top parameter importances\n",
        "        try:\n",
        "            importances = optuna.importance.get_param_importances(study)\n",
        "            print(f\"\\nParameter Importances:\")\n",
        "            for param, importance in sorted(importances.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "                print(f\"  {param}: {importance:.4f}\")\n",
        "        except:\n",
        "            print(\"Could not calculate parameter importances.\")\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"TUNING COMPLETED FOR {self.model_type}\")\n",
        "        print(f\"Total trials: {n_trials}\")\n",
        "        print(f\"Best validation AUC: {self.best_val_auc:.4f}\")\n",
        "        print(f\"Best test AUC: {self.best_test_auc:.4f}\")\n",
        "        print(f\"Best test log loss: {self.best_test_logloss:.4f}\")\n",
        "        print(f\"Best parameters: {self.best_params}\")\n",
        "        print(f\"Total tuning time: {tuning_time:.1f}s\")\n",
        "        print(f\"Results saved to {self.csv_path}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Save best parameters to JSON\n",
        "        best_params_file = os.path.join(self.save_dir, f'{self.model_type}_best_params.json')\n",
        "        with open(best_params_file, 'w') as f:\n",
        "            json.dump(self.best_params, f, indent=4)\n",
        "\n",
        "        print(f\"Best parameters saved to {best_params_file}\")\n",
        "\n",
        "        # Add reminder if subsampling was used\n",
        "        if self.subsample_fraction is not None and self.subsample_fraction < 1.0:\n",
        "            print(f\"\\nâš ï¸ REMINDER: Tuning used {self.subsample_fraction*100:.1f}% of training data\")\n",
        "            print(f\"   For final model training, use these parameters with the FULL dataset!\")\n",
        "\n",
        "        return {\n",
        "            'best_params': self.best_params,\n",
        "            'best_val_auc': self.best_val_auc,\n",
        "            'best_test_auc': self.best_test_auc,\n",
        "            'best_test_logloss': self.best_test_logloss,\n",
        "            'trials': len(self.results),\n",
        "            'csv_path': self.csv_path,\n",
        "            'params_file': best_params_file,\n",
        "            'subsample_fraction': self.subsample_fraction,\n",
        "            'optuna_study': self.optuna_study\n",
        "        }\n",
        "\n",
        "    def get_best_params(self):\n",
        "        \"\"\"Return best parameters dari tuning\"\"\"\n",
        "        return self.best_params\n",
        "\n",
        "print(f\"HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA LOADED!\")"
      ],
      "metadata": {
        "id": "xrOdRWwblxnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e175cde-b788-4b47-8ab8-842546a073a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA\n",
            "============================================================\n",
            "HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA LOADED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6G: RUN HYPERPARAMETER TUNING WITH OPTUNA\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RUN HYPERPARAMETER TUNING WITH OPTUNA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup environment\n",
        "os.makedirs('tuning_results', exist_ok=True)\n",
        "os.makedirs('tuning_results/din_dice', exist_ok=True)\n",
        "os.makedirs('tuning_results/din_prelu', exist_ok=True)\n",
        "os.makedirs('tuning_results/deepfm', exist_ok=True)\n",
        "os.makedirs('tuning_results/baseline', exist_ok=True)\n",
        "\n",
        "# Current settings\n",
        "CURRENT_USER = \"Muhammad Sultan Nurrochman\"\n",
        "CURRENT_TIME = \"-\"\n",
        "N_TRIALS = 8  # Number of trials per model\n",
        "SUBSAMPLE_FRACTION = 0.1  # Use 20% data for tuning\n",
        "\n",
        "print(f\"Environment setup completed!\")\n",
        "print(f\"Using {SUBSAMPLE_FRACTION*100:.1f}% of training data for tuning\")\n",
        "print(f\"Running {N_TRIALS} trials for each model\")\n"
      ],
      "metadata": {
        "id": "_PMEhUdomc1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d780904-119f-4843-c939-05a2fcd6f2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RUN HYPERPARAMETER TUNING WITH OPTUNA\n",
            "============================================================\n",
            "Environment setup completed!\n",
            "Using 10.0% of training data for tuning\n",
            "Running 8 trials for each model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DIN-DICE HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup DIN-DICE tuner with Optuna\n",
        "din_tuner = ModelTuner(\n",
        "    model_type='DIN-DICE',\n",
        "    model_data=model_data,\n",
        "    subsample_fraction=SUBSAMPLE_FRACTION,\n",
        "    save_dir='tuning_results/din_dice',\n",
        "    current_user=CURRENT_USER,\n",
        "    current_time=CURRENT_TIME\n",
        ")\n",
        "\n",
        "# Run tuning\n",
        "din_tuning_results = din_tuner.run_tuning(n_trials=N_TRIALS)\n",
        "\n",
        "# Get best parameters\n",
        "din_best_params = din_tuning_results['best_params']\n",
        "\n",
        "print(\"\\nDIN-DICE Best Parameters:\")\n",
        "for param, value in din_best_params.items():\n",
        "    print(f\"    {param}: {value}\")"
      ],
      "metadata": {
        "id": "J1d7glDcs7UL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e8279c-c173-4749-eb86-44f0fcbdb007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIN-DICE HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "Creating 10.0% subsample of training data...\n",
            "  Original training samples: 21,246,368\n",
            "  Subsampled training size: 2,124,636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 16:25:30,368] A new study created in memory with name: no-name-ec547f37-13e0-43c5-8e62-7f8066614ffd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original positive rate: 0.0515\n",
            "  Subsampled positive rate: 0.0514\n",
            "âœ… Subsample created successfully\n",
            "\n",
            "================================================================================\n",
            "STARTING HYPERPARAMETER TUNING FOR DIN-DICE (USING 10.0% DATA) USING OPTUNA\n",
            "Number of trials: 8\n",
            "User: Muhammad Sultan Nurrochman\n",
            "Time: -\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 1e-05, 'l2_dense': 2e-05, 'dice_alpha_init': 0.4, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8927, AUC: 0.4365\n",
            "  Val   - Loss: 0.7565, AUC: 0.3990\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8469, AUC: 0.4534\n",
            "  Val   - Loss: 0.7329, AUC: 0.4186\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.8144, AUC: 0.4703\n",
            "  Val   - Loss: 0.7076, AUC: 0.4412\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7900, AUC: 0.4854\n",
            "  Val   - Loss: 0.6893, AUC: 0.4697\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7718, AUC: 0.4972\n",
            "  Val   - Loss: 0.6765, AUC: 0.5041\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7565, AUC: 0.5044\n",
            "  Val   - Loss: 0.6657, AUC: 0.5362\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7428, AUC: 0.5124\n",
            "  Val   - Loss: 0.6567, AUC: 0.5586\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.7310, AUC: 0.5161\n",
            "  Val   - Loss: 0.6479, AUC: 0.5762\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 16:37:44,592] Trial 0 finished with value: 0.5762196779251099 and parameters: {'hidden_units_idx': 0, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 1e-05, 'l2_dense': 2e-05, 'dice_alpha_init': 0.4, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2}. Best is trial 0 with value: 0.5762196779251099.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.5762\n",
            "Test AUC: 0.5757\n",
            "Test Log Loss: 0.6345\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.5762\n",
            "Test AUC: 0.5757\n",
            "Test Log Loss: 0.6345\n",
            "Training Time: 733.9s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.6113, AUC: 0.5387\n",
            "  Val   - Loss: 0.4183, AUC: 0.6562\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.4216, AUC: 0.5486\n",
            "  Val   - Loss: 0.3630, AUC: 0.6568\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.3868, AUC: 0.5723\n",
            "  Val   - Loss: 0.3618, AUC: 0.6710\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.3764, AUC: 0.5930\n",
            "  Val   - Loss: 0.3611, AUC: 0.6777\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.3706, AUC: 0.6153\n",
            "  Val   - Loss: 0.3606, AUC: 0.6848\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.3659, AUC: 0.6602\n",
            "  Val   - Loss: 0.3599, AUC: 0.6935\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.3579, AUC: 0.7789\n",
            "  Val   - Loss: 0.3632, AUC: 0.6610\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.3439, AUC: 0.8794\n",
            "  Val   - Loss: 0.3701, AUC: 0.6366\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 17:25:56,496] Trial 1 finished with value: 0.6934754848480225 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.15}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6935\n",
            "Test AUC: 0.6936\n",
            "Test Log Loss: 0.2209\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6935\n",
            "Test AUC: 0.6936\n",
            "Test Log Loss: 0.2209\n",
            "Training Time: 2891.6s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 2e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 2e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.8, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.1, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8726, AUC: 0.4916\n",
            "  Val   - Loss: 0.6508, AUC: 0.4875\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8335, AUC: 0.5007\n",
            "  Val   - Loss: 0.6340, AUC: 0.5265\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.8029, AUC: 0.5072\n",
            "  Val   - Loss: 0.6176, AUC: 0.5607\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7767, AUC: 0.5148\n",
            "  Val   - Loss: 0.6050, AUC: 0.5879\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7537, AUC: 0.5186\n",
            "  Val   - Loss: 0.5924, AUC: 0.6076\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7329, AUC: 0.5224\n",
            "  Val   - Loss: 0.5803, AUC: 0.6209\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7137, AUC: 0.5240\n",
            "  Val   - Loss: 0.5697, AUC: 0.6296\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6956, AUC: 0.5253\n",
            "  Val   - Loss: 0.5588, AUC: 0.6356\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 17:38:20,750] Trial 2 finished with value: 0.6356160640716553 and parameters: {'hidden_units_idx': 0, 'learning_rate': 2e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 2e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.8, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.1}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6356\n",
            "Test AUC: 0.6345\n",
            "Test Log Loss: 0.5416\n",
            "Training Time: 743.9s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 2e-05, 'batch_size': 2048, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.45, 'dice_beta_init': 1.2, 'dice_epsilon': 1e-08, 'attention_hidden': 16, 'label_smoothing': 0.15, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8256, AUC: 0.5064\n",
            "  Val   - Loss: 0.6176, AUC: 0.5915\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.7293, AUC: 0.5204\n",
            "  Val   - Loss: 0.5733, AUC: 0.6351\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.6659, AUC: 0.5239\n",
            "  Val   - Loss: 0.5363, AUC: 0.6480\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.6158, AUC: 0.5253\n",
            "  Val   - Loss: 0.5017, AUC: 0.6511\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.5726, AUC: 0.5280\n",
            "  Val   - Loss: 0.4698, AUC: 0.6537\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.5345, AUC: 0.5280\n",
            "  Val   - Loss: 0.4391, AUC: 0.6514\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.5002, AUC: 0.5295\n",
            "  Val   - Loss: 0.4130, AUC: 0.6476\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.4712, AUC: 0.5309\n",
            "  Val   - Loss: 0.3923, AUC: 0.6452\n",
            "  Early stopping triggered!\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 18:26:55,916] Trial 3 finished with value: 0.653675377368927 and parameters: {'hidden_units_idx': 0, 'learning_rate': 2e-05, 'batch_size': 2048, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.45, 'dice_beta_init': 1.2, 'dice_epsilon': 1e-08, 'attention_hidden': 16, 'label_smoothing': 0.15}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6537\n",
            "Test AUC: 0.6546\n",
            "Test Log Loss: 0.4174\n",
            "Training Time: 2914.9s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.5, 'l2_reg': 1e-05, 'l2_dense': 5e-05, 'dice_alpha_init': 0.5, 'dice_beta_init': 2.0, 'dice_epsilon': 1e-10, 'attention_hidden': 8, 'label_smoothing': 0.1, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8469, AUC: 0.5151\n",
            "  Val   - Loss: 0.6468, AUC: 0.5930\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8243, AUC: 0.5219\n",
            "  Val   - Loss: 0.6442, AUC: 0.6226\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.8061, AUC: 0.5247\n",
            "  Val   - Loss: 0.6403, AUC: 0.6402\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7901, AUC: 0.5252\n",
            "  Val   - Loss: 0.6357, AUC: 0.6505\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7757, AUC: 0.5285\n",
            "  Val   - Loss: 0.6304, AUC: 0.6566\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7631, AUC: 0.5274\n",
            "  Val   - Loss: 0.6247, AUC: 0.6608\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7502, AUC: 0.5313\n",
            "  Val   - Loss: 0.6207, AUC: 0.6631\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.7392, AUC: 0.5296\n",
            "  Val   - Loss: 0.6150, AUC: 0.6647\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 18:41:30,405] Trial 4 finished with value: 0.6647292375564575 and parameters: {'hidden_units_idx': 3, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.5, 'l2_reg': 1e-05, 'l2_dense': 5e-05, 'dice_alpha_init': 0.5, 'dice_beta_init': 2.0, 'dice_epsilon': 1e-10, 'attention_hidden': 8, 'label_smoothing': 0.1}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6647\n",
            "Test AUC: 0.6644\n",
            "Test Log Loss: 0.6055\n",
            "Training Time: 874.1s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'dice_alpha_init': 0.4, 'dice_beta_init': 2.0, 'dice_epsilon': 1e-09, 'attention_hidden': 8, 'label_smoothing': 0.15, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8752, AUC: 0.5109\n",
            "  Val   - Loss: 0.7038, AUC: 0.6011\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8377, AUC: 0.5145\n",
            "  Val   - Loss: 0.6842, AUC: 0.6232\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.8067, AUC: 0.5188\n",
            "  Val   - Loss: 0.6655, AUC: 0.6349\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7802, AUC: 0.5185\n",
            "  Val   - Loss: 0.6492, AUC: 0.6412\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7563, AUC: 0.5199\n",
            "  Val   - Loss: 0.6339, AUC: 0.6439\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7350, AUC: 0.5187\n",
            "  Val   - Loss: 0.6199, AUC: 0.6454\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7160, AUC: 0.5181\n",
            "  Val   - Loss: 0.6065, AUC: 0.6459\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6980, AUC: 0.5179\n",
            "  Val   - Loss: 0.5938, AUC: 0.6446\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 19:10:15,756] Trial 5 finished with value: 0.6458544135093689 and parameters: {'hidden_units_idx': 3, 'learning_rate': 1e-05, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'dice_alpha_init': 0.4, 'dice_beta_init': 2.0, 'dice_epsilon': 1e-09, 'attention_hidden': 8, 'label_smoothing': 0.15}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6459\n",
            "Test AUC: 0.6455\n",
            "Test Log Loss: 0.5897\n",
            "Training Time: 1725.0s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 0.0001, 'dice_alpha_init': 0.5, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8787, AUC: 0.5077\n",
            "  Val   - Loss: 0.7243, AUC: 0.5268\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8011, AUC: 0.5187\n",
            "  Val   - Loss: 0.6886, AUC: 0.5653\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.7712, AUC: 0.5279\n",
            "  Val   - Loss: 0.6723, AUC: 0.5975\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7529, AUC: 0.5324\n",
            "  Val   - Loss: 0.6601, AUC: 0.6144\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7373, AUC: 0.5335\n",
            "  Val   - Loss: 0.6512, AUC: 0.6225\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7235, AUC: 0.5348\n",
            "  Val   - Loss: 0.6427, AUC: 0.6288\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7105, AUC: 0.5350\n",
            "  Val   - Loss: 0.6337, AUC: 0.6347\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6983, AUC: 0.5379\n",
            "  Val   - Loss: 0.6252, AUC: 0.6391\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 19:22:35,018] Trial 6 finished with value: 0.6391257643699646 and parameters: {'hidden_units_idx': 1, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 0.0001, 'dice_alpha_init': 0.5, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6391\n",
            "Test AUC: 0.6383\n",
            "Test Log Loss: 0.6059\n",
            "Training Time: 739.0s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 2e-05, 'dice_alpha_init': 0.3, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.7405, AUC: 0.5109\n",
            "  Val   - Loss: 0.6183, AUC: 0.6400\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.6142, AUC: 0.5174\n",
            "  Val   - Loss: 0.5194, AUC: 0.6426\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.5264, AUC: 0.5220\n",
            "  Val   - Loss: 0.4486, AUC: 0.6549\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.4708, AUC: 0.5334\n",
            "  Val   - Loss: 0.4200, AUC: 0.6580\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.4461, AUC: 0.5482\n",
            "  Val   - Loss: 0.4132, AUC: 0.6625\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.4355, AUC: 0.5629\n",
            "  Val   - Loss: 0.4110, AUC: 0.6652\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.4289, AUC: 0.5789\n",
            "  Val   - Loss: 0.4091, AUC: 0.6669\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.4241, AUC: 0.5901\n",
            "  Val   - Loss: 0.4077, AUC: 0.6684\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 19:51:28,067] Trial 7 finished with value: 0.6684398651123047 and parameters: {'hidden_units_idx': 3, 'learning_rate': 0.0001, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 2e-05, 'dice_alpha_init': 0.3, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6684\n",
            "Test AUC: 0.6675\n",
            "Test Log Loss: 0.2457\n",
            "Training Time: 1732.7s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "Optuna Study Statistics:\n",
            "  Best Value: 0.6935\n",
            "  Best Trial: 1\n",
            "\n",
            "Parameter Importances:\n",
            "  dropout_rate: 0.2951\n",
            "  dice_alpha_init: 0.1281\n",
            "  learning_rate: 0.1141\n",
            "  hidden_units_idx: 0.1123\n",
            "  l2_dense: 0.1070\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETED FOR DIN-DICE\n",
            "Total trials: 8\n",
            "Best validation AUC: 0.6935\n",
            "Best test AUC: 0.6936\n",
            "Best test log loss: 0.2209\n",
            "Best parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "Total tuning time: 12357.7s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "================================================================================\n",
            "Best parameters saved to tuning_results/din_dice/DIN-DICE_best_params.json\n",
            "\n",
            "âš ï¸ REMINDER: Tuning used 10.0% of training data\n",
            "   For final model training, use these parameters with the FULL dataset!\n",
            "\n",
            "DIN-DICE Best Parameters:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.4\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    dice_alpha_init: 0.35\n",
            "    dice_beta_init: 1.0\n",
            "    dice_epsilon: 1e-09\n",
            "    attention_hidden: 16\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# DIN-PReLU Hyperparameter Tuning\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DIN-PRELU HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup DIN-PReLU tuner with Optuna\n",
        "din_prelu_tuner = ModelTuner(\n",
        "    model_type='DIN-PReLU',\n",
        "    model_data=model_data,\n",
        "    subsample_fraction=SUBSAMPLE_FRACTION,\n",
        "    save_dir='tuning_results/din_prelu',\n",
        "    current_user=CURRENT_USER,\n",
        "    current_time=CURRENT_TIME\n",
        ")\n",
        "\n",
        "# Run tuning\n",
        "din_prelu_tuning_results = din_prelu_tuner.run_tuning(n_trials=N_TRIALS)\n",
        "\n",
        "# Get best parameters\n",
        "din_prelu_best_params = din_prelu_tuning_results['best_params']\n",
        "\n",
        "print(\"\\nDIN-PReLU Best Parameters:\")\n",
        "for param, value in din_prelu_best_params.items():\n",
        "    print(f\"    {param}: {value}\")"
      ],
      "metadata": {
        "id": "9ls5XDUZtF9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e935486-4f22-45e1-eb2d-cf054221a370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIN-PRELU HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "Creating 10.0% subsample of training data...\n",
            "  Original training samples: 21,246,368\n",
            "  Subsampled training size: 2,124,636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 19:51:30,015] A new study created in memory with name: no-name-7427c5e5-d8cb-41c9-97e2-273d9a87ae6f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original positive rate: 0.0515\n",
            "  Subsampled positive rate: 0.0514\n",
            "âœ… Subsample created successfully\n",
            "\n",
            "================================================================================\n",
            "STARTING HYPERPARAMETER TUNING FOR DIN-PReLU (USING 10.0% DATA) USING OPTUNA\n",
            "Number of trials: 8\n",
            "User: Muhammad Sultan Nurrochman\n",
            "Time: -\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 2e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'prelu_alpha_init': 0.4, 'attention_hidden': 8, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8608, AUC: 0.4992\n",
            "  Val   - Loss: 0.7335, AUC: 0.5325\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8126, AUC: 0.5135\n",
            "  Val   - Loss: 0.7042, AUC: 0.6085\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.7769, AUC: 0.5207\n",
            "  Val   - Loss: 0.6806, AUC: 0.6316\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7483, AUC: 0.5223\n",
            "  Val   - Loss: 0.6592, AUC: 0.6426\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7227, AUC: 0.5262\n",
            "  Val   - Loss: 0.6399, AUC: 0.6495\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7011, AUC: 0.5284\n",
            "  Val   - Loss: 0.6218, AUC: 0.6528\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.6812, AUC: 0.5298\n",
            "  Val   - Loss: 0.6050, AUC: 0.6569\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6624, AUC: 0.5317\n",
            "  Val   - Loss: 0.5889, AUC: 0.6596\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 20:02:28,333] Trial 0 finished with value: 0.6595548391342163 and parameters: {'hidden_units_idx': 1, 'learning_rate': 2e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'prelu_alpha_init': 0.4, 'attention_hidden': 8, 'label_smoothing': 0.15}. Best is trial 0 with value: 0.6595548391342163.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6596\n",
            "Test AUC: 0.6591\n",
            "Test Log Loss: 0.5680\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6596\n",
            "Test AUC: 0.6591\n",
            "Test Log Loss: 0.5680\n",
            "Training Time: 658.0s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 2e-05, 'l2_dense': 1e-05, 'prelu_alpha_init': 0.2, 'attention_hidden': 16, 'label_smoothing': 0.05, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.7475, AUC: 0.5319\n",
            "  Val   - Loss: 0.6230, AUC: 0.6077\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.6360, AUC: 0.5450\n",
            "  Val   - Loss: 0.5409, AUC: 0.6242\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.5559, AUC: 0.5522\n",
            "  Val   - Loss: 0.4726, AUC: 0.6283\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.4813, AUC: 0.5568\n",
            "  Val   - Loss: 0.4070, AUC: 0.6377\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.4147, AUC: 0.5632\n",
            "  Val   - Loss: 0.3532, AUC: 0.6486\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.3619, AUC: 0.5740\n",
            "  Val   - Loss: 0.3148, AUC: 0.6595\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.3258, AUC: 0.5950\n",
            "  Val   - Loss: 0.2917, AUC: 0.6667\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.3026, AUC: 0.6117\n",
            "  Val   - Loss: 0.2780, AUC: 0.6708\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 20:15:12,053] Trial 1 finished with value: 0.6708238124847412 and parameters: {'hidden_units_idx': 3, 'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 2e-05, 'l2_dense': 1e-05, 'prelu_alpha_init': 0.2, 'attention_hidden': 16, 'label_smoothing': 0.05}. Best is trial 1 with value: 0.6708238124847412.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6708\n",
            "Test AUC: 0.6708\n",
            "Test Log Loss: 0.2321\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6708\n",
            "Test AUC: 0.6708\n",
            "Test Log Loss: 0.2321\n",
            "Training Time: 763.4s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 5e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.3, 'attention_hidden': 16, 'label_smoothing': 0.0, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.7771, AUC: 0.5246\n",
            "  Val   - Loss: 0.6389, AUC: 0.6097\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.6825, AUC: 0.5403\n",
            "  Val   - Loss: 0.5747, AUC: 0.6297\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.6159, AUC: 0.5452\n",
            "  Val   - Loss: 0.5202, AUC: 0.6376\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.5571, AUC: 0.5452\n",
            "  Val   - Loss: 0.4676, AUC: 0.6419\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.5016, AUC: 0.5479\n",
            "  Val   - Loss: 0.4154, AUC: 0.6451\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.4496, AUC: 0.5470\n",
            "  Val   - Loss: 0.3673, AUC: 0.6447\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.4014, AUC: 0.5505\n",
            "  Val   - Loss: 0.3245, AUC: 0.6448\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.3599, AUC: 0.5486\n",
            "  Val   - Loss: 0.2893, AUC: 0.6426\n",
            "  Early stopping triggered!\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 20:26:07,910] Trial 2 finished with value: 0.645082414150238 and parameters: {'hidden_units_idx': 1, 'learning_rate': 5e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.3, 'attention_hidden': 16, 'label_smoothing': 0.0}. Best is trial 1 with value: 0.6708238124847412.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6451\n",
            "Test AUC: 0.6451\n",
            "Test Log Loss: 0.4158\n",
            "Training Time: 655.6s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 5e-05, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.3, 'attention_hidden': 16, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8098, AUC: 0.5157\n",
            "  Val   - Loss: 0.6171, AUC: 0.6263\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.6743, AUC: 0.5257\n",
            "  Val   - Loss: 0.5353, AUC: 0.6347\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.5879, AUC: 0.5307\n",
            "  Val   - Loss: 0.4740, AUC: 0.6318\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.5229, AUC: 0.5327\n",
            "  Val   - Loss: 0.4273, AUC: 0.6285\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.4737, AUC: 0.5351\n",
            "  Val   - Loss: 0.3958, AUC: 0.6309\n",
            "  Early stopping triggered!\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 20:39:54,072] Trial 3 finished with value: 0.6347348690032959 and parameters: {'hidden_units_idx': 1, 'learning_rate': 5e-05, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.3, 'attention_hidden': 16, 'label_smoothing': 0.15}. Best is trial 1 with value: 0.6708238124847412.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6347\n",
            "Test AUC: 0.6339\n",
            "Test Log Loss: 0.5014\n",
            "Training Time: 825.9s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.6040, AUC: 0.5342\n",
            "  Val   - Loss: 0.4119, AUC: 0.6463\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.4171, AUC: 0.5495\n",
            "  Val   - Loss: 0.3624, AUC: 0.6506\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.3865, AUC: 0.5739\n",
            "  Val   - Loss: 0.3612, AUC: 0.6638\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.3767, AUC: 0.5947\n",
            "  Val   - Loss: 0.3604, AUC: 0.6747\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.3707, AUC: 0.6146\n",
            "  Val   - Loss: 0.3599, AUC: 0.6817\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.3663, AUC: 0.6479\n",
            "  Val   - Loss: 0.3594, AUC: 0.6912\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.3595, AUC: 0.7484\n",
            "  Val   - Loss: 0.3620, AUC: 0.6631\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.3455, AUC: 0.8685\n",
            "  Val   - Loss: 0.3692, AUC: 0.6377\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 21:22:19,299] Trial 4 finished with value: 0.6912413239479065 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.15}. Best is trial 4 with value: 0.6912413239479065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6912\n",
            "Test AUC: 0.6913\n",
            "Test Log Loss: 0.2214\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6912\n",
            "Test AUC: 0.6913\n",
            "Test Log Loss: 0.2214\n",
            "Training Time: 2544.9s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.1, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8390, AUC: 0.4891\n",
            "  Val   - Loss: 0.6559, AUC: 0.5174\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.7625, AUC: 0.5158\n",
            "  Val   - Loss: 0.6184, AUC: 0.5803\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.7152, AUC: 0.5255\n",
            "  Val   - Loss: 0.5911, AUC: 0.6096\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.6760, AUC: 0.5331\n",
            "  Val   - Loss: 0.5657, AUC: 0.6223\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.6432, AUC: 0.5330\n",
            "  Val   - Loss: 0.5416, AUC: 0.6294\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.6126, AUC: 0.5384\n",
            "  Val   - Loss: 0.5177, AUC: 0.6344\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.5855, AUC: 0.5372\n",
            "  Val   - Loss: 0.4943, AUC: 0.6380\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.5587, AUC: 0.5387\n",
            "  Val   - Loss: 0.4711, AUC: 0.6392\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 22:04:44,453] Trial 5 finished with value: 0.6392340064048767 and parameters: {'hidden_units_idx': 0, 'learning_rate': 1e-05, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.1}. Best is trial 4 with value: 0.6912413239479065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6392\n",
            "Test AUC: 0.6400\n",
            "Test Log Loss: 0.4396\n",
            "Training Time: 2544.9s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 2e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 16, 'label_smoothing': 0.05, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.6232, AUC: 0.5327\n",
            "  Val   - Loss: 0.4086, AUC: 0.6213\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.3745, AUC: 0.5419\n",
            "  Val   - Loss: 0.2782, AUC: 0.6390\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.2884, AUC: 0.5832\n",
            "  Val   - Loss: 0.2610, AUC: 0.6608\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.2716, AUC: 0.6219\n",
            "  Val   - Loss: 0.2592, AUC: 0.6789\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.2651, AUC: 0.6526\n",
            "  Val   - Loss: 0.2578, AUC: 0.6891\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.2580, AUC: 0.7220\n",
            "  Val   - Loss: 0.2585, AUC: 0.6811\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.2390, AUC: 0.8490\n",
            "  Val   - Loss: 0.2668, AUC: 0.6487\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.2170, AUC: 0.9164\n",
            "  Val   - Loss: 0.2798, AUC: 0.6301\n",
            "  Early stopping triggered!\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 22:54:34,351] Trial 6 finished with value: 0.6891223192214966 and parameters: {'hidden_units_idx': 3, 'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 2e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 16, 'label_smoothing': 0.05}. Best is trial 4 with value: 0.6912413239479065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6891\n",
            "Test AUC: 0.6883\n",
            "Test Log Loss: 0.1973\n",
            "Training Time: 2989.6s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 4096, 'dropout_rate': 0.4, 'l2_reg': 0.0001, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.0, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8531, AUC: 0.4958\n",
            "  Val   - Loss: 0.6664, AUC: 0.5177\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8047, AUC: 0.5138\n",
            "  Val   - Loss: 0.6425, AUC: 0.5711\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.7707, AUC: 0.5266\n",
            "  Val   - Loss: 0.6247, AUC: 0.6021\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7426, AUC: 0.5303\n",
            "  Val   - Loss: 0.6092, AUC: 0.6186\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7176, AUC: 0.5342\n",
            "  Val   - Loss: 0.5950, AUC: 0.6280\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.6943, AUC: 0.5380\n",
            "  Val   - Loss: 0.5808, AUC: 0.6344\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.6728, AUC: 0.5399\n",
            "  Val   - Loss: 0.5671, AUC: 0.6388\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6527, AUC: 0.5395\n",
            "  Val   - Loss: 0.5541, AUC: 0.6418\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:15:53,127] Trial 7 finished with value: 0.6418236494064331 and parameters: {'hidden_units_idx': 0, 'learning_rate': 1e-05, 'batch_size': 4096, 'dropout_rate': 0.4, 'l2_reg': 0.0001, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.0}. Best is trial 4 with value: 0.6912413239479065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6418\n",
            "Test AUC: 0.6411\n",
            "Test Log Loss: 0.5543\n",
            "Training Time: 1278.5s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "Optuna Study Statistics:\n",
            "  Best Value: 0.6912\n",
            "  Best Trial: 4\n",
            "\n",
            "Parameter Importances:\n",
            "  learning_rate: 0.4850\n",
            "  l2_reg: 0.1246\n",
            "  l2_dense: 0.1136\n",
            "  dropout_rate: 0.0852\n",
            "  batch_size: 0.0584\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETED FOR DIN-PReLU\n",
            "Total trials: 8\n",
            "Best validation AUC: 0.6912\n",
            "Best test AUC: 0.6913\n",
            "Best test log loss: 0.2214\n",
            "Best parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "Total tuning time: 12263.1s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "================================================================================\n",
            "Best parameters saved to tuning_results/din_prelu/DIN-PReLU_best_params.json\n",
            "\n",
            "âš ï¸ REMINDER: Tuning used 10.0% of training data\n",
            "   For final model training, use these parameters with the FULL dataset!\n",
            "\n",
            "DIN-PReLU Best Parameters:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 5e-05\n",
            "    l2_dense: 5e-05\n",
            "    prelu_alpha_init: 0.35\n",
            "    attention_hidden: 8\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# DeepFM Hyperparameter Tuning\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DEEPFM HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup DeepFM tuner with Optuna\n",
        "deepfm_tuner = ModelTuner(\n",
        "    model_type='DeepFM',\n",
        "    model_data=model_data,\n",
        "    subsample_fraction=SUBSAMPLE_FRACTION,\n",
        "    save_dir='tuning_results/deepfm',\n",
        "    current_user=CURRENT_USER,\n",
        "    current_time=CURRENT_TIME\n",
        ")\n",
        "\n",
        "# Run tuning\n",
        "deepfm_tuning_results = deepfm_tuner.run_tuning(n_trials=N_TRIALS)\n",
        "\n",
        "# Get best parameters\n",
        "deepfm_best_params = deepfm_tuning_results['best_params']\n",
        "\n",
        "print(\"\\nDeepFM Best Parameters:\")\n",
        "for param, value in deepfm_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n"
      ],
      "metadata": {
        "id": "fSyzxslHtPJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb969b6-044b-4bc7-9b35-0c4e49a6f2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DEEPFM HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "Creating 10.0% subsample of training data...\n",
            "  Original training samples: 21,246,368\n",
            "  Subsampled training size: 2,124,636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:15:54,484] A new study created in memory with name: no-name-0b64cd82-485c-4e9f-8d59-20e217cad112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original positive rate: 0.0515\n",
            "  Subsampled positive rate: 0.0514\n",
            "âœ… Subsample created successfully\n",
            "\n",
            "================================================================================\n",
            "STARTING HYPERPARAMETER TUNING FOR DeepFM (USING 10.0% DATA) USING OPTUNA\n",
            "Number of trials: 8\n",
            "User: Muhammad Sultan Nurrochman\n",
            "Time: -\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.001, 'batch_size': 2048, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 0.001, 'hidden_units': [256, 128, 64], 'label_smoothing': 0.0}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 26ms/step - auc: 0.5646 - loss: 0.6211 - val_auc: 0.6797 - val_loss: 0.1951\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6774 - loss: 0.1958 - val_auc: 0.6886 - val_loss: 0.1916\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6844 - loss: 0.1935 - val_auc: 0.6896 - val_loss: 0.1911\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6843 - loss: 0.1932 - val_auc: 0.6898 - val_loss: 0.1904\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6850 - loss: 0.1927 - val_auc: 0.6895 - val_loss: 0.1906\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6847 - loss: 0.1926 - val_auc: 0.6898 - val_loss: 0.1903\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6853 - loss: 0.1923 - val_auc: 0.6903 - val_loss: 0.1897\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6854 - loss: 0.1918 - val_auc: 0.6898 - val_loss: 0.1897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:26:11,231] Trial 0 finished with value: 0.6903295516967773 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.001, 'batch_size': 2048, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 0.001, 'label_smoothing': 0.0}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6903\n",
            "Test AUC: 0.6895\n",
            "Test Log Loss: 0.1888\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6903\n",
            "Test AUC: 0.6895\n",
            "Test Log Loss: 0.1888\n",
            "Training Time: 616.6s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'hidden_units': [128, 64, 32], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - auc: 0.4672 - loss: 4.7975 - val_auc: 0.4886 - val_loss: 1.7899\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5189 - loss: 1.4786 - val_auc: 0.5683 - val_loss: 0.7377\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5355 - loss: 0.7108 - val_auc: 0.5901 - val_loss: 0.5122\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5458 - loss: 0.5267 - val_auc: 0.5953 - val_loss: 0.4353\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5581 - loss: 0.4533 - val_auc: 0.5958 - val_loss: 0.3904\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - auc: 0.5725 - loss: 0.4091 - val_auc: 0.5952 - val_loss: 0.3622\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5809 - loss: 0.3822 - val_auc: 0.5974 - val_loss: 0.3464\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5938 - loss: 0.3636 - val_auc: 0.6012 - val_loss: 0.3372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:34:41,608] Trial 1 finished with value: 0.6011937260627747 and parameters: {'hidden_units_idx': 0, 'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'label_smoothing': 0.1}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6012\n",
            "Test AUC: 0.6014\n",
            "Test Log Loss: 0.2375\n",
            "Training Time: 510.3s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'hidden_units': [256, 128, 64], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - auc: 0.5143 - loss: 6.1584 - val_auc: 0.5332 - val_loss: 5.6777\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5204 - loss: 5.4161 - val_auc: 0.5457 - val_loss: 4.9653\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5252 - loss: 4.7623 - val_auc: 0.5545 - val_loss: 4.3572\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5279 - loss: 4.1906 - val_auc: 0.5618 - val_loss: 3.8277\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5329 - loss: 3.6882 - val_auc: 0.5683 - val_loss: 3.3642\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5341 - loss: 3.2471 - val_auc: 0.5734 - val_loss: 2.9575\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5330 - loss: 2.8615 - val_auc: 0.5773 - val_loss: 2.6009\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5367 - loss: 2.5221 - val_auc: 0.5798 - val_loss: 2.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:43:15,265] Trial 2 finished with value: 0.5798419713973999 and parameters: {'hidden_units_idx': 1, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'label_smoothing': 0.1}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.5798\n",
            "Test AUC: 0.5791\n",
            "Test Log Loss: 0.7592\n",
            "Training Time: 513.6s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 5e-05, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'hidden_units': [64, 32, 16], 'label_smoothing': 0.05}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - auc: 0.5625 - loss: 1.2270 - val_auc: 0.6196 - val_loss: 0.6489\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5693 - loss: 0.6894 - val_auc: 0.6272 - val_loss: 0.4758\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5859 - loss: 0.4974 - val_auc: 0.6331 - val_loss: 0.3727\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6156 - loss: 0.3883 - val_auc: 0.6391 - val_loss: 0.3200\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6557 - loss: 0.3301 - val_auc: 0.6479 - val_loss: 0.2976\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.7015 - loss: 0.3013 - val_auc: 0.6571 - val_loss: 0.2885\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.7408 - loss: 0.2866 - val_auc: 0.6646 - val_loss: 0.2840\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.7779 - loss: 0.2766 - val_auc: 0.6684 - val_loss: 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:53:31,029] Trial 3 finished with value: 0.6684173941612244 and parameters: {'hidden_units_idx': 2, 'learning_rate': 5e-05, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'label_smoothing': 0.05}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6684\n",
            "Test AUC: 0.6702\n",
            "Test Log Loss: 0.2002\n",
            "Training Time: 615.7s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.5, 'l2_reg': 0.001, 'l2_dense': 1e-05, 'hidden_units': [64, 32, 16], 'label_smoothing': 0.2}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - auc: 0.4945 - loss: 20.6317 - val_auc: 0.5424 - val_loss: 0.5651\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5241 - loss: 0.5868 - val_auc: 0.5588 - val_loss: 0.4477\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5396 - loss: 0.4783 - val_auc: 0.5743 - val_loss: 0.4193\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5597 - loss: 0.4420 - val_auc: 0.6027 - val_loss: 0.4128\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5857 - loss: 0.4274 - val_auc: 0.6321 - val_loss: 0.4092\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6086 - loss: 0.4189 - val_auc: 0.6572 - val_loss: 0.4071\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6295 - loss: 0.4134 - val_auc: 0.6726 - val_loss: 0.4060\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6453 - loss: 0.4101 - val_auc: 0.6804 - val_loss: 0.4052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:03:49,972] Trial 4 finished with value: 0.6803634762763977 and parameters: {'hidden_units_idx': 2, 'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.5, 'l2_reg': 0.001, 'l2_dense': 1e-05, 'label_smoothing': 0.2}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6804\n",
            "Test AUC: 0.6795\n",
            "Test Log Loss: 0.2401\n",
            "Training Time: 618.8s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'hidden_units': [128, 64, 32], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - auc: 0.4956 - loss: 1.4355 - val_auc: 0.4993 - val_loss: 0.8658\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5046 - loss: 0.9645 - val_auc: 0.5127 - val_loss: 0.6356\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5184 - loss: 0.7176 - val_auc: 0.5317 - val_loss: 0.5142\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5395 - loss: 0.5788 - val_auc: 0.5466 - val_loss: 0.4428\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5648 - loss: 0.4931 - val_auc: 0.5580 - val_loss: 0.4019\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5915 - loss: 0.4405 - val_auc: 0.5653 - val_loss: 0.3791\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.6227 - loss: 0.4059 - val_auc: 0.5740 - val_loss: 0.3661\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.6543 - loss: 0.3838 - val_auc: 0.5825 - val_loss: 0.3590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:12:23,139] Trial 5 finished with value: 0.5824745297431946 and parameters: {'hidden_units_idx': 0, 'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'label_smoothing': 0.1}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.5825\n",
            "Test AUC: 0.5833\n",
            "Test Log Loss: 0.2357\n",
            "Training Time: 513.1s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.5, 'l2_reg': 0.0001, 'l2_dense': 0.001, 'hidden_units': [256, 128, 64], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step - auc: 0.5341 - loss: 2.0654 - val_auc: 0.5674 - val_loss: 0.3886\n",
            "Epoch 2/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6180 - loss: 0.3691 - val_auc: 0.6188 - val_loss: 0.3322\n",
            "Epoch 3/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6506 - loss: 0.3302 - val_auc: 0.6663 - val_loss: 0.3199\n",
            "Epoch 4/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6625 - loss: 0.3224 - val_auc: 0.6689 - val_loss: 0.3172\n",
            "Epoch 5/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6708 - loss: 0.3176 - val_auc: 0.6870 - val_loss: 0.3128\n",
            "Epoch 6/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6826 - loss: 0.3136 - val_auc: 0.6897 - val_loss: 0.3114\n",
            "Epoch 7/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6866 - loss: 0.3124 - val_auc: 0.6905 - val_loss: 0.3109\n",
            "Epoch 8/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6876 - loss: 0.3120 - val_auc: 0.6911 - val_loss: 0.3107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:21:35,311] Trial 6 finished with value: 0.6910551190376282 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.5, 'l2_reg': 0.0001, 'l2_dense': 0.001, 'label_smoothing': 0.1}. Best is trial 6 with value: 0.6910551190376282.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6911\n",
            "Test AUC: 0.6903\n",
            "Test Log Loss: 0.2074\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6911\n",
            "Test AUC: 0.6903\n",
            "Test Log Loss: 0.2074\n",
            "Training Time: 552.1s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'hidden_units': [64, 32, 16], 'label_smoothing': 0.05}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - auc: 0.5420 - loss: 6.8381 - val_auc: 0.6411 - val_loss: 0.2732\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6306 - loss: 0.2793 - val_auc: 0.6702 - val_loss: 0.2654\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6615 - loss: 0.2680 - val_auc: 0.6829 - val_loss: 0.2614\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6780 - loss: 0.2629 - val_auc: 0.6881 - val_loss: 0.2588\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6846 - loss: 0.2601 - val_auc: 0.6902 - val_loss: 0.2570\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6870 - loss: 0.2583 - val_auc: 0.6912 - val_loss: 0.2559\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6883 - loss: 0.2572 - val_auc: 0.6914 - val_loss: 0.2553\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6889 - loss: 0.2566 - val_auc: 0.6914 - val_loss: 0.2550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:31:57,888] Trial 7 finished with value: 0.6914399266242981 and parameters: {'hidden_units_idx': 2, 'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'label_smoothing': 0.05}. Best is trial 7 with value: 0.6914399266242981.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6914\n",
            "Test AUC: 0.6907\n",
            "Test Log Loss: 0.1957\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6914\n",
            "Test AUC: 0.6907\n",
            "Test Log Loss: 0.1957\n",
            "Training Time: 622.5s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "Optuna Study Statistics:\n",
            "  Best Value: 0.6914\n",
            "  Best Trial: 7\n",
            "\n",
            "Parameter Importances:\n",
            "  batch_size: 0.5990\n",
            "  hidden_units_idx: 0.1240\n",
            "  label_smoothing: 0.1075\n",
            "  dropout_rate: 0.0522\n",
            "  learning_rate: 0.0504\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETED FOR DeepFM\n",
            "Total trials: 8\n",
            "Best validation AUC: 0.6914\n",
            "Best test AUC: 0.6907\n",
            "Best test log loss: 0.1957\n",
            "Best parameters: {'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'label_smoothing': 0.05, 'hidden_units': [64, 32, 16]}\n",
            "Total tuning time: 4563.4s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "================================================================================\n",
            "Best parameters saved to tuning_results/deepfm/DeepFM_best_params.json\n",
            "\n",
            "âš ï¸ REMINDER: Tuning used 10.0% of training data\n",
            "   For final model training, use these parameters with the FULL dataset!\n",
            "\n",
            "DeepFM Best Parameters:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 0.001\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.05\n",
            "    hidden_units: [64, 32, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# Baseline Hyperparameter Tuning\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BASELINE HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup Baseline tuner with Optuna\n",
        "baseline_tuner = ModelTuner(\n",
        "    model_type='Baseline',\n",
        "    model_data=model_data,\n",
        "    subsample_fraction=SUBSAMPLE_FRACTION,\n",
        "    save_dir='tuning_results/baseline',\n",
        "    current_user=CURRENT_USER,\n",
        "    current_time=CURRENT_TIME\n",
        ")\n",
        "\n",
        "# Run tuning\n",
        "baseline_tuning_results = baseline_tuner.run_tuning(n_trials=N_TRIALS)\n",
        "\n",
        "# Get best parameters\n",
        "baseline_best_params = baseline_tuning_results['best_params']\n",
        "\n",
        "print(\"\\nBaseline Best Parameters:\")\n",
        "for param, value in baseline_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n"
      ],
      "metadata": {
        "id": "jxvsNeO9tXrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d3ae15-365d-4dda-e256-ee77ecfa29b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BASELINE HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "Creating 10.0% subsample of training data...\n",
            "  Original training samples: 21,246,368\n",
            "  Subsampled training size: 2,124,636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:31:59,263] A new study created in memory with name: no-name-654c4d57-1475-4713-8bb7-fe5b800a81da\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original positive rate: 0.0515\n",
            "  Subsampled positive rate: 0.0514\n",
            "âœ… Subsample created successfully\n",
            "\n",
            "================================================================================\n",
            "STARTING HYPERPARAMETER TUNING FOR Baseline (USING 10.0% DATA) USING OPTUNA\n",
            "Number of trials: 8\n",
            "User: Muhammad Sultan Nurrochman\n",
            "Time: -\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'hidden_units': [128, 64], 'label_smoothing': 0.2}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - auc: 0.5005 - loss: 1.4148 - val_auc: 0.5307 - val_loss: 1.2355\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5051 - loss: 1.3484 - val_auc: 0.5549 - val_loss: 1.1765\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5088 - loss: 1.2843 - val_auc: 0.5730 - val_loss: 1.1213\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5111 - loss: 1.2256 - val_auc: 0.5855 - val_loss: 1.0712\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5127 - loss: 1.1707 - val_auc: 0.5947 - val_loss: 1.0252\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5129 - loss: 1.1215 - val_auc: 0.6012 - val_loss: 0.9833\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5121 - loss: 1.0755 - val_auc: 0.6068 - val_loss: 0.9441\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5158 - loss: 1.0327 - val_auc: 0.6110 - val_loss: 0.9088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:40:00,089] Trial 0 finished with value: 0.6109569668769836 and parameters: {'hidden_units_idx': 0, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'label_smoothing': 0.2}. Best is trial 0 with value: 0.6109569668769836.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6110\n",
            "Test AUC: 0.6110\n",
            "Test Log Loss: 0.6576\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6110\n",
            "Test AUC: 0.6110\n",
            "Test Log Loss: 0.6576\n",
            "Training Time: 480.8s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 0.0001, 'l2_dense': 0.001, 'hidden_units': [256, 128], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - auc: 0.5294 - loss: 1.9081 - val_auc: 0.6529 - val_loss: 0.3440\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6435 - loss: 0.3498 - val_auc: 0.6831 - val_loss: 0.3196\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6623 - loss: 0.3217 - val_auc: 0.6896 - val_loss: 0.3131\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6711 - loss: 0.3141 - val_auc: 0.6904 - val_loss: 0.3114\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6717 - loss: 0.3133 - val_auc: 0.6907 - val_loss: 0.3111\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6715 - loss: 0.3132 - val_auc: 0.6907 - val_loss: 0.3110\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6707 - loss: 0.3131 - val_auc: 0.6908 - val_loss: 0.3110\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6714 - loss: 0.3131 - val_auc: 0.6902 - val_loss: 0.3111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:48:00,852] Trial 1 finished with value: 0.6907510757446289 and parameters: {'hidden_units_idx': 2, 'learning_rate': 0.001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 0.0001, 'l2_dense': 0.001, 'label_smoothing': 0.1}. Best is trial 1 with value: 0.6907510757446289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6908\n",
            "Test AUC: 0.6900\n",
            "Test Log Loss: 0.2087\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6908\n",
            "Test AUC: 0.6900\n",
            "Test Log Loss: 0.2087\n",
            "Training Time: 480.7s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.5, 'l2_reg': 0.001, 'l2_dense': 0.001, 'hidden_units': [256, 128], 'label_smoothing': 0.2}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - auc: 0.5229 - loss: 52.2190 - val_auc: 0.5721 - val_loss: 46.2997\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5248 - loss: 44.7743 - val_auc: 0.5881 - val_loss: 39.6613\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5255 - loss: 38.3270 - val_auc: 0.5953 - val_loss: 33.8798\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5267 - loss: 32.7282 - val_auc: 0.5998 - val_loss: 28.8516\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5283 - loss: 27.8619 - val_auc: 0.6027 - val_loss: 24.4808\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5292 - loss: 23.6318 - val_auc: 0.6055 - val_loss: 20.6844\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5287 - loss: 19.9599 - val_auc: 0.6071 - val_loss: 17.3945\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5280 - loss: 16.7789 - val_auc: 0.6094 - val_loss: 14.5504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:56:01,879] Trial 2 finished with value: 0.6093747615814209 and parameters: {'hidden_units_idx': 2, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.5, 'l2_reg': 0.001, 'l2_dense': 0.001, 'label_smoothing': 0.2}. Best is trial 1 with value: 0.6907510757446289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6094\n",
            "Test AUC: 0.6093\n",
            "Test Log Loss: 0.5560\n",
            "Training Time: 481.0s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 0.001, 'l2_dense': 0.001, 'hidden_units': [128, 64], 'label_smoothing': 0.05}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - auc: 0.5223 - loss: 11.0280 - val_auc: 0.5405 - val_loss: 0.2960\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6158 - loss: 0.3006 - val_auc: 0.6798 - val_loss: 0.2692\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6542 - loss: 0.2708 - val_auc: 0.6869 - val_loss: 0.2622\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6584 - loss: 0.2632 - val_auc: 0.6904 - val_loss: 0.2582\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - auc: 0.6628 - loss: 0.2612 - val_auc: 0.6902 - val_loss: 0.2578\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6643 - loss: 0.2606 - val_auc: 0.6906 - val_loss: 0.2573\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - auc: 0.6656 - loss: 0.2603 - val_auc: 0.6902 - val_loss: 0.2571\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - auc: 0.6663 - loss: 0.2601 - val_auc: 0.6903 - val_loss: 0.2568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:04:03,199] Trial 3 finished with value: 0.6905850172042847 and parameters: {'hidden_units_idx': 0, 'learning_rate': 0.001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 0.001, 'l2_dense': 0.001, 'label_smoothing': 0.05}. Best is trial 1 with value: 0.6907510757446289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6906\n",
            "Test AUC: 0.6898\n",
            "Test Log Loss: 0.1972\n",
            "Training Time: 481.3s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'hidden_units': [64, 32], 'label_smoothing': 0.15}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - auc: 0.5189 - loss: 11.0976 - val_auc: 0.5885 - val_loss: 0.3835\n",
            "Epoch 2/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.5549 - loss: 0.3966 - val_auc: 0.6201 - val_loss: 0.3743\n",
            "Epoch 3/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.5974 - loss: 0.3817 - val_auc: 0.6429 - val_loss: 0.3684\n",
            "Epoch 4/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6237 - loss: 0.3734 - val_auc: 0.6763 - val_loss: 0.3652\n",
            "Epoch 5/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6457 - loss: 0.3680 - val_auc: 0.6870 - val_loss: 0.3633\n",
            "Epoch 6/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6632 - loss: 0.3652 - val_auc: 0.6899 - val_loss: 0.3622\n",
            "Epoch 7/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6730 - loss: 0.3636 - val_auc: 0.6909 - val_loss: 0.3615\n",
            "Epoch 8/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6777 - loss: 0.3628 - val_auc: 0.6909 - val_loss: 0.3610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:13:02,285] Trial 4 finished with value: 0.690935492515564 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'label_smoothing': 0.15}. Best is trial 4 with value: 0.690935492515564.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6909\n",
            "Test AUC: 0.6901\n",
            "Test Log Loss: 0.2233\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6909\n",
            "Test AUC: 0.6901\n",
            "Test Log Loss: 0.2233\n",
            "Training Time: 539.0s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 5e-05, 'batch_size': 4096, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.001, 'hidden_units': [64, 32], 'label_smoothing': 0.15}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - auc: 0.5186 - loss: 38.5748 - val_auc: 0.5722 - val_loss: 10.5664\n",
            "Epoch 2/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5339 - loss: 7.3812 - val_auc: 0.5867 - val_loss: 1.8640\n",
            "Epoch 3/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5375 - loss: 1.4504 - val_auc: 0.5959 - val_loss: 0.6561\n",
            "Epoch 4/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5376 - loss: 0.6726 - val_auc: 0.6022 - val_loss: 0.5170\n",
            "Epoch 5/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5413 - loss: 0.5649 - val_auc: 0.6056 - val_loss: 0.4661\n",
            "Epoch 6/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5415 - loss: 0.5114 - val_auc: 0.6113 - val_loss: 0.4313\n",
            "Epoch 7/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5473 - loss: 0.4714 - val_auc: 0.6194 - val_loss: 0.4094\n",
            "Epoch 8/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5550 - loss: 0.4437 - val_auc: 0.6282 - val_loss: 0.3975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:22:08,626] Trial 5 finished with value: 0.6281977891921997 and parameters: {'hidden_units_idx': 1, 'learning_rate': 5e-05, 'batch_size': 4096, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.001, 'label_smoothing': 0.15}. Best is trial 4 with value: 0.690935492515564.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6282\n",
            "Test AUC: 0.6285\n",
            "Test Log Loss: 0.2501\n",
            "Training Time: 546.3s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'hidden_units': [256, 128], 'label_smoothing': 0.0}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 31ms/step - auc: 0.5398 - loss: 1.6497 - val_auc: 0.6628 - val_loss: 0.1969\n",
            "Epoch 2/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6435 - loss: 0.2059 - val_auc: 0.6863 - val_loss: 0.1913\n",
            "Epoch 3/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - auc: 0.6705 - loss: 0.1951 - val_auc: 0.6889 - val_loss: 0.1900\n",
            "Epoch 4/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6801 - loss: 0.1926 - val_auc: 0.6900 - val_loss: 0.1896\n",
            "Epoch 5/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6829 - loss: 0.1918 - val_auc: 0.6905 - val_loss: 0.1894\n",
            "Epoch 6/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - auc: 0.6858 - loss: 0.1914 - val_auc: 0.6907 - val_loss: 0.1892\n",
            "Epoch 7/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - auc: 0.6867 - loss: 0.1911 - val_auc: 0.6908 - val_loss: 0.1890\n",
            "Epoch 8/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - auc: 0.6874 - loss: 0.1908 - val_auc: 0.6909 - val_loss: 0.1889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:31:15,375] Trial 6 finished with value: 0.6908634901046753 and parameters: {'hidden_units_idx': 2, 'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'label_smoothing': 0.0}. Best is trial 4 with value: 0.690935492515564.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6909\n",
            "Test AUC: 0.6902\n",
            "Test Log Loss: 0.1885\n",
            "Training Time: 546.7s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'hidden_units': [64, 32], 'label_smoothing': 0.0}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 24ms/step - auc: 0.5193 - loss: 0.6399 - val_auc: 0.6615 - val_loss: 0.2038\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6105 - loss: 0.2095 - val_auc: 0.6815 - val_loss: 0.1939\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6431 - loss: 0.1984 - val_auc: 0.6869 - val_loss: 0.1920\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6645 - loss: 0.1951 - val_auc: 0.6900 - val_loss: 0.1903\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6741 - loss: 0.1933 - val_auc: 0.6907 - val_loss: 0.1891\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6779 - loss: 0.1922 - val_auc: 0.6908 - val_loss: 0.1886\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6787 - loss: 0.1917 - val_auc: 0.6913 - val_loss: 0.1881\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - auc: 0.6793 - loss: 0.1914 - val_auc: 0.6911 - val_loss: 0.1880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:41:36,038] Trial 7 finished with value: 0.6912732720375061 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'label_smoothing': 0.0}. Best is trial 7 with value: 0.6912732720375061.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6913\n",
            "Test AUC: 0.6905\n",
            "Test Log Loss: 0.1887\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6913\n",
            "Test AUC: 0.6905\n",
            "Test Log Loss: 0.1887\n",
            "Training Time: 620.6s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "Optuna Study Statistics:\n",
            "  Best Value: 0.6913\n",
            "  Best Trial: 7\n",
            "\n",
            "Parameter Importances:\n",
            "  learning_rate: 0.4536\n",
            "  label_smoothing: 0.1969\n",
            "  l2_reg: 0.1285\n",
            "  dropout_rate: 0.0942\n",
            "  l2_dense: 0.0505\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETED FOR Baseline\n",
            "Total trials: 8\n",
            "Best validation AUC: 0.6913\n",
            "Best test AUC: 0.6905\n",
            "Best test log loss: 0.1887\n",
            "Best parameters: {'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'label_smoothing': 0.0, 'hidden_units': [64, 32]}\n",
            "Total tuning time: 4176.8s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "================================================================================\n",
            "Best parameters saved to tuning_results/baseline/Baseline_best_params.json\n",
            "\n",
            "âš ï¸ REMINDER: Tuning used 10.0% of training data\n",
            "   For final model training, use these parameters with the FULL dataset!\n",
            "\n",
            "Baseline Best Parameters:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.7\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.0\n",
            "    hidden_units: [64, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# Save All Best Parameters to One File\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING ALL BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Collect all best parameters\n",
        "all_best_params = {\n",
        "    'DIN-DICE': din_best_params,\n",
        "    'DIN-PReLU': din_prelu_best_params,\n",
        "    'DeepFM': deepfm_best_params,\n",
        "    'Baseline': baseline_best_params\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "with open('tuning_results/all_best_params.json', 'w') as f:\n",
        "    json.dump(all_best_params, f, indent=4)\n",
        "\n",
        "print(f\"All best parameters saved to: tuning_results/all_best_params.json\")\n",
        "\n",
        "# =====================================================================\n",
        "# Plot Comparison of Best Models\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARING MODEL PERFORMANCE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Collect test metrics\n",
        "models = ['DIN-DICE', 'DIN-PReLU', 'DeepFM', 'Baseline']\n",
        "test_aucs = [\n",
        "    din_tuning_results['best_test_auc'],\n",
        "    din_prelu_tuning_results['best_test_auc'],\n",
        "    deepfm_tuning_results['best_test_auc'],\n",
        "    baseline_tuning_results['best_test_auc']\n",
        "]\n",
        "test_loglosses = [\n",
        "    din_tuning_results['best_test_logloss'],\n",
        "    din_prelu_tuning_results['best_test_logloss'],\n",
        "    deepfm_tuning_results['best_test_logloss'],\n",
        "    baseline_tuning_results['best_test_logloss']\n",
        "]\n",
        "\n",
        "# Plot AUC comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(models, test_aucs, color=['lightblue', 'lightgreen', 'coral', 'lightgray'])\n",
        "plt.ylabel('Test AUC')\n",
        "plt.title('Comparison of Model Performance (AUC)')\n",
        "plt.ylim(0.5, 1.0)  # AUC range\n",
        "\n",
        "# Add values above bars\n",
        "for i, v in enumerate(test_aucs):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('tuning_results/model_auc_comparison.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Plot Log Loss comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(models, test_loglosses, color=['lightblue', 'lightgreen', 'coral', 'lightgray'])\n",
        "plt.ylabel('Test Log Loss')\n",
        "plt.title('Comparison of Model Performance (Log Loss)')\n",
        "\n",
        "# Add values above bars\n",
        "for i, v in enumerate(test_loglosses):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('tuning_results/model_logloss_comparison.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Performance comparison plots saved!\")\n",
        "print(f\"Hyperparameter tuning complete for all models!\")"
      ],
      "metadata": {
        "id": "mg0WWU7etegB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "outputId": "398a085c-e164-4891-e3e2-1b8c2d4dba30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SAVING ALL BEST PARAMETERS\n",
            "============================================================\n",
            "All best parameters saved to: tuning_results/all_best_params.json\n",
            "\n",
            "============================================================\n",
            "COMPARING MODEL PERFORMANCE\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance comparison plots saved!\n",
            "Hyperparameter tuning complete for all models!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 7: TRAIN ALL MODELS WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN ALL MODELS WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create best_hyperparameters.json from tuning results\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Option 1: If all_best_params.json exists from previous cell\n",
        "if os.path.exists('tuning_results/all_best_params.json'):\n",
        "    print(\"Loading parameters from combined results file...\")\n",
        "    with open('tuning_results/all_best_params.json', 'r') as f:\n",
        "        best_params = json.load(f)\n",
        "\n",
        "# Option 2: Load individual parameter files\n",
        "else:\n",
        "    print(\"Loading parameters from individual model files...\")\n",
        "    best_params = {}\n",
        "\n",
        "    # DIN-DICE best parameters\n",
        "    din_files = [f for f in os.listdir('tuning_results/din_dice') if f.endswith('_best_params.json')]\n",
        "    if din_files:\n",
        "        with open(f'tuning_results/din_dice/{din_files[0]}', 'r') as f:\n",
        "            best_params['DIN-DICE'] = json.load(f)\n",
        "\n",
        "    # DIN-PReLU best parameters\n",
        "    prelu_files = [f for f in os.listdir('tuning_results/din_prelu') if f.endswith('_best_params.json')]\n",
        "    if prelu_files:\n",
        "        with open(f'tuning_results/din_prelu/{prelu_files[0]}', 'r') as f:\n",
        "            best_params['DIN-PReLU'] = json.load(f)\n",
        "\n",
        "    # DeepFM best parameters\n",
        "    deepfm_files = [f for f in os.listdir('tuning_results/deepfm') if f.endswith('_best_params.json')]\n",
        "    if deepfm_files:\n",
        "        with open(f'tuning_results/deepfm/{deepfm_files[0]}', 'r') as f:\n",
        "            best_params['DeepFM'] = json.load(f)\n",
        "\n",
        "    # Baseline best parameters\n",
        "    baseline_files = [f for f in os.listdir('tuning_results/baseline') if f.endswith('_best_params.json')]\n",
        "    if baseline_files:\n",
        "        with open(f'tuning_results/baseline/{baseline_files[0]}', 'r') as f:\n",
        "            best_params['Baseline'] = json.load(f)\n",
        "\n",
        "    # Save all parameters to a single file for future use\n",
        "    with open('best_hyperparameters.json', 'w') as f:\n",
        "        json.dump(best_params, f, indent=4)\n",
        "\n",
        "    print(\"Combined parameters saved to 'best_hyperparameters.json'\")\n",
        "\n",
        "# Display the loaded parameters\n",
        "print(\"\\nLoaded best parameters:\")\n",
        "for model, params in best_params.items():\n",
        "    print(f\"\\n{model} best parameters:\")\n",
        "    for param, value in params.items():\n",
        "        print(f\"    {param}: {value}\")\n"
      ],
      "metadata": {
        "id": "gEHrIPB9gD3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e88cd4f-dfee-44ff-92b4-88d15fe979ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN ALL MODELS WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Loading parameters from combined results file...\n",
            "\n",
            "Loaded best parameters:\n",
            "\n",
            "DIN-DICE best parameters:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.4\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    dice_alpha_init: 0.35\n",
            "    dice_beta_init: 1.0\n",
            "    dice_epsilon: 1e-09\n",
            "    attention_hidden: 16\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n",
            "\n",
            "DIN-PReLU best parameters:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 5e-05\n",
            "    l2_dense: 5e-05\n",
            "    prelu_alpha_init: 0.35\n",
            "    attention_hidden: 8\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n",
            "\n",
            "DeepFM best parameters:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 0.001\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.05\n",
            "    hidden_units: [64, 32, 16]\n",
            "\n",
            "Baseline best parameters:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.7\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.0\n",
            "    hidden_units: [64, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# =====================================================================\n",
        "# 1. TRAIN DIN-DICE WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN DIN-DICE WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get best parameters\n",
        "din_best_params = best_params['DIN-DICE']\n",
        "\n",
        "print(\"Best Parameters for DIN-DICE:\")\n",
        "for param, value in din_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n",
        "\n",
        "# Create new DIN-DICE model with best parameters\n",
        "def create_optimized_din_dice_model():\n",
        "    \"\"\"Create DIN-DICE model dengan best parameters dari tuning\"\"\"\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = din_best_params['hidden_units']\n",
        "    attention_hidden = din_best_params['attention_hidden']\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = din_best_params['dropout_rate']\n",
        "    l2_reg = din_best_params['l2_reg']\n",
        "    l2_dense = din_best_params['l2_dense']\n",
        "\n",
        "    print(f\"Building DIN-DICE with optimal parameters:\")\n",
        "    print(f\"    Attention hidden: {attention_hidden}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 reg: {l2_reg}\")\n",
        "    print(f\"    L2 dense: {l2_dense}\")\n",
        "    print(f\"    DICE Î±_init: {din_best_params['dice_alpha_init']}\")\n",
        "    print(f\"    DICE Î²_init: {din_best_params['dice_beta_init']}\")\n",
        "    print(f\"    DICE Îµ: {din_best_params['dice_epsilon']}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "    seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    target_item_emb = item_embedding_layer(item_input)\n",
        "    sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "    # DIN Attention mechanism\n",
        "    attention_scores, attended_emb = DINAttention(\n",
        "        hidden_units=attention_hidden,\n",
        "        max_seq_len=max_seq_len,\n",
        "        activation_type='dice',  # Tambahkan parameter ini\n",
        "        dice_alpha_init=din_best_params['dice_alpha_init'],  # Tambahkan parameter ini\n",
        "        dice_beta_init=din_best_params['dice_beta_init'],    # Tambahkan parameter ini\n",
        "        dice_epsilon=din_best_params['dice_epsilon'],        # Tambahkan parameter ini\n",
        "        name='din_attention'\n",
        "    )([sequence_emb, target_item_emb])\n",
        "\n",
        "    # Sequence pooling\n",
        "    pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "        [attention_scores, attended_emb, seq_length_input]\n",
        "    )\n",
        "\n",
        "    # Feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        target_item_emb,\n",
        "        pooled_sequence,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK dengan DICE activation\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "\n",
        "        # DICE activation dengan parameter optimal\n",
        "        dice = DiceActivation(\n",
        "            name=f'dice_{i+1}',\n",
        "            alpha_init=din_best_params['dice_alpha_init'],\n",
        "            beta_init=din_best_params['dice_beta_init'],\n",
        "            epsilon=din_best_params['dice_epsilon']\n",
        "        )\n",
        "        x = dice(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='din_dice_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DIN-DICE model with best parameters\n",
        "print(f\"Creating DIN-DICE model with best parameters...\")\n",
        "din_dice_model = create_optimized_din_dice_model()\n",
        "\n",
        "# Compile DIN-DICE model with best parameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=din_best_params['learning_rate'],\n",
        "    beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
        "    clipnorm=0.5\n",
        ")\n",
        "metrics = [\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "# LOSS dengan label smoothing optimal\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=din_best_params['label_smoothing'])\n",
        "\n",
        "din_dice_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(f\"DIN-DICE model created successfully with optimal parameters!\")\n",
        "print(f\"Model summary:\")\n",
        "print(f\"    Total parameters: {din_dice_model.count_params():,}\")\n",
        "print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in din_dice_model.trainable_weights]):,}\")\n",
        "\n",
        "# Run manual training with best parameters\n",
        "print(f\"\\nStarting DIN-DICE training with best parameters...\")\n",
        "din_dice_results = manual_training_loop_din_dice(\n",
        "    model=din_dice_model,\n",
        "    batch_size=8192,\n",
        "    save_csv=True\n",
        ")"
      ],
      "metadata": {
        "id": "tRn3IiqOm5PX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d80ea54d-3f01-460c-8686-da381e6565de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN DIN-DICE WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Best Parameters for DIN-DICE:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.4\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    dice_alpha_init: 0.35\n",
            "    dice_beta_init: 1.0\n",
            "    dice_epsilon: 1e-09\n",
            "    attention_hidden: 16\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n",
            "Creating DIN-DICE model with best parameters...\n",
            "Building DIN-DICE with optimal parameters:\n",
            "    Attention hidden: 16\n",
            "    Dropout rate: 0.4\n",
            "    L2 reg: 1e-05\n",
            "    L2 dense: 0.0001\n",
            "    DICE Î±_init: 0.35\n",
            "    DICE Î²_init: 1.0\n",
            "    DICE Îµ: 1e-09\n",
            "DIN-DICE model created successfully with optimal parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,660,002\n",
            "    Trainable parameters: 63,659,618\n",
            "\n",
            "Starting DIN-DICE training with best parameters...\n",
            "STARTING DIN-DICE TRAINING:\n",
            "  Batch size: 8192\n",
            "  Epochs: 15\n",
            "  Early stopping patience: 4\n",
            "Epoch 1/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.2086, AUC: 0.6754\n",
            "  Val   Loss: 0.1825, AUC: 0.7312\n",
            "Epoch 2/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.1738, AUC: 0.7866\n",
            "  Val   Loss: 0.1851, AUC: 0.7237\n",
            "Epoch 3/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.1621, AUC: 0.8320\n",
            "  Val   Loss: 0.1962, AUC: 0.7049\n",
            "Epoch 4/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.1483, AUC: 0.8727\n",
            "  Val   Loss: 0.2187, AUC: 0.6854\n",
            "Epoch 5/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.1306, AUC: 0.9110\n",
            "  Val   Loss: 0.2619, AUC: 0.6618\n",
            "Early stopping triggered after 5 epochs!\n",
            "\n",
            "Training completed. Evaluating final model on test set...\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Best epoch: 1\n",
            "  Best validation AUC: 0.7312\n",
            "  Test AUC: 0.7315\n",
            "  Test log loss: 0.1836\n",
            "  Training time: 3757.6s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results saved to din_dice_training_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# 2. TRAIN DIN-PRELU WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN DIN-PRELU WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get best parameters\n",
        "din_prelu_best_params = best_params['DIN-PReLU']\n",
        "\n",
        "print(\"Best Parameters for DIN-PReLU:\")\n",
        "for param, value in din_prelu_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n",
        "\n",
        "# Create new DIN-PReLU model with best parameters\n",
        "def create_optimized_din_prelu_model():\n",
        "    \"\"\"Create DIN-PReLU model dengan best parameters dari tuning\"\"\"\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = din_prelu_best_params['hidden_units']\n",
        "    attention_hidden = din_prelu_best_params['attention_hidden']\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = din_prelu_best_params['dropout_rate']\n",
        "    l2_reg = din_prelu_best_params['l2_reg']\n",
        "    l2_dense = din_prelu_best_params['l2_dense']\n",
        "\n",
        "    print(f\"Building DIN-PReLU with optimal parameters:\")\n",
        "    print(f\"    Attention hidden: {attention_hidden}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 reg: {l2_reg}\")\n",
        "    print(f\"    L2 dense: {l2_dense}\")\n",
        "    print(f\"    PReLU Î±_init: {din_prelu_best_params['prelu_alpha_init']}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "    seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    target_item_emb = item_embedding_layer(item_input)\n",
        "    sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "    # DIN Attention mechanism\n",
        "    attention_scores, attended_emb = DINAttention(\n",
        "        hidden_units=attention_hidden,\n",
        "        max_seq_len=max_seq_len,\n",
        "        activation_type='prelu',  # Tambahkan parameter ini\n",
        "        prelu_alpha_init=din_prelu_best_params['prelu_alpha_init'],  # Tambahkan parameter ini\n",
        "        name='din_attention'\n",
        "    )([sequence_emb, target_item_emb])\n",
        "\n",
        "    # Sequence pooling\n",
        "    pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "        [attention_scores, attended_emb, seq_length_input]\n",
        "    )\n",
        "\n",
        "    # Feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        target_item_emb,\n",
        "        pooled_sequence,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK dengan PReLU activation\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "\n",
        "        # PReLU activation dengan parameter optimal\n",
        "        x = tf.keras.layers.PReLU(\n",
        "            alpha_initializer=tf.keras.initializers.Constant(din_prelu_best_params['prelu_alpha_init']),\n",
        "            name=f'prelu_{i+1}'\n",
        "        )(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='din_prelu_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DIN-PReLU model with best parameters\n",
        "print(f\"Creating DIN-PReLU model with best parameters...\")\n",
        "din_prelu_model = create_optimized_din_prelu_model()\n",
        "\n",
        "# Compile DIN-PReLU model with best parameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=din_prelu_best_params['learning_rate'],\n",
        "    beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
        "    clipnorm=0.5\n",
        ")\n",
        "metrics = [\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "# LOSS dengan label smoothing optimal\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=din_prelu_best_params['label_smoothing'])\n",
        "\n",
        "din_prelu_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(f\"DIN-PReLU model created successfully with optimal parameters!\")\n",
        "print(f\"Model summary:\")\n",
        "print(f\"    Total parameters: {din_prelu_model.count_params():,}\")\n",
        "print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in din_prelu_model.trainable_weights]):,}\")\n",
        "\n",
        "# Run manual training with best parameters\n",
        "print(f\"\\nStarting DIN-PReLU training with best parameters...\")\n",
        "din_prelu_results = manual_training_loop_din_prelu(\n",
        "    model=din_prelu_model,\n",
        "    batch_size=8192,\n",
        "    save_csv=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "pIlBjx7cm49_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6b88cc7-cbbe-4f57-e468-e7bdee2d67b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN DIN-PRELU WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Best Parameters for DIN-PReLU:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 5e-05\n",
            "    l2_dense: 5e-05\n",
            "    prelu_alpha_init: 0.35\n",
            "    attention_hidden: 8\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n",
            "Creating DIN-PReLU model with best parameters...\n",
            "Building DIN-PReLU with optimal parameters:\n",
            "    Attention hidden: 8\n",
            "    Dropout rate: 0.3\n",
            "    L2 reg: 5e-05\n",
            "    L2 dense: 5e-05\n",
            "    PReLU Î±_init: 0.35\n",
            "DIN-PReLU model created successfully with optimal parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,658,578\n",
            "    Trainable parameters: 63,658,194\n",
            "\n",
            "Starting DIN-PReLU training with best parameters...\n",
            "STARTING DIN-PReLU TRAINING:\n",
            "  Batch size: 8192\n",
            "  Epochs: 15\n",
            "  Early stopping patience: 4\n",
            "  Test set evaluation: Only at end of training\n",
            "Epoch 1/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.2057, AUC: 0.6821\n",
            "  Val   Loss: 0.1822, AUC: 0.7318\n",
            "Epoch 2/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.1731, AUC: 0.7887\n",
            "  Val   Loss: 0.1847, AUC: 0.7234\n",
            "Epoch 3/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.1613, AUC: 0.8343\n",
            "  Val   Loss: 0.1951, AUC: 0.7031\n",
            "Epoch 4/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.1468, AUC: 0.8754\n",
            "  Val   Loss: 0.2169, AUC: 0.6804\n",
            "Epoch 5/15\n",
            "  Batch 100/2594\n",
            "  Batch 200/2594\n",
            "  Batch 300/2594\n",
            "  Batch 400/2594\n",
            "  Batch 500/2594\n",
            "  Batch 600/2594\n",
            "  Batch 700/2594\n",
            "  Batch 800/2594\n",
            "  Batch 900/2594\n",
            "  Batch 1000/2594\n",
            "  Batch 1100/2594\n",
            "  Batch 1200/2594\n",
            "  Batch 1300/2594\n",
            "  Batch 1400/2594\n",
            "  Batch 1500/2594\n",
            "  Batch 1600/2594\n",
            "  Batch 1700/2594\n",
            "  Batch 1800/2594\n",
            "  Batch 1900/2594\n",
            "  Batch 2000/2594\n",
            "  Batch 2100/2594\n",
            "  Batch 2200/2594\n",
            "  Batch 2300/2594\n",
            "  Batch 2400/2594\n",
            "  Batch 2500/2594\n",
            "  Train Loss: 0.1296, AUC: 0.9114\n",
            "  Val   Loss: 0.2548, AUC: 0.6606\n",
            "Early stopping triggered after 5 epochs!\n",
            "\n",
            "Training completed. Evaluating final model on test set...\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Best epoch: 1\n",
            "  Best validation AUC: 0.7318\n",
            "  Test AUC: 0.7321\n",
            "  Test log loss: 0.1832\n",
            "  Training time: 3253.1s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results saved to din_prelu_training_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# 3. TRAIN DEEPFM WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN DEEPFM WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get best parameters\n",
        "deepfm_best_params = best_params['DeepFM']\n",
        "\n",
        "print(\"Best Parameters for DeepFM:\")\n",
        "for param, value in deepfm_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n",
        "\n",
        "# Create new DeepFM model with best parameters\n",
        "def create_optimized_deepfm_model():\n",
        "    \"\"\"Create DeepFM model with best parameters\"\"\"\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = deepfm_best_params['hidden_units']\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = deepfm_best_params['dropout_rate']\n",
        "    l2_reg = deepfm_best_params['l2_reg']\n",
        "    l2_dense = deepfm_best_params['l2_dense']\n",
        "\n",
        "    print(f\"Building DeepFM with optimal parameters:\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 reg: {l2_reg}\")\n",
        "    print(f\"    L2 dense: {l2_dense}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "    # FM PART: Factorization Machine component\n",
        "\n",
        "    # LINEAR PART\n",
        "    user_linear = tf.keras.layers.Dense(1, use_bias=False, name='user_linear',\n",
        "                                      kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(user_emb)\n",
        "    item_linear = tf.keras.layers.Dense(1, use_bias=False, name='item_linear',\n",
        "                                      kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(item_emb)\n",
        "    dense_linear = tf.keras.layers.Dense(1, use_bias=False, name='dense_linear',\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "\n",
        "    # INTERACTION PART\n",
        "    # User-Item interaction\n",
        "    user_item_interaction = tf.keras.layers.Multiply(name='user_item_mult')([user_emb, item_emb])\n",
        "\n",
        "    # User-Dense interaction\n",
        "    user_dense_proj = tf.keras.layers.Dense(embedding_dim, name='user_dense_proj',\n",
        "                                          kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "    user_dense_interaction = tf.keras.layers.Multiply(name='user_dense_mult')([user_emb, user_dense_proj])\n",
        "\n",
        "    # Item-Dense interaction\n",
        "    item_dense_proj = tf.keras.layers.Dense(embedding_dim, name='item_dense_proj',\n",
        "                                          kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "    item_dense_interaction = tf.keras.layers.Multiply(name='item_dense_mult')([item_emb, item_dense_proj])\n",
        "\n",
        "    # Sum all interactions\n",
        "    fm_interactions = tf.keras.layers.Add(name='fm_interactions')([\n",
        "        user_item_interaction,\n",
        "        user_dense_interaction,\n",
        "        item_dense_interaction\n",
        "    ])\n",
        "    fm_interaction_sum = tf.keras.layers.Dense(1, name='fm_interaction_sum',\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(fm_interactions)\n",
        "\n",
        "    # FM output\n",
        "    fm_output = tf.keras.layers.Add(name='fm_output')([\n",
        "        user_linear,\n",
        "        item_linear,\n",
        "        dense_linear,\n",
        "        fm_interaction_sum\n",
        "    ])\n",
        "\n",
        "    # DEEP PART: Deep Neural Network component\n",
        "\n",
        "    # Concatenate all features untuk deep part\n",
        "    deep_features = tf.keras.layers.Concatenate(name='deep_features')([\n",
        "        user_emb,\n",
        "        item_emb,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK\n",
        "    x = deep_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation='relu',\n",
        "            name=f'deep_dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'deep_dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'deep_bn_{i+1}')(x)\n",
        "\n",
        "    # DEEP OUTPUT\n",
        "    deep_output = tf.keras.layers.Dense(1, name='deep_output',\n",
        "                                      kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # COMBINE FM + DEEP\n",
        "    combined_output = tf.keras.layers.Add(name='fm_deep_combine')([fm_output, deep_output])\n",
        "\n",
        "    # Final activation\n",
        "    final_output = tf.keras.layers.Activation('sigmoid', name='final_output')(combined_output)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, dense_input],\n",
        "        outputs=final_output,\n",
        "        name='deepfm_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DeepFM model with best parameters\n",
        "print(f\"Creating DeepFM model with best parameters...\")\n",
        "deepfm_model = create_optimized_deepfm_model()\n",
        "\n",
        "# Create DeepFM dataset\n",
        "deepfm_data = create_deepfm_dataset()\n",
        "\n",
        "# Compile DeepFM model with best parameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=deepfm_best_params['learning_rate'],\n",
        "    beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
        "    clipnorm=0.5\n",
        ")\n",
        "metrics = [\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "# LOSS dengan label smoothing optimal\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=deepfm_best_params['label_smoothing'])\n",
        "\n",
        "deepfm_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(f\"DeepFM model created successfully with optimal parameters!\")\n",
        "print(f\"Model summary:\")\n",
        "print(f\"    Total parameters: {deepfm_model.count_params():,}\")\n",
        "print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in deepfm_model.trainable_weights]):,}\")\n",
        "\n",
        "# Train DeepFM with best parameters\n",
        "print(f\"\\nStarting DeepFM training with best parameters...\")\n",
        "deepfm_results = train_deepfm_model(\n",
        "    model=deepfm_model,\n",
        "    batch_size=deepfm_best_params['batch_size'],\n",
        "    save_csv=True\n",
        ")"
      ],
      "metadata": {
        "id": "nty8aYzAm47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b83d1f11-3395-4e78-fbd5-e57066236af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN DEEPFM WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Best Parameters for DeepFM:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 0.001\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.05\n",
            "    hidden_units: [64, 32, 16]\n",
            "Creating DeepFM model with best parameters...\n",
            "Building DeepFM with optimal parameters:\n",
            "    Hidden units: [64, 32, 16]\n",
            "    Dropout rate: 0.3\n",
            "    L2 reg: 0.001\n",
            "    L2 dense: 0.0001\n",
            "Creating DeepFM dataset...\n",
            "DeepFM model created successfully with optimal parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,643,189\n",
            "    Trainable parameters: 63,642,965\n",
            "\n",
            "Starting DeepFM training with best parameters...\n",
            "STARTING DEEPFM TRAINING:\n",
            "  Batch size: 2048\n",
            "  Epochs: 15\n",
            "  Early stopping patience: 4\n",
            "  Test set evaluation: Only at end of training\n",
            "Creating DeepFM dataset...\n",
            "Epoch 1/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 17ms/step - auc: 0.6061 - loss: 1.2937 - precision: 0.0762 - recall: 0.0567 - val_auc: 0.6911 - val_loss: 0.2547 - val_precision: 0.6605 - val_recall: 0.0121\n",
            "Epoch 2/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 17ms/step - auc: 0.6895 - loss: 0.2554 - precision: 0.6739 - recall: 0.0116 - val_auc: 0.6913 - val_loss: 0.2544 - val_precision: 0.6634 - val_recall: 0.0120\n",
            "Epoch 3/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 17ms/step - auc: 0.6898 - loss: 0.2551 - precision: 0.6814 - recall: 0.0112 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6675 - val_recall: 0.0119\n",
            "Epoch 4/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 17ms/step - auc: 0.6898 - loss: 0.2551 - precision: 0.6826 - recall: 0.0111 - val_auc: 0.6912 - val_loss: 0.2543 - val_precision: 0.6683 - val_recall: 0.0119\n",
            "Epoch 5/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 17ms/step - auc: 0.6899 - loss: 0.2551 - precision: 0.6823 - recall: 0.0110 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6654 - val_recall: 0.0120\n",
            "Epoch 6/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 16ms/step - auc: 0.6899 - loss: 0.2550 - precision: 0.6818 - recall: 0.0111 - val_auc: 0.6911 - val_loss: 0.2543 - val_precision: 0.6678 - val_recall: 0.0119\n",
            "Epoch 7/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 16ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6849 - recall: 0.0111 - val_auc: 0.6912 - val_loss: 0.2543 - val_precision: 0.6687 - val_recall: 0.0119\n",
            "Epoch 8/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 17ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6818 - recall: 0.0110 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6686 - val_recall: 0.0119\n",
            "Epoch 9/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 16ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6842 - recall: 0.0110 - val_auc: 0.6912 - val_loss: 0.2543 - val_precision: 0.6676 - val_recall: 0.0119\n",
            "Epoch 10/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 16ms/step - auc: 0.6899 - loss: 0.2550 - precision: 0.6818 - recall: 0.0111 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6689 - val_recall: 0.0119\n",
            "Epoch 11/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 16ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6858 - recall: 0.0111 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6776 - val_recall: 0.0114\n",
            "Epoch 12/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 16ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6788 - recall: 0.0110 - val_auc: 0.6914 - val_loss: 0.2543 - val_precision: 0.6686 - val_recall: 0.0119\n",
            "Epoch 13/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 17ms/step - auc: 0.6901 - loss: 0.2550 - precision: 0.6829 - recall: 0.0111 - val_auc: 0.6912 - val_loss: 0.2543 - val_precision: 0.6717 - val_recall: 0.0117\n",
            "Epoch 14/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 17ms/step - auc: 0.6901 - loss: 0.2550 - precision: 0.6812 - recall: 0.0111 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6686 - val_recall: 0.0119\n",
            "Epoch 15/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 17ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6823 - recall: 0.0111 - val_auc: 0.6914 - val_loss: 0.2543 - val_precision: 0.6717 - val_recall: 0.0118\n",
            "Restored best weights from epoch 12\n",
            "\n",
            "Training completed. Evaluating final model on test set...\n",
            "\u001b[1m1297/1297\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - auc: 0.6914 - loss: 0.2553 - precision: 0.6779 - recall: 0.0127\n",
            "\u001b[1m1297/1297\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Best epoch: 12\n",
            "  Best validation AUC: 0.6914\n",
            "  Test AUC: 0.6908\n",
            "  Test Log Loss: 0.1949\n",
            "  Training time: 2619.9s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results saved to deepfm_training_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# 4. TRAIN BASELINE WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN BASELINE WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get best parameters\n",
        "baseline_best_params = best_params['Baseline']\n",
        "\n",
        "print(\"Best Parameters for Baseline:\")\n",
        "for param, value in baseline_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n",
        "\n",
        "# Create new Baseline model with best parameters\n",
        "def create_optimized_baseline_model():\n",
        "    \"\"\"Create Baseline model with best parameters\"\"\"\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = baseline_best_params['hidden_units']\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = baseline_best_params['dropout_rate']\n",
        "    l2_reg = baseline_best_params['l2_reg']\n",
        "    l2_dense = baseline_best_params['l2_dense']\n",
        "\n",
        "    print(f\"Building Baseline with optimal parameters:\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 reg: {l2_reg}\")\n",
        "    print(f\"    L2 dense: {l2_dense}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "    # Simple feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        item_emb,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # FEEDFORWARD NETWORK\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation='relu',\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='baseline_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create Baseline model with best parameters\n",
        "print(f\"Creating Baseline model with best parameters...\")\n",
        "baseline_model = create_optimized_baseline_model()\n",
        "\n",
        "# Create Baseline dataset\n",
        "baseline_data = create_baseline_dataset()\n",
        "\n",
        "# Compile Baseline model with best parameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=baseline_best_params['learning_rate'],\n",
        "    beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
        "    clipnorm=0.5\n",
        ")\n",
        "metrics = [\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "# LOSS dengan label smoothing optimal\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=baseline_best_params['label_smoothing'])\n",
        "\n",
        "baseline_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(f\"Baseline model created successfully with optimal parameters!\")\n",
        "print(f\"Model summary:\")\n",
        "print(f\"    Total parameters: {baseline_model.count_params():,}\")\n",
        "print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in baseline_model.trainable_weights]):,}\")\n",
        "\n",
        "# Train Baseline with best parameters\n",
        "print(f\"\\nStarting Baseline training with best parameters...\")\n",
        "baseline_results = train_baseline_model(\n",
        "    model=baseline_model,\n",
        "    batch_size=baseline_best_params['batch_size'],\n",
        "    save_csv=True\n",
        ")"
      ],
      "metadata": {
        "id": "IHeiAjk1m44x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed89f315-b8ed-4316-adb0-c98120bf0e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN BASELINE WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Best Parameters for Baseline:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.7\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.0\n",
            "    hidden_units: [64, 32]\n",
            "Creating Baseline model with best parameters...\n",
            "Building Baseline with optimal parameters:\n",
            "    Hidden units: [64, 32]\n",
            "    Dropout rate: 0.7\n",
            "    L2 reg: 1e-05\n",
            "    L2 dense: 0.0001\n",
            "Creating Baseline dataset...\n",
            "Baseline model created successfully with optimal parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,641,217\n",
            "    Trainable parameters: 63,641,025\n",
            "\n",
            "Starting Baseline training with best parameters...\n",
            "STARTING BASELINE TRAINING:\n",
            "  Batch size: 2048\n",
            "  Epochs: 15\n",
            "  Early stopping patience: 4\n",
            "  Test set evaluation: Only at end of training\n",
            "Creating Baseline dataset...\n",
            "Epoch 1/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 16ms/step - auc: 0.6044 - loss: 0.2757 - precision: 0.0756 - recall: 0.0482 - val_auc: 0.6912 - val_loss: 0.1879 - val_precision: 0.9506 - val_recall: 0.0061\n",
            "Epoch 2/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6808 - loss: 0.1904 - precision: 0.5480 - recall: 0.0073 - val_auc: 0.6912 - val_loss: 0.1879 - val_precision: 0.9188 - val_recall: 0.0063\n",
            "Epoch 3/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6811 - loss: 0.1903 - precision: 0.5546 - recall: 0.0074 - val_auc: 0.6913 - val_loss: 0.1879 - val_precision: 0.7628 - val_recall: 0.0087\n",
            "Epoch 4/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6809 - loss: 0.1903 - precision: 0.5426 - recall: 0.0072 - val_auc: 0.6913 - val_loss: 0.1878 - val_precision: 0.7175 - val_recall: 0.0099\n",
            "Epoch 5/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6810 - loss: 0.1903 - precision: 0.5433 - recall: 0.0073 - val_auc: 0.6914 - val_loss: 0.1878 - val_precision: 0.6717 - val_recall: 0.0118\n",
            "Epoch 6/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 16ms/step - auc: 0.6812 - loss: 0.1902 - precision: 0.5442 - recall: 0.0074 - val_auc: 0.6915 - val_loss: 0.1878 - val_precision: 0.9272 - val_recall: 0.0063\n",
            "Epoch 7/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 16ms/step - auc: 0.6811 - loss: 0.1903 - precision: 0.5389 - recall: 0.0072 - val_auc: 0.6913 - val_loss: 0.1879 - val_precision: 0.9506 - val_recall: 0.0061\n",
            "Epoch 8/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6807 - loss: 0.1903 - precision: 0.5524 - recall: 0.0074 - val_auc: 0.6911 - val_loss: 0.1879 - val_precision: 0.9474 - val_recall: 0.0061\n",
            "Epoch 9/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6809 - loss: 0.1902 - precision: 0.5540 - recall: 0.0074 - val_auc: 0.6912 - val_loss: 0.1879 - val_precision: 0.7902 - val_recall: 0.0081\n",
            "Epoch 10/15\n",
            "\u001b[1m10372/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - auc: 0.6809 - loss: 0.1903 - precision: 0.5485 - recall: 0.0074Early stopping triggered after 10 epochs!\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6809 - loss: 0.1903 - precision: 0.5485 - recall: 0.0074 - val_auc: 0.6913 - val_loss: 0.1879 - val_precision: 0.9311 - val_recall: 0.0063\n",
            "Restored best weights from epoch 6\n",
            "\n",
            "Training completed. Evaluating final model on test set...\n",
            "\u001b[1m1297/1297\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - auc: 0.6915 - loss: 0.1891 - precision: 0.9172 - recall: 0.0072\n",
            "\u001b[1m1297/1297\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Best epoch: 6\n",
            "  Best validation AUC: 0.6915\n",
            "  Test AUC: 0.6908\n",
            "  Test Log Loss: 0.1886\n",
            "  Training time: 1685.7s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results saved to baseline_training_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# OVERALL TRAINING SUMMARY\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"OVERALL TRAINING SUMMARY WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a comparison table of results\n",
        "training_summary = {\n",
        "    'Model': [],\n",
        "    'Val AUC': [],\n",
        "    'Test AUC': [],\n",
        "    'Test LogLoss': [],\n",
        "    'Training Time': [],\n",
        "    'Parameters': []\n",
        "}\n",
        "\n",
        "if 'din_dice_results' in locals() and din_dice_results.get('success'):\n",
        "    training_summary['Model'].append('DIN-DICE')\n",
        "    training_summary['Val AUC'].append(f\"{din_dice_results['best_val_auc']:.4f}\")\n",
        "    training_summary['Test AUC'].append(f\"{din_dice_results['best_test_auc']:.4f}\")\n",
        "    training_summary['Test LogLoss'].append(f\"{din_dice_results['best_test_logloss']:.4f}\")\n",
        "    training_summary['Training Time'].append(f\"{din_dice_results['training_time']:.1f}s\")\n",
        "    training_summary['Parameters'].append(f\"{din_dice_model.count_params():,}\")\n",
        "\n",
        "if 'din_prelu_results' in locals() and din_prelu_results.get('success'):\n",
        "    training_summary['Model'].append('DIN-PReLU')\n",
        "    training_summary['Val AUC'].append(f\"{din_prelu_results['best_val_auc']:.4f}\")\n",
        "    training_summary['Test AUC'].append(f\"{din_prelu_results['best_test_auc']:.4f}\")\n",
        "    training_summary['Test LogLoss'].append(f\"{din_prelu_results['best_test_logloss']:.4f}\")\n",
        "    training_summary['Training Time'].append(f\"{din_prelu_results['training_time']:.1f}s\")\n",
        "    training_summary['Parameters'].append(f\"{din_prelu_model.count_params():,}\")\n",
        "\n",
        "if 'deepfm_results' in locals() and deepfm_results.get('success'):\n",
        "    training_summary['Model'].append('DeepFM')\n",
        "    training_summary['Val AUC'].append(f\"{deepfm_results['best_val_auc']:.4f}\")\n",
        "    training_summary['Test AUC'].append(f\"{deepfm_results['best_test_auc']:.4f}\")\n",
        "    training_summary['Test LogLoss'].append(f\"{deepfm_results['best_test_logloss']:.4f}\")\n",
        "    training_summary['Training Time'].append(f\"{deepfm_results['training_time']:.1f}s\")\n",
        "    training_summary['Parameters'].append(f\"{deepfm_model.count_params():,}\")\n",
        "\n",
        "if 'baseline_results' in locals() and baseline_results.get('success'):\n",
        "    training_summary['Model'].append('Baseline')\n",
        "    training_summary['Val AUC'].append(f\"{baseline_results['best_val_auc']:.4f}\")\n",
        "    training_summary['Test AUC'].append(f\"{baseline_results['best_test_auc']:.4f}\")\n",
        "    training_summary['Test LogLoss'].append(f\"{baseline_results['best_test_logloss']:.4f}\")\n",
        "    training_summary['Training Time'].append(f\"{baseline_results['training_time']:.1f}s\")\n",
        "    training_summary['Parameters'].append(f\"{baseline_model.count_params():,}\")\n",
        "\n",
        "# Display summary table\n",
        "training_df = pd.DataFrame(training_summary)\n",
        "print(\"\\nOPTIMIZED MODELS PERFORMANCE SUMMARY:\")\n",
        "print(training_df)\n",
        "\n",
        "# Save summary to CSV\n",
        "summary_path = \"training_summary_optimized.csv\"\n",
        "training_df.to_csv(summary_path, index=False)\n",
        "print(f\"\\nSummary saved to {summary_path}\")\n",
        "\n",
        "# Create a comparison plot for Test AUC\n",
        "plt.figure(figsize=(12, 6))\n",
        "models = training_summary['Model']\n",
        "test_aucs = [float(auc) for auc in training_summary['Test AUC']]\n",
        "plt.bar(models, test_aucs, color='lightcoral')\n",
        "plt.title('Test AUC Comparison (Optimized Models)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Test AUC')\n",
        "plt.ylim(0.5, 1.0)\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(test_aucs):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_auc_comparison_optimized.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Create a comparison plot for Test LogLoss\n",
        "plt.figure(figsize=(12, 6))\n",
        "test_logloss = [float(loss) for loss in training_summary['Test LogLoss']]\n",
        "plt.bar(models, test_logloss, color='lightgreen')\n",
        "plt.title('Test Log Loss Comparison (Optimized Models)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Test Log Loss')\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(test_logloss):\n",
        "    plt.text(i, v - 0.02, f'{v:.4f}', ha='center', color='black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_logloss_comparison_optimized.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Final Output\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETED FOR ALL OPTIMIZED MODELS!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nThe hyperparameter tuning and optimized training process has been completed.\")\n",
        "print(\"All models have been trained with their best parameters from hyperparameter tuning.\")\n",
        "print(\"The results show both validation and test performance metrics.\")\n",
        "print(\"The best model based on test AUC is:\", training_summary['Model'][np.argmax(test_aucs)])\n",
        "print(\"The best model based on test LogLoss is:\", training_summary['Model'][np.argmin(test_logloss)])"
      ],
      "metadata": {
        "id": "YSKP1G-6m42I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c775faa-dcfe-400f-fe70-916563dbe82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "OVERALL TRAINING SUMMARY WITH BEST PARAMETERS\n",
            "============================================================\n",
            "\n",
            "OPTIMIZED MODELS PERFORMANCE SUMMARY:\n",
            "       Model Val AUC Test AUC Test LogLoss Training Time  Parameters\n",
            "0   DIN-DICE  0.7312   0.7315       0.1836       3757.6s  63,660,002\n",
            "1  DIN-PReLU  0.7318   0.7321       0.1832       3253.1s  63,658,578\n",
            "2     DeepFM  0.6914   0.6908       0.1949       2619.9s  63,643,189\n",
            "3   Baseline  0.6915   0.6908       0.1886       1685.7s  63,641,217\n",
            "\n",
            "Summary saved to training_summary_optimized.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAW5JJREFUeJzt3Xm8l3P+P/7Had9UtEsKyTJMCMkyg4msYxsi80FkLBlLX+tYEkPf7xg0xpI9Q9EwZsxYItnGWCfCIDQiWwlTURSd9+8Pv87HcU6c6nQdk/v9dnvfeL+u13Vdz+v9Pu/L+/3wul5XWalUKgUAAAAAClSvrgsAAAAA4PtHKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAsBTOPvvslJWV1XUZ3+iPf/xjVllllXzyySd1XUq6deuWQw45pFa3WVZWlrPPPrtWt/ltvuvv+0MPPZSysrI89NBDS7zuqFGjUlZWljfeeKPG63z44Ydp3rx57r777iXeHwAIpQD4XiorK6vRY2l+2H3dvHnzcvbZZy/Vtu6+++6UlZVl1VVXTXl5ebV9ysrKcswxx1S77LbbblvscTz00EPZe++907FjxzRq1Cjt27fP7rvvnttvv71GtS1cuDDXX399tt1226yyyipp3LhxunXrloEDB+af//xnjY+R5WPhwoUZOnRofvnLX6ZFixaVln3++ee55JJLstlmm2WllVZKixYtstlmm+WSSy7J559/vtT7fOyxx3L22Wdn1qxZy1j9f79DDjkkZWVladmyZT799NMqy1977bWK88xvf/vbOqiwdrRp0yaDBg3KmWeeWdelAPBfqEFdFwAAdeHGG2+s9PwPf/hDxo8fX6V9vfXWW+Z9zZs3L8OGDUuSbLvttku07ujRo9OtW7e88cYbeeCBB9K3b99lridJhg4dmnPOOSdrr712jjjiiHTt2jUffvhh7r777uyzzz4ZPXp0BgwYsNj1P/300+y9994ZN25cfvSjH+VXv/pVVllllbzxxhv54x//mBtuuCHTpk3LaqutViv1fhedccYZOfXUU+u6jMX629/+lldeeSW/+MUvKrXPnTs3u+66ax5++OHstttuOeSQQ1KvXr2MGzcuxx13XG6//fbcddddad68+RLv87HHHsuwYcNyyCGHpHXr1pWWvfLKK6lXr3b/f+inn36aBg2+u19nGzRokHnz5uVvf/tb9ttvv0rLRo8enSZNmuSzzz6ro+pqz5FHHplLLrkkDzzwQLbffvu6LgeA/yLf3f+KA8By9POf/7zS8yeeeCLjx4+v0l6X5s6dmzvuuCPDhw/P9ddfn9GjR9dKKHXbbbflnHPOyc9+9rOMGTMmDRs2rFh20kkn5d577/3W0TInnXRSxo0bl4svvjjHH398pWVDhw7NxRdfvMx1flfNnTs3zZs3T4MGDb7Tgcj111+frbbaKp07d67UPmTIkDz88MP5/e9/X2mE3VFHHZXLLrssxxxzTE488cRcccUVtVpP48aNa3V7SdKkSZNa32Ztaty4cbbaaqvcfPPNVUKpMWPGZNddd82f/vSnOqqu9qy33nrZYIMNMmrUKKEUAEvE5XsAsBjl5eUZMWJEfvCDH6RJkybp0KFDjjjiiPznP/+p1O+f//xn+vXrl7Zt26Zp06ZZY401cuihhyZJ3njjjbRr1y5JMmzYsIrLdWoyD86f//znfPrpp9l3332z//775/bbb6+VURVnnnlmVllllVx33XWVAqlF+vXrl912222x67/99tu58sors8MOO1QJpJKkfv36OfHEEyuNknr22Wez8847p2XLlmnRokV+8pOf5Iknnqi03qL5bB599NEce+yxadeuXVq3bp0jjjgiCxYsyKxZs3LQQQdl5ZVXzsorr5yTTz45pVKpYv033nij4lKoiy++OF27dk3Tpk3z4x//OP/6178q7ev555/PIYcckjXXXDNNmjRJx44dc+ihh+bDDz+s1G/R/EEvvfRSBgwYkJVXXjlbb711pWVfNX78+Gy99dZp3bp1WrRokXXWWSe/+tWvKvV5//33c9hhh6VDhw5p0qRJevbsmRtuuKFSn68ey1VXXZW11lorjRs3zmabbZann356se/NIp999lnGjRtXJcR8++23c+2112b77bev9pLPwYMHZ7vttss111yTt99+u6J90SWio0ePzjrrrJMmTZqkV69eeeSRRyq9VieddFKSZI011qj4W180P9HX55Ra1vd7UV2LPkuLXrPFPb7qySefzE477ZRWrVqlWbNm+fGPf5x//OMfVV6PRx99NJtttlmaNGmStdZaK1deeeW3vvZfN2DAgNxzzz2VLml8+umn89prry12NOLrr7+efffdN6usskqaNWuWLbbYInfddVeVfm+//Xb23HPPNG/ePO3bt88JJ5yQ+fPnV7vNmh7z133T+e2rdthhh/ztb3+r8h4BwDf57v7vPQCoY0cccURGjRqVgQMH5thjj83UqVNz6aWX5tlnn80//vGPNGzYMO+//3523HHHtGvXLqeeempat26dN954o2Jepnbt2uWKK67IUUcdlb322it77713kuSHP/zht+5/9OjR2W677dKxY8fsv//+OfXUU/O3v/0t++6771If02uvvZbJkyfn0EMPzUorrbRU27jnnnvyxRdf5H/+539q1P/FF1/MNttsk5YtW+bkk09Ow4YNc+WVV2bbbbfNww8/nN69e1fq/8tf/jIdO3bMsGHD8sQTT+Sqq65K69at89hjj2X11VfP+eefn7vvvjsXXHBBNthggxx00EGV1v/DH/6Qjz/+OIMHD85nn32W3/3ud9l+++3zwgsvpEOHDkm+DI9ef/31DBw4MB07dsyLL76Yq666Ki+++GKeeOKJKiHGvvvum7XXXjvnn3/+Yn90v/jii9ltt93ywx/+MOecc04aN26cKVOmVPrh/+mnn2bbbbfNlClTcswxx2SNNdbIrbfemkMOOSSzZs3KcccdV2mbY8aMyccff5wjjjgiZWVl+c1vfpO99947r7/+erWB4iITJ07MggULsskmm1Rqv+eee7Jw4cIqr9lXHXTQQXnwwQczbty4DBo0qKL94YcfztixY3PsscemcePGufzyy7PTTjvlqaeeygYbbJC99947r776am6++eZcfPHFadu2bZJUhLKLs6zv9yLt2rWrcvnt559/nhNOOCGNGjWqaHvggQey8847p1evXhk6dGjq1auX66+/Pttvv33+/ve/Z/PNN0+SvPDCCxWf7bPPPjtffPFFhg4dWvE3VFN77713jjzyyNx+++0VYc6YMWOy7rrrVnl/kmTGjBnZcsstM2/evBx77LFp06ZNbrjhhvz0pz/Nbbfdlr322ivJl39LP/nJTzJt2rQce+yxWXXVVXPjjTfmgQceqLLNmh7z133b+e2revXqlYsvvjgvvvhiNthggyV6jQD4HisBAKXBgweXvvqfxb///e+lJKXRo0dX6jdu3LhK7X/+859LSUpPP/30Yrc9c+bMUpLS0KFDa1zPjBkzSg0aNChdffXVFW1bbrllaY899qjSN0lp8ODB1W7n1ltvLSUpPfjgg6VSqVS64447SklKF198cY1r+boTTjihlKT07LPP1qj/nnvuWWrUqFHp3//+d0Xbu+++W1pppZVKP/rRjyrarr/++lKSUr9+/Url5eUV7X369CmVlZWVjjzyyIq2L774orTaaquVfvzjH1e0TZ06tZSk1LRp09Lbb79d0f7kk0+WkpROOOGEirZ58+ZVqfPmm28uJSk98sgjFW1Dhw4tJSkdcMABVfovWrbIxRdfXEpSmjlz5mJfixEjRpSSlG666aaKtgULFpT69OlTatGiRWnOnDmVjqVNmzaljz76qKLvovfvb3/722L3USqVStdcc00pSemFF16o1H788cd/63v3zDPPlJKUhgwZUtGWpJSk9M9//rOi7c033yw1adKktNdee1W0XXDBBaUkpalTp1bZbteuXUsHH3xwxfNlfb8X1fVNn6ujjz66VL9+/dIDDzxQKpVKpfLy8tLaa69dZZ/z5s0rrbHGGqUddtihom3PPfcsNWnSpPTmm29WtL300kul+vXrl2ryFfrggw8uNW/evFQqlUo/+9nPSj/5yU9KpVKptHDhwlLHjh1Lw4YNq3ifL7jggor1Fr1Hf//73yvaPv7449Iaa6xR6tatW2nhwoWlUul//5b++Mc/VvSbO3duqXv37pU+80tyzIvek0XvX03Ob4s89thjpSSlsWPHfmtfAFjE5XsAUI1bb701rVq1yg477JAPPvig4tGrV6+0aNEiDz74YJJUTOZ85513LtNdy77ulltuSb169bLPPvtUtB1wwAG55557qlw+uCTmzJmTJEs9SmpJt7Fw4cLcd9992XPPPbPmmmtWtHfq1CkDBgzIo48+WrG9RQ477LBKI5V69+6dUqmUww47rKKtfv362XTTTfP6669X2eeee+5ZaR6lzTffPL179650y/qmTZtW/Ptnn32WDz74IFtssUWS5JlnnqmyzSOPPPJbj3XR38Idd9yx2Dsl3n333enYsWMOOOCAiraGDRvm2GOPzSeffJKHH364Uv/+/ftn5ZVXrni+zTbbJEm1x/1Viy5D/Oq6SfLxxx8n+eb3btGyr78vffr0Sa9evSqer7766tljjz1y7733ZuHChd9YzzdZ1vd7cf7whz/k8ssvz29+85tst912SZJJkyZVXDb34YcfVnyu586dm5/85Cd55JFHUl5enoULF+bee+/NnnvumdVXX71im+utt1769eu3xMc4YMCAPPTQQ5k+fXoeeOCBTJ8+fbGX7t19993ZfPPNKy4TTZIWLVrkF7/4Rd5444289NJLFf06deqUn/3sZxX9mjVrVmVi+5oec3WW5Py26G/tgw8++OYXAwC+QigFANV47bXXMnv27LRv3z7t2rWr9Pjkk0/y/vvvJ0l+/OMfZ5999smwYcPStm3b7LHHHrn++usXO69LTd10003ZfPPN8+GHH2bKlCmZMmVKNt544yxYsCC33nrrEm9v0Y/+li1bJvnfcGJpLMk2Zs6cmXnz5mWdddapsmy99dZLeXl53nrrrUrtXw0BkqRVq1ZJki5dulRpry6gW3vttau09ejRo2JuoyT56KOPctxxx6VDhw5p2rRp2rVrlzXWWCNJMnv27CrrL1r2Tfr375+tttoqgwYNSocOHbL//vvnj3/8Y6Uf/G+++WbWXnvtKnehW3SXxzfffLNS+9dfi0U//GsaTJa+dqnhosDpm967xQVXi3td582bl5kzZ9aonuos6/tdnUmTJuXII4/MAQcckCFDhlS0v/baa0mSgw8+uMrn+pprrsn8+fMze/bszJw5M59++mm1x1zd3/K32WWXXbLSSitl7NixGT16dDbbbLN079692r5vvvnmYj8vi5Yv+mf37t2rXGr69XVreszVWZLz26K/ta/XAwDfxJxSAFCN8vLytG/fPqNHj652+aJ5csrKynLbbbfliSeeyN/+9rfce++9OfTQQ3PhhRfmiSeeSIsWLZZ436+99lrFZNbV/SgePXp0pdEQjRs3zqefflrttubNm5fkf+9Stu666yb5cr6cpfXVbWy00UZLvZ3FqV+/fo3bvx661NR+++2Xxx57LCeddFI22mijtGjRIuXl5dlpp52qHTXy1ZFVi9O0adM88sgjefDBB3PXXXdl3LhxGTt2bLbffvvcd999iz2ub7K4db7tuNu0aZPky/DqqxPOLwo2nn/++cW+d88//3ySZP3111/ScpdKbb/f//nPf7LPPvukR48eueaaayotW/TeXnDBBYs9/hYtWixzqPx1jRs3zt57750bbrghr7/+eo1udFBbanrM1VmS89uiwHDRXGIAUBNCKQCoxlprrZX7778/W221VY0CiS222CJbbLFFzjvvvIwZMyYHHnhgbrnllgwaNGiJRw6MHj06DRs2zI033ljlh/mjjz6aSy65JNOmTasYYdK1a9e88sor1W5rUXvXrl2TfDmyZZ111skdd9yR3/3ud0sVmu28886pX79+brrppm+d7Lxdu3Zp1qxZtfVNnjw59erVqzIiZlktGhnyVa+++mq6deuW5MsfzxMmTMiwYcNy1llnfeN6S6pevXr5yU9+kp/85Ce56KKLcv755+f000/Pgw8+mL59+6Zr1655/vnnU15eXmm01OTJk5P87/u0rBYFh1OnTs2GG25Y0b7ovbvxxhsXO2H4H/7whzRo0CA77bRTpfbFva7NmjWrFNLWpfLy8hx44IGZNWtW7r///jRr1qzS8rXWWivJl6P9vn5nwq9q165dmjZtWu0xL+6z9m0GDBiQ6667LvXq1cv++++/2H6L+zx//W+ka9eu+de//pVSqVTpdf/6ujU95m/yTee3RaZOnZrkf4NPAKgJl+8BQDX222+/LFy4MOeee26VZV988UXF7d3/85//VBm9sWg0wqLRFot+GH/1lvDfZPTo0dlmm23Sv3///OxnP6v0OOmkk5IkN998c0X/XXbZJU888UQmTpxYaTuzZs3K6NGjs9FGG6Vjx44V7cOGDcuHH36YQYMG5Ysvvqiy//vuuy933nnnYuvr0qVLDj/88Nx33335/e9/X2V5eXl5Lrzwwrz99tupX79+dtxxx9xxxx2VLp+bMWNGxowZk6233rricsDa8pe//CXvvPNOxfOnnnoqTz75ZHbeeeck/zsC5+vv24gRI5Zpvx999FGVtq//Leyyyy6ZPn16xo4dW9Hniy++yO9///u0aNEiP/7xj5ephkV69eqVRo0a5Z///Gel9i5dumTgwIG5//77c8UVV1RZb+TIkXnggQdy2GGHVRphlSSPP/54pfm23nrrrdxxxx3ZcccdK17T5s2bJ6n533ptGzZsWO69997cfPPN1V5y2atXr6y11lr57W9/m08++aTK8kWXIdavXz/9+vXLX/7yl0ybNq1i+csvv5x77713qWrbbrvtcu655+bSSy+t9Hn8ul122SVPPfVUHn/88Yq2uXPn5qqrrkq3bt0qRrDtsssueffdd3PbbbdV9Js3b16uuuqqpTrm6tTk/LbIxIkT06pVq/zgBz9Y7PYA4OuMlAKAavz4xz/OEUcckeHDh2fSpEnZcccd07Bhw7z22mu59dZb87vf/S4/+9nPcsMNN+Tyyy/PXnvtlbXWWisff/xxrr766rRs2TK77LJLki8v61p//fUzduzY9OjRI6ussko22GCDam+b/uSTT2bKlCk55phjqq2rc+fO2WSTTTJ69OiccsopSZJTTz01t956a370ox/liCOOyLrrrpt33303o0aNynvvvZfrr7++0jb69++fF154Ieedd16effbZHHDAAenatWs+/PDDjBs3LhMmTMiYMWO+8fW58MIL8+9//zvHHntsbr/99uy2225ZeeWVM23atNx6662ZPHlyxWiQX//61xk/fny23nrrHH300WnQoEGuvPLKzJ8/P7/5zW+W+L35Nt27d8/WW2+do446KvPnz8+IESPSpk2bnHzyyUm+HDHyox/9KL/5zW/y+eefp3PnzrnvvvsqRnosrXPOOSePPPJIdt1113Tt2jXvv/9+Lr/88qy22moVk1b/4he/yJVXXplDDjkkEydOTLdu3XLbbbflH//4R0aMGLFME9B/VZMmTbLjjjvm/vvvzznnnFNp2cUXX5zJkyfn6KOPzrhx4ypGRN17772544478uMf/zgXXnhhlW1usMEG6devX4499tg0btw4l19+eZIvg6BFFk2Efvrpp2f//fdPw4YNs/vuu1eEVcvTCy+8kHPPPTc/+tGP8v777+emm26qtPznP/956tWrl2uuuSY777xzfvCDH2TgwIHp3Llz3nnnnTz44INp2bJl/va3v1Uc17hx47LNNtvk6KOPrggPf/CDH1Rc4rgk6tWrlzPOOONb+5166qm5+eabs/POO+fYY4/NKquskhtuuCFTp07Nn/70p4oRdocffnguvfTSHHTQQZk4cWI6deqUG2+8scrosCU55q+ryfltkfHjx2f33Xev89FyAPyXqaO7/gHAd8rgwYOrvc37VVddVerVq1epadOmpZVWWqm04YYblk4++eTSu+++WyqVSqVnnnmmdMABB5RWX331UuPGjUvt27cv7bbbbqV//vOflbbz2GOPlXr16lVq1KjRN97G/pe//GUpSenf//73Yms9++yzS0lKzz33XEXb22+/XRo0aFCpc+fOpQYNGpRWWWWV0m677VZ64oknFrudCRMmlPbYY49S+/btSw0aNCi1a9eutPvuu5fuuOOOb3qpKnzxxRela665prTNNtuUWrVqVWrYsGGpa9eupYEDB5aeffbZSn2feeaZUr9+/UotWrQoNWvWrLTddtuVHnvssUp9Ft2O/uu3nx86dGgpSWnmzJmV2g8++OBS8+bNK55PnTq1lKR0wQUXlC688MJSly5dSo0bNy5ts802lV6rRa/XXnvtVWrdunWpVatWpX333bf07rvvVnlvFrfvry77+uu56qqrlho1alRaddVVSwcccEDp1VdfrbTejBkzSgMHDiy1bdu21KhRo9KGG25Yuv766yv1+eqxfN03/f181e23314qKysrTZs2rcqy+fPnly6++OJSr169Ss2bNy81a9astMkmm5RGjBhRWrBgQbX7HDx4cOmmm24qrb322qXGjRuXNt5449KDDz5Ype+5555b6ty5c6levXqlJKWpU6eWSqVSqWvXrqWDDz64ot+yvt9ffy0efPDBUpLFPr7q2WefLe29996lNm3alBo3blzq2rVrab/99itNmDChUr+HH3644nO75pprlkaOHFnlfV+c6ur9usW9z//+979LP/vZz0qtW7cuNWnSpLT55puX7rzzzirrv/nmm6Wf/vSnpWbNmpXatm1bOu6440rjxo0rJany3tTkmBe9J4ves5qe315++eVSktL999//ra8LAHxVWam0lDOEAgB8h7zxxhtZY401csEFF+TEE0+s63Lq3MKFC7P++utnv/32q/Yy1CVRVlaWwYMH59JLL62l6liRHH/88XnkkUcyceJEI6UAWCLmlAIAWAHVr18/55xzTi677LJq5xKC2vDhhx/mmmuuya9//WuBFABLzJxSAAArqP79+6d///51XQYrsDZt2gg9AVhqRkoBAAAAULg6DaUeeeSR7L777ll11VVTVlaWv/zlL9+6zkMPPZRNNtkkjRs3Tvfu3TNq1KjlXicA8N3XrVu3lEol80ktB6VSyXxSAECtq9NQau7cuenZs2cuu+yyGvWfOnVqdt1112y33XaZNGlSjj/++AwaNCj33nvvcq4UAAAAgNr0nbn7XllZWf785z9nzz33XGyfU045JXfddVf+9a9/VbTtv//+mTVrVsaNG1dAlQAAAADUhv+qic4ff/zx9O3bt1Jbv379cvzxxy92nfnz52f+/PkVz8vLy/PRRx+lTZs27hACAAAAUMtKpVI+/vjjrLrqqqlXb/EX6f1XhVLTp09Phw4dKrV16NAhc+bMyaeffpqmTZtWWWf48OEZNmxYUSUCAAAAkOStt97Kaqutttjl/1Wh1NI47bTTMmTIkIrns2fPzuqrr5633norLVu2rMPKAAAAAFY8c+bMSZcuXbLSSit9Y7//qlCqY8eOmTFjRqW2GTNmpGXLltWOkkqSxo0bp3HjxlXaW7ZsKZQCAAAAWE6+bdqkOr373pLq06dPJkyYUKlt/Pjx6dOnTx1VBAAAAMDSqNNQ6pNPPsmkSZMyadKkJMnUqVMzadKkTJs2LcmXl94ddNBBFf2PPPLIvP766zn55JMzefLkXH755fnjH/+YE044oS7KBwAAAGAp1Wko9c9//jMbb7xxNt544yTJkCFDsvHGG+ess85Kkrz33nsVAVWSrLHGGrnrrrsyfvz49OzZMxdeeGGuueaa9OvXr07qBwAAAGDplJVKpVJdF1GkOXPmpFWrVpk9e7Y5pQAAAABqWU2zl/+qOaUAAAAAWDEIpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAoXJ2HUpdddlm6deuWJk2apHfv3nnqqacW2/fzzz/POeeck7XWWitNmjRJz549M27cuAKrBQAAAKA21GkoNXbs2AwZMiRDhw7NM888k549e6Zfv355//33q+1/xhln5Morr8zvf//7vPTSSznyyCOz11575dlnny24cgAAAACWRVmpVCrV1c579+6dzTbbLJdeemmSpLy8PF26dMkvf/nLnHrqqVX6r7rqqjn99NMzePDgirZ99tknTZs2zU033VSjfc6ZMyetWrXK7Nmz07Jly9o5EAAAAACS1Dx7qbORUgsWLMjEiRPTt2/f/y2mXr307ds3jz/+eLXrzJ8/P02aNKnU1rRp0zz66KOL3c/8+fMzZ86cSg8AAAAA6ladhVIffPBBFi5cmA4dOlRq79ChQ6ZPn17tOv369ctFF12U1157LeXl5Rk/fnxuv/32vPfee4vdz/Dhw9OqVauKR5cuXWr1OAAAAABYcnU+0fmS+N3vfpe111476667bho1apRjjjkmAwcOTL16iz+M0047LbNnz654vPXWWwVWDAAAAEB16iyUatu2berXr58ZM2ZUap8xY0Y6duxY7Trt2rXLX/7yl8ydOzdvvvlmJk+enBYtWmTNNddc7H4aN26cli1bVnoAAAAAULfqLJRq1KhRevXqlQkTJlS0lZeXZ8KECenTp883rtukSZN07tw5X3zxRf70pz9ljz32WN7lAgAAAFCLGtTlzocMGZKDDz44m266aTbffPOMGDEic+fOzcCBA5MkBx10UDp37pzhw4cnSZ588sm888472WijjfLOO+/k7LPPTnl5eU4++eS6PAwAAAAAllCdhlL9+/fPzJkzc9ZZZ2X69OnZaKONMm7cuIrJz6dNm1ZpvqjPPvssZ5xxRl5//fW0aNEiu+yyS2688ca0bt26jo4AAAAAgKVRViqVSnVdRJHmzJmTVq1aZfbs2eaXAgAAAKhlNc1e/qvuvgcAAADAikEoBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDhhFIAAAAAFE4oBQAAAEDh6jyUuuyyy9KtW7c0adIkvXv3zlNPPfWN/UeMGJF11lknTZs2TZcuXXLCCSfks88+K6haAAAAAGpDnYZSY8eOzZAhQzJ06NA888wz6dmzZ/r165f333+/2v5jxozJqaeemqFDh+bll1/Otddem7Fjx+ZXv/pVwZUDAAAAsCzqNJS66KKLcvjhh2fgwIFZf/31M3LkyDRr1izXXXddtf0fe+yxbLXVVhkwYEC6deuWHXfcMQcccMC3jq4CAAAA4LulzkKpBQsWZOLEienbt+//FlOvXvr27ZvHH3+82nW23HLLTJw4sSKEev3113P33Xdnl112Wex+5s+fnzlz5lR6AAAAAFC3GtTVjj/44IMsXLgwHTp0qNTeoUOHTJ48udp1BgwYkA8++CBbb711SqVSvvjiixx55JHfePne8OHDM2zYsFqtHQAAAIBlU+cTnS+Jhx56KOeff34uv/zyPPPMM7n99ttz11135dxzz13sOqeddlpmz55d8XjrrbcKrBgAAACA6tTZSKm2bdumfv36mTFjRqX2GTNmpGPHjtWuc+aZZ+Z//ud/MmjQoCTJhhtumLlz5+YXv/hFTj/99NSrVzVja9y4cRo3blz7BwAAAADAUquzkVKNGjVKr169MmHChIq28vLyTJgwIX369Kl2nXnz5lUJnurXr58kKZVKy69YAAAAAGpVnY2USpIhQ4bk4IMPzqabbprNN988I0aMyNy5czNw4MAkyUEHHZTOnTtn+PDhSZLdd989F110UTbeeOP07t07U6ZMyZlnnpndd9+9IpwCAAAA4LuvTkOp/v37Z+bMmTnrrLMyffr0bLTRRhk3blzF5OfTpk2rNDLqjDPOSFlZWc4444y88847adeuXXbfffecd955dXUIAAAAACyFstL37Lq3OXPmpFWrVpk9e3ZatmxZ1+UAAAAArFBqmr38V919DwAAAIAVg1AKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMLVOJRauHBhnn/++Xz66adVls2bNy/PP/98ysvLa7U4AAAAAFZMNQ6lbrzxxhx66KFp1KhRlWWNGjXKoYcemjFjxtRqcQAAAACsmGocSl177bU58cQTU79+/SrLGjRokJNPPjlXXXVVrRYHAAAAwIqpxqHUK6+8ki222GKxyzfbbLO8/PLLtVIUAAAAACu2GodSc+fOzZw5cxa7/OOPP868efNqpSgAAAAAVmw1DqXWXnvtPPbYY4td/uijj2bttdeulaIAAAAAWLHVOJQaMGBAzjjjjDz//PNVlj333HM566yzMmDAgFotDgAAAIAVU1mpVCrVpOPnn3+eHXfcMY8++mj69u2bddddN0kyefLk3H///dlqq60yfvz4NGzYcLkWvKzmzJmTVq1aZfbs2WnZsmVdlwMAAACwQqlp9lLjUCr5Mpi6+OKLM2bMmLz22msplUrp0aNHBgwYkOOPPz6NGjWqleKXJ6EUAAAAwPKzXEKpFYFQCgAAAGD5qWn20mBJNlid5s2bp379+kteIQAAAADfWzWe6Lx169ZZeeWVqzyaNm2addZZJ1dfffXyrBMAAACAFUiNR0o9+OCD1bbPmjUrEydOzEknnZQGDRpk4MCBtVYcAAAAACumWptT6rrrrsull16aZ555pjY2t9yYUwoAAABg+alp9lLjy/e+zY9//ONMmTKltjYHAAAAwAqs1kKp2bNnp1WrVrW1OQAAAABWYLUSSn3++ee54IIL0rt379rYHAAAAAAruBpPdL733ntX2z579uy8+OKLKSsry9///vdaKwwAAACAFVeNQ6nFXZrXpUuX7LPPPjnwwANdvgcAAABAjdQ4lLr++uuXZx0AAAAAfI/UypxSc+bMyRVXXJFNN920NjYHAAAAwAquxiOlqvPggw/muuuuy+23355WrVplr732qq26AAAAAFiBLXEo9c4772TUqFG5/vrrM2vWrPznP//JmDFjst9++6WsrGx51AgAAADACqbGl+/96U9/yi677JJ11lknkyZNyoUXXph333039erVy4YbbiiQAgAAAKDGajxSqn///jnllFMyduzYrLTSSsuzJgAAAABWcDUeKXXYYYflsssuy0477ZSRI0fmP//5z/KsCwAAAIAVWI1DqSuvvDLvvfdefvGLX+Tmm29Op06dsscee6RUKqW8vHx51ggAAADACqbGoVSSNG3aNAcffHAefvjhvPDCC/nBD36QDh06ZKuttsqAAQNy++23L686AeA76bLLLku3bt3SpEmT9O7dO0899dRi+2677bYpKyur8th1110r+px99tlZd91107x586y88srp27dvnnzyyYrlb7zxRg477LCsscYaadq0adZaa60MHTo0CxYsqOjz2Wef5ZBDDsmGG26YBg0aZM8991wuxw4AAMtiiUKpr1p77bVz/vnn56233spNN92UefPm5YADDqjN2qDOFP0jM0nOO++8bLnllmnWrFlat25d7b6q288tt9xSK8cMLLmxY8dmyJAhGTp0aJ555pn07Nkz/fr1y/vvv19t/9tvvz3vvfdexeNf//pX6tevn3333beiT48ePXLppZfmhRdeyKOPPppu3bplxx13zMyZM5MkkydPTnl5ea688sq8+OKLufjiizNy5Mj86le/qtjGwoUL07Rp0xx77LHp27fv8n0RAABgKZWVSqVSbW3s/fffT/v27Wtrc8vFnDlz0qpVq8yePTstW7as63L4Dho7dmwOOuigjBw5Mr17986IESNy66235pVXXqn27/ujjz6qNELhww8/TM+ePXPNNdfkkEMOSZKMGTMm7du3z5prrplPP/00F198cW699dZMmTIl7dq1S5IMHTo0rVu3zttvv51rr702s2bNqrKvsrKyXH/99dlpp50q2lq3bp0mTZrU7osA1Ejv3r2z2Wab5dJLL02SlJeXp0uXLvnlL3+ZU0899VvXHzFiRM4666y89957ad68ebV9Fv136/77789PfvKTavtccMEFueKKK/L6669XWXbIIYdk1qxZ+ctf/lLzAwMAgGVQ0+xlqUdKVee7HkhBTVx00UU5/PDDM3DgwKy//voZOXJkmjVrluuuu67a/qussko6duxY8Rg/fnyaNWtWaeTDgAED0rdv36y55pr5wQ9+kIsuuihz5szJ888/X9Fn2LBhOeGEE7Lhhht+Y32tW7eutD+BFNSNBQsWZOLEiZVGItWrVy99+/bN448/XqNtXHvttdl///0XG0gtWLAgV111VVq1apWePXsudjuzZ8/OKqussmQHAAAAdaxWQyn4b/dd+pG5OIMHD07btm2z+eab57rrrkstDnYElsAHH3yQhQsXpkOHDpXaO3TokOnTp3/r+k899VT+9a9/ZdCgQVWW3XnnnWnRokWaNGmSiy++OOPHj0/btm2r3c6UKVPy+9//PkccccTSHQgAANSRBnVdAHyXfNOPzMmTJ3/r+ot+ZF577bVVlt15553Zf//9M2/evHTq1Okbf2QuzjnnnJPtt98+zZo1y3333Zejjz46n3zySY499tgl2g5Q96699tpsuOGG2Xzzzass22677TJp0qR88MEHufrqq7PffvvlySefrDIi+Z133slOO+2UfffdN4cffnhRpQMAQK0QSkEtqo0fmd/kzDPPrPj3jTfeOHPnzs0FF1wglII60LZt29SvXz8zZsyo1D5jxox07NjxG9edO3dubrnllpxzzjnVLm/evHm6d++e7t27Z4sttsjaa6+da6+9NqeddlpFn3fffTfbbbddttxyy1x11VXLfkAAAFCwJb58b80118yHH35YpX3WrFlZc801a6UoqCu18SPzsMMOq3b5oh+ZW2yxRa699to0aNCg2hFVS6J37955++23M3/+/GXaDrDkGjVqlF69emXChAkVbeXl5ZkwYUL69OnzjeveeuutmT9/fn7+85/XaF/l5eWVPufvvPNOtt122/Tq1SvXX3996tVzNT4AAP99lvhb7BtvvJGFCxdWaZ8/f37eeeedWikK6kpd/shcGpMmTcrKK6+cxo0bL9N2gKUzZMiQXH311bnhhhvy8ssv56ijjsrcuXMzcODAJMlBBx1UaXTTItdee2323HPPtGnTplL73Llz86tf/SpPPPFE3nzzzUycODGHHnpo3nnnnYqbJywKpFZfffX89re/zcyZMzN9+vQq81i99NJLmTRpUj766KPMnj07kyZNyqRJk5bPCwEAAEuhxpfv/fWvf63493vvvTetWrWqeL5w4cJMmDAh3bp1q9XioC4MGTIkBx98cDbddNNsvvnmGTFiRJUfmZ07d87w4cMrrfdNPzLPO++8/PSnP02nTp3ywQcf5LLLLqv0IzNJpk2blo8++ijTpk3LwoULK348du/ePS1atMjf/va3zJgxI1tssUWaNGmS8ePH5/zzz8+JJ564fF8QYLH69++fmTNn5qyzzsr06dOz0UYbZdy4cRXz0k2bNq3KKKZXXnkljz76aO67774q26tfv34mT56cG264IR988EHatGmTzTbbLH//+9/zgx/8IEkyfvz4TJkyJVOmTMlqq61Waf2v3vhgl112yZtvvlnxfOONN67SBwAA6lJZqYbfThd9qS4rK6vyhbZhw4bp1q1bLrzwwuy22261X2UtmjNnTlq1apXZs2enZcuWdV0O31GXXnppLrjggoofmZdcckl69+6dJNl2223TrVu3jBo1qqL/K6+8knXXXTf33Xdfdthhh0rb+uyzzzJgwIA8+eSTlX5knnHGGdlss80q+h1yyCG54YYbqtTy4IMPZtttt824ceNy2mmnZcqUKSmVSunevXuOOuqoHH744S7dAQAA4DujptlLjUOpRdZYY408/fTTS3zXsO8KoRQAAADA8lPT7GWJ7743derUKm2zZs1K69atl3RTAAAAAHxPLfE1P//v//2/jB07tuL5vvvum1VWWSWdO3fOc889V6vFAQAAALBiWuJQauTIkenSpUuSLydbvf/++zNu3LjsvPPOOemkk2q9QAAAAABWPEt8+d706dMrQqk777wz++23X3bcccd069atYiJoAAAAAPgmSzxSauWVV85bb72VJBk3blz69u2b5MtbTC9cuLB2qwMAAABghbTEI6X23nvvDBgwIGuvvXY+/PDD7LzzzkmSZ599Nt27d6/1AgEAAABY8SxxKHXxxRenW7dueeutt/Kb3/wmLVq0SJK89957Ofroo2u9QAAAAABWPGWlUqlU10UUac6cOWnVqlVmz56dli1b1nU5AAAAACuUmmYvSzynVJLceOON2XrrrbPqqqvmzTffTJKMGDEid9xxx9JVCwAAAMD3yhJfvnfFFVfkrLPOyvHHH5/zzjuvYnLz1q1bZ8SIEdljjz1qvUgWb/awYXVdAqxwWg0dWtclLBfOF1D7VtTzBQBAEZZ4pNTvf//7XH311Tn99NNTv379ivZNN900L7zwQq0WBwAAAMCKaYlDqalTp2bjjTeu0t64cePMnTu3VooCAAAAYMW2xKHUGmuskUmTJlVpHzduXNZbb73aqAkAAACAFVyN55Q655xzcuKJJ2bIkCEZPHhwPvvss5RKpTz11FO5+eabM3z48FxzzTXLs1YAAAAAVhA1DqWGDRuWI488MoMGDUrTpk1zxhlnZN68eRkwYEBWXXXV/O53v8v++++/PGsFAAAAYAVR41CqVCpV/PuBBx6YAw88MPPmzcsnn3yS9u3bL5fiAAAAAFgx1TiUSpKysrJKz5s1a5ZmzZrVakEAAAAArPiWKJTq0aNHlWDq6z766KNlKggAAACAFd8ShVLDhg1Lq1atllctAAAAAHxPLFEotf/++5s/CgAAAIBlVq+mHb/tsj0AAAAAqKkah1JfvfseAAAAACyLGl++V15evjzrAAAAAOB7pMYjpQAAAACgtgilAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAAAAACicUAoAAACAwgmlAABgObvsssvSrVu3NGnSJL17985TTz31jf1nzZqVwYMHp1OnTmncuHF69OiRu+++u2L5xx9/nOOPPz5du3ZN06ZNs+WWW+bpp5+utI1SqZSzzjornTp1StOmTdO3b9+89tprlfq8+uqr2WOPPdK2bdu0bNkyW2+9dR588MHaO3BgiTlf8H0ilAIAgOVo7NixGTJkSIYOHZpnnnkmPXv2TL9+/fL+++9X23/BggXZYYcd8sYbb+S2227LK6+8kquvvjqdO3eu6DNo0KCMHz8+N954Y1544YXsuOOO6du3b955552KPr/5zW9yySWXZOTIkXnyySfTvHnz9OvXL5999llFn9122y1ffPFFHnjggUycODE9e/bMbrvtlunTpy+/FwRYLOcLvm/KSqVSqa6LKNKcOXPSqlWrzJ49Oy1btqzrcpbZ7GHD6roEWOG0Gjq0rktYLpwvoPatqOcLalfv3r2z2Wab5dJLL02SlJeXp0uXLvnlL3+ZU089tUr/kSNH5oILLsjkyZPTsGHDKss//fTTrLTSSrnjjjuy6667VrT36tUrO++8c37961+nVCpl1VVXzf/5P/8nJ554YpJk9uzZ6dChQ0aNGpX9998/H3zwQdq1a5dHHnkk22yzTZIvR1S0bNky48ePT9++fZfHywF8A+cLVhQ1zV6MlAIAgOVkwYIFmThxYqUfbPXq1Uvfvn3z+OOPV7vOX//61/Tp0yeDBw9Ohw4dssEGG+T888/PwoULkyRffPFFFi5cmCZNmlRar2nTpnn00UeTJFOnTs306dMr7bdVq1bp3bt3xX7btGmTddZZJ3/4wx8yd+7cfPHFF7nyyivTvn379OrVq1ZfB+DbOV/wfdSgrgsAAIAV1QcffJCFCxemQ4cOldo7dOiQyZMnV7vO66+/ngceeCAHHnhg7r777kyZMiVHH310Pv/88wwdOjQrrbRS+vTpk3PPPTfrrbdeOnTokJtvvjmPP/54unfvniQVl9NUt99Fy8rKynL//fdnzz33zEorrZR69eqlffv2GTduXFZeeeXafimAb+F8wfeRkVIAAPAdUl5envbt2+eqq65Kr1690r9//5x++ukZOXJkRZ8bb7wxpVIpnTt3TuPGjXPJJZfkgAMOSL16Nf96XyqVMnjw4LRv3z5///vf89RTT2XPPffM7rvvnvfee295HBpQy5wv+G/3nQilluTuAttuu23KysqqPL56fSwAAHwXtG3bNvXr18+MGTMqtc+YMSMdO3asdp1OnTqlR48eqV+/fkXbeuutl+nTp2fBggVJkrXWWisPP/xwPvnkk7z11lt56qmn8vnnn2fNNddMkoptf9N+H3jggdx555255ZZbstVWW2WTTTbJ5ZdfnqZNm+aGG26onRcAqDHnC76P6jyUWtK7C9x+++157733Kh7/+te/Ur9+/ey7774FVw4AAN+sUaNG6dWrVyZMmFDRVl5engkTJqRPnz7VrrPVVltlypQpKS8vr2h79dVX06lTpzRq1KhS3+bNm6dTp075z3/+k3vvvTd77LFHkmSNNdZIx44dK+13zpw5efLJJyv2O2/evCSpMlqiXr16lfYNFMP5gu+jOg+lLrroohx++OEZOHBg1l9//YwcOTLNmjXLddddV23/VVZZJR07dqx4jB8/Ps2aNRNKAQDwnTRkyJBcffXVueGGG/Lyyy/nqKOOyty5czNw4MAkyUEHHZTTTjutov9RRx2Vjz76KMcdd1xeffXV3HXXXTn//PMzePDgij733ntvxo0bl6lTp2b8+PHZbrvtsu6661Zss6ysLMcff3x+/etf569//WteeOGFHHTQQVl11VWz5557Jkn69OmTlVdeOQcffHCee+65vPrqqznppJMydepUVyFAHXG+4PumTic6X3R3ga9+qL7t7gJfd+2112b//fdP8+bNl1eZAACw1Pr375+ZM2fmrLPOyvTp07PRRhtl3LhxFZMKT5s2rdLogy5duuTee+/NCSeckB/+8Ifp3LlzjjvuuJxyyikVfWbPnp3TTjstb7/9dlZZZZXss88+Oe+88yrdEv7kk0/O3Llz84tf/CKzZs3K1ltvnXHjxlXchatt27YZN25cTj/99Gy//fb5/PPP84Mf/CB33HFHevbsWdCrA3yV8wXfN2WlUqlUVzt/991307lz5zz22GOVhiOefPLJefjhh/Pkk09+4/pPPfVUevfunSeffDKbb755tX3mz5+f+fPnVzyfM2dOunTpktmzZ6dly5a1cyB1aPawYXVdAqxwWg0dWtclLBfOF1D7VtTzBQDAspgzZ05atWr1rdlLnV++tyyuvfbabLjhhosNpJJk+PDhadWqVcWjS5cuBVYIAAAAQHXqNJRamrsLLDJ37tzccsstOeyww76x32mnnZbZs2dXPN56661lrhsAAACAZVOnodTS3F1gkVtvvTXz58/Pz3/+82/s17hx47Rs2bLSAwAAAIC6VacTnSdf3l3g4IMPzqabbprNN988I0aMqHJ3gc6dO2f48OGV1rv22muz5557pk2bNnVRNgAAAADLoM5DqSW9u0CSvPLKK3n00Udz33331UXJAAAAACyjOg+lkuSYY47JMcccU+2yhx56qErbOuuskzq8aSAAAAAAy+i/+u57AAAAAPx3EkoBAAAAUDihFAAAAACF+07MKQUAwHfD7GHD6roEWCG1Gjq0rkuodc4XUPtWxHPFNzFSCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKJxQCgAAAIDCCaUAAAAAKFydh1KXXXZZunXrliZNmqR379556qmnvrH/rFmzMnjw4HTq1CmNGzdOjx49cvfddxdULQAAAAC1oUFd7nzs2LEZMmRIRo4cmd69e2fEiBHp169fXnnllbRv375K/wULFmSHHXZI+/btc9ttt6Vz5855880307p16+KLBwAAAGCp1WkoddFFF+Xwww/PwIEDkyQjR47MXXfdleuuuy6nnnpqlf7XXXddPvroozz22GNp2LBhkqRbt25FlgwAAABALaizy/cWLFiQiRMnpm/fvv9bTL166du3bx5//PFq1/nrX/+aPn36ZPDgwenQoUM22GCDnH/++Vm4cGFRZQMAAABQC+pspNQHH3yQhQsXpkOHDpXaO3TokMmTJ1e7zuuvv54HHnggBx54YO6+++5MmTIlRx99dD7//PMMHTq02nXmz5+f+fPnVzyfM2dO7R0EAAAAAEulzic6XxLl5eVp3759rrrqqvTq1Sv9+/fP6aefnpEjRy52neHDh6dVq1YVjy5duhRYMQAAAADVqbNQqm3btqlfv35mzJhRqX3GjBnp2LFjtet06tQpPXr0SP369Sva1ltvvUyfPj0LFiyodp3TTjsts2fPrni89dZbtXcQAAAAACyVOgulGjVqlF69emXChAkVbeXl5ZkwYUL69OlT7TpbbbVVpkyZkvLy8oq2V199NZ06dUqjRo2qXadx48Zp2bJlpQcAAAAAdatOL98bMmRIrr766txwww15+eWXc9RRR2Xu3LkVd+M76KCDctppp1X0P+qoo/LRRx/luOOOy6uvvpq77ror559/fgYPHlxXhwAAAADAUqizic6TpH///pk5c2bOOuusTJ8+PRtttFHGjRtXMfn5tGnTUq/e/+ZmXbp0yb333psTTjghP/zhD9O5c+ccd9xxOeWUU+rqEAAAAABYCnUaSiXJMccck2OOOabaZQ899FCVtj59+uSJJ55YzlUBAAAAsDz9V919DwAAAIAVg1AKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMIJpQAAAAAonFAKAAAAgMJ9J0Kpyy67LN26dUuTJk3Su3fvPPXUU4vtO2rUqJSVlVV6NGnSpMBqAQAAAFhWdR5KjR07NkOGDMnQoUPzzDPPpGfPnunXr1/ef//9xa7TsmXLvPfeexWPN998s8CKAQAAAFhWdR5KXXTRRTn88MMzcODArL/++hk5cmSaNWuW6667brHrlJWVpWPHjhWPDh06FFgxAAAAAMuqTkOpBQsWZOLEienbt29FW7169dK3b988/vjji13vk08+SdeuXdOlS5fsscceefHFF4soFwAAAIBa0qAud/7BBx9k4cKFVUY6dejQIZMnT652nXXWWSfXXXddfvjDH2b27Nn57W9/my233DIvvvhiVltttSr958+fn/nz51c8nz17dpJkzpw5tXgkdWfOZ5/VdQmwwilbQc4PX+d8AbVvRTxfOFfA8uF8AdTEinKuWJS5lEqlb+xXVvq2HsvRu+++m86dO+exxx5Lnz59KtpPPvnkPPzww3nyySe/dRuff/551ltvvRxwwAE599xzqyw/++yzM2zYsFqtGwAAAIBv9tZbb1U7gGiROh0p1bZt29SvXz8zZsyo1D5jxox07NixRtto2LBhNt5440yZMqXa5aeddlqGDBlS8by8vDwfffRR2rRpk7KysqUvHpbAnDlz0qVLl7z11ltp2bJlXZcDfIc5XwA14VwB1JTzBXWhVCrl448/zqqrrvqN/eo0lGrUqFF69eqVCRMmZM8990zyZWg0YcKEHHPMMTXaxsKFC/PCCy9kl112qXZ548aN07hx40ptrVu3XpayYam1bNnSfwiAGnG+AGrCuQKoKecLitaqVatv7VOnoVSSDBkyJAcffHA23XTTbL755hkxYkTmzp2bgQMHJkkOOuigdO7cOcOHD0+SnHPOOdliiy3SvXv3zJo1KxdccEHefPPNDBo0qC4PAwAAAIAlUOehVP/+/TNz5sycddZZmT59ejbaaKOMGzeuYvLzadOmpV69/71J4H/+858cfvjhmT59elZeeeX06tUrjz32WNZff/26OgQAAAAAllCdTnQO3xfz58/P8OHDc9ppp1W5nBTgq5wvgJpwrgBqyvmC7zKhFAAAAACFq/ftXQAAAACgdgmlAAAAACicUAoAAAC+Z7p165YRI0ZUPC8rK8tf/vKXOquH7yehFN87hxxySMrKylJWVpaGDRumQ4cO2WGHHXLdddelvLy8ot/XT9LdunVLWVlZnnjiiUrbO/7447PtttvWyj6r22+SPPvss9l3333ToUOHNGnSJGuvvXYOP/zwvPrqq0mSN954o2L7X398vV6genV9bmjUqFG6d++ec845J1988UWS5KGHHqr0eW7Xrl122WWXvPDCC0t0bNtuu22OP/74apdVd85JkrPPPjsbbbTREu0H+NKS/He/CNV9P9h6662rLP/6eWz+/Plp06ZNysrK8tBDDxVcNazYvnqeKCsrS5s2bbLTTjvl+eefr7Oa3nvvvey88851tn++n4RSfC/ttNNOee+99/LGG2/knnvuyXbbbZfjjjsuu+22W8WPweo0adIkp5xySqH7vPPOO7PFFltk/vz5GT16dF5++eXcdNNNadWqVc4888xKfe+///689957lR69evVaqnrh+6guzw2vvfZa/s//+T85++yzc8EFF1Tq88orr+S9997Lvffem/nz52fXXXfNggULlmp/QDGW9nyyvFx//fWVvh/89a9/rbS8S5cuuf766yu1/fnPf06LFi2KLBO+VxadJ957771MmDAhDRo0yG677VZn9XTs2NHd+SicUIrvpcaNG6djx47p3LlzNtlkk/zqV7/KHXfckXvuuSejRo1a7Hq/+MUv8sQTT+Tuu+8uZJ/z5s3LwIEDs8suu+Svf/1r+vbtmzXWWCO9e/fOb3/721x55ZWV+rdp0yYdO3as9GjYsOES1wrfV3V5bujatWuOOuqo9O3bt8qPxfbt26djx47ZZJNNcvzxx+ett97K5MmTK5Y/+uij2WabbdK0adN06dIlxx57bObOnbvEtQC1pybnk1mzZmXQoEFp165dWrZsme233z7PPfdcpe3ccccd2WSTTdKkSZOsueaaGTZsWKVQq6ysLFdccUV23nnnNG3aNGuuuWZuu+22KvW0bt260veDVVZZpdLygw8+OLfccks+/fTTirbrrrsuBx98cC2+KsBXLTpPdOzYMRtttFFOPfXUvPXWW5k5c2aS5JRTTkmPHj3SrFmzrLnmmjnzzDPz+eefV6z/3HPPZbvttstKK62Uli1bplevXvnnP/9ZsXxJvx989fK9RVdi3H777dluu+3SrFmz9OzZM48//nildXwHYVkJpeD/t/3226dnz565/fbbF9tnjTXWyJFHHpnTTjutVobff9s+77333nzwwQc5+eSTq13eunXrZa4B+GZFnxuaNm262FFQs2fPzi233JIkadSoUZLk3//+d3baaafss88+ef755zN27Ng8+uijOeaYY5apDqD2ff18su++++b999/PPffck4kTJ2aTTTbJT37yk3z00UdJkr///e856KCDctxxx+Wll17KlVdemVGjRuW8886rtN0zzzwz++yzT5577rkceOCB2X///fPyyy8vUW29evVKt27d8qc//SlJMm3atDzyyCP5n//5n1o4cuDbfPLJJ7npppvSvXv3tGnTJkmy0korZdSoUXnppZfyu9/9LldffXUuvvjiinUOPPDArLbaann66aczceLEnHrqqRX/Q7q2vh+cfvrpOfHEEzNp0qT06NEjBxxwQEUw7jsItUEoBV+x7rrr5o033vjGPmeccUamTp2a0aNHL/d9vvbaaxV9amLLLbdMixYtKj2AZVfEuaFUKuX+++/Pvffem+23377SstVWWy0tWrRI69atM2bMmPz0pz+tOC8MHz48Bx54YI4//visvfba2XLLLXPJJZfkD3/4Qz777LOlqgVYfhadTx599NE89dRTufXWW7Pppptm7bXXzm9/+9u0bt26YqTTsGHDcuqpp+bggw/OmmuumR122CHnnntulZHS++67bwYNGpQePXrk3HPPzaabbprf//73lfoccMABlb4fVDeZ8aGHHprrrrsuSTJq1Kjssssuadeu3fJ5IYDceeedFZ/JlVZaKX/9618zduzY1Kv35c/0M844I1tuuWW6deuW3XffPSeeeGL++Mc/Vqw/bdq09O3bN+uuu27WXnvt7LvvvunZs2eS2vt+cOKJJ2bXXXdNjx49MmzYsLz55puZMmVKre6D7zehFHxFqVRKWVnZN/Zp165dTjzxxJx11llVRjP8/e9/r/SFryY/Tr9pn6VSqebFJxk7dmwmTZpU6QEsu+V5blj0hbRJkybZeeed079//5x99tlV1p84cWJGjRqVHj16ZOTIkRXLnnvuuYwaNarS9vv165fy8vJMnTp12Q8eqFWLzifPPfdcPvnkk7Rp06bS53fq1Kn597//neTLz/c555xTafnhhx+e9957L/PmzavYZp8+fSrto0+fPlVGSl188cWVvh/ssMMOVWr7+c9/nscffzyvv/56Ro0alUMPPXQ5vALAItttt13FZ/Kpp55Kv379svPOO+fNN99M8uV3+6222iodO3ZMixYtcsYZZ2TatGkV6w8ZMiSDBg1K375983//7/+tOHcktff94Ic//GHFv3fq1ClJ8v7779fqPvh+a1DXBcB3ycsvv5w11ljjW/sNGTIkl19+eS6//PJK7ZtuummlIKhDhw7LtM8ePXokSSZPnlzlC2d1unTpku7du39rP2DJLM9zw3bbbZcrrrgijRo1yqqrrpoGDar+p3mNNdZI69ats8466+T9999P//7988gjjyT5crj/EUcckWOPPbbKequvvvq31tyyZcvMnj27SvusWbPSqlWrb10fWDKLzieffPJJOnXqVO1d7RZdnv/JJ59k2LBh2Xvvvav0adKkyRLtt2PHjt/6HaFNmzbZbbfdcthhh+Wzzz7LzjvvnI8//niJ9gPUXPPmzSt9Lq+55pq0atUqV199dXbdddcceOCBGTZsWPr165dWrVrllltuyYUXXljR/+yzz86AAQNy11135Z577snQoUNzyy23ZK+99lrm7weLfHV+2kX/g27RVAW1tQ++34RS8P974IEH8sILL+SEE0741r4tWrTImWeembPPPjs//elPK9qbNm26RKHQt+1zxx13TNu2bfOb3/wmf/7zn6ssnzVrlnmlYDlb3ueGr38h/TaDBw/O8OHD8+c//zl77bVXNtlkk7z00ktLHUivs846mThxYpX2Z555Juuss85SbROo3lfPJ6uttlqmT5+eBg0apFu3btX232STTfLKK6986+f7iSeeyEEHHVTp+cYbb7xUNR566KHZZZddcsopp6R+/fpLtQ1g6ZSVlaVevXr59NNP89hjj6Vr1645/fTTK5YvGkH1VT169EiPHj1ywgkn5IADDsj1119fK98PaqKIfbDiE0rxvTR//vxMnz49CxcuzIwZMzJu3LgMHz48u+22W6Uvdd/kF7/4RS6++OKMGTMmvXv3Xi77bN68ea655prsu++++elPf5pjjz023bt3zwcffJA//vGPmTZtWsWkx0ny4YcfZvr06ZW20bp16yX+v6nwfVUX54Yl1axZsxx++OEZOnRo9txzz5xyyinZYostcswxx2TQoEFp3rx5XnrppYwfPz6XXnppxXozZ86scklvp06dcsIJJ2SbbbbJeeedl7333jsLFy7MzTffnMcff7zKiC+g5r7tfFKvXr306dMne+65Z37zm9+kR48eeffdd3PXXXdlr732yqabbpqzzjoru+22W1ZfffX87Gc/S7169fLcc8/lX//6V379619X7GvRvFRbb711Ro8enaeeeirXXnvtUtW90047ZebMmWnZsmVtvRTAYiw6TyTJf/7zn1x66aX55JNPsvvuu2fOnDkV3/U322yz3HXXXZX+J/Wnn36ak046KT/72c+yxhpr5O23387TTz+dffbZJ0lq/P1gWRSxD1Z8Qim+l8aNG5dOnTqlQYMGWXnlldOzZ89ccsklOfjggysmFvw2DRs2zLnnnpsBAwYs133uscceeeyxxzJ8+PAMGDAgc+bMSZcuXbL99ttX+kKaJH379q2y/s0335z999+/RjXC911dnBuWxjHHHJOLLroot956a/bbb788/PDDOf3007PNNtukVCplrbXWSv/+/SutM2bMmIwZM6ZS27nnnpszzjgj99xzT84555xceOGFqVevXjbccMNMmDAhG2ywwXI7BljR1eR8cvfdd+f000/PwIEDM3PmzHTs2DE/+tGPKi7x7devX+68886cc845+X//7/+lYcOGWXfddTNo0KBK+xo2bFhuueWWHH300enUqVNuvvnmrL/++ktVd1lZWdq2bbtsBw/UyKLzRPLlnfbWXXfd3Hrrrdl2222TJCeccEKOOeaYzJ8/P7vuumvFaOwkqV+/fj788MMcdNBBmTFjRtq2bZu99947w4YNS/LlXFA1+X6wLIrYByu+stKSzqQMAAB8J5SVleXPf/5z9txzz7ouBQCWmLvvAQAAAFA4oRQAAAAAhTOnFAAA/JcyEwcA/82MlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAAAAAAonlAIAAACgcEIpAID/Qg899FDKysoya9asGq/TrVu3jBgxYrnVBACwJIRSAADLwSGHHJKysrIceeSRVZYNHjw4ZWVlOeSQQ4ovDADgO0IoBQCwnHTp0iW33HJLPv3004q2zz77LGPGjMnqq69eh5UBANQ9oRQAwHKyySabpEuXLrn99tsr2m6//fasvvrq2XjjjSva5s+fn2OPPTbt27dPkyZNsvXWW+fpp5+utK277747PXr0SNOmTbPddtvljTfeqLK/Rx99NNtss02aNm2aLl265Nhjj83cuXOX2/EBACwLoRQAwHJ06KGH5vrrr694ft1112XgwIGV+px88sn505/+lBtuuCHPPPNMunfvnn79+uWjjz5Kkrz11lvZe++9s/vuu2fSpEkZNGhQTj311Erb+Pe//52ddtop++yzT55//vmMHTs2jz76aI455pjlf5AAAEtBKAUAsBz9/Oc/z6OPPpo333wzb775Zv7xj3/k5z//ecXyuXPn5oorrsgFF1yQnXfeOeuvv36uvvrqNG3aNNdee22S5Iorrshaa62VCy+8MOuss04OPPDAKvNRDR8+PAceeGCOP/74rL322tlyyy1zySWX5A9/+EM+++yzIg8ZAKBGGtR1AQAAK7J27dpl1113zahRo1IqlbLrrrumbdu2Fcv//e9/5/PPP89WW21V0dawYcNsvvnmefnll5MkL7/8cnr37l1pu3369Kn0/Lnnnsvzzz+f0aNHV7SVSqWUl5dn6tSpWW+99ZbH4QEALDWhFADAcnbooYdWXEZ32WWXLZd9fPLJJzniiCNy7LHHVllmUnUA4LtIKAUAsJzttNNOWbBgQcrKytKvX79Ky9Zaa600atQo//jHP9K1a9ckyeeff56nn346xx9/fJJkvfXWy1//+tdK6z3xxBOVnm+yySZ56aWX0r179+V3IAAAtcicUgAAy1n9+vXz8ssv56WXXkr9+vUrLWvevHmOOuqonHTSSRk3blxeeumlHH744Zk3b14OO+ywJMmRRx6Z1157LSeddFJeeeWVjBkzJqNGjaq0nVNOOSWPPfZYjjnmmEyaNCmvvfZa7rjjDhOdAwDfWUIpAIACtGzZMi1btqx22f/9v/83++yzT/7nf/4nm2yySaZMmZJ77703K6+8cpIvL7/705/+lL/85S/p2bNnRo4cmfPPP7/SNn74wx/m4YcfzquvvpptttkmG2+8cc4666ysuuqqy/3YAACWRlmpVCrVdREAAAAAfL8YKQUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABROKAUAAABA4YRSAAAAABTu/wO8vquvd73mJQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING COMPLETED FOR ALL OPTIMIZED MODELS!\n",
            "============================================================\n",
            "\n",
            "The hyperparameter tuning and optimized training process has been completed.\n",
            "All models have been trained with their best parameters from hyperparameter tuning.\n",
            "The results show both validation and test performance metrics.\n",
            "The best model based on test AUC is: DIN-PReLU\n",
            "The best model based on test LogLoss is: DIN-PReLU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 8: MODEL EVALUATION & TESTING (SIMPLIFIED METRICS)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CELL 8: MODEL EVALUATION & TESTING (SIMPLIFIED METRICS)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Add required sklearn imports\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "def comprehensive_model_evaluation():\n",
        "    \"\"\"Comprehensive evaluation of all trained models focusing on AUC, Log Loss, and AUC-based RelaImpr\"\"\"\n",
        "\n",
        "    # Current timestamp and user information\n",
        "    current_timestamp = \"-\"\n",
        "    current_user = \"Muhammad Sultan Nurrochman\"\n",
        "\n",
        "    print(\"ðŸ“Š Starting simplified model evaluation...\")\n",
        "\n",
        "    # Collect all trained models\n",
        "    trained_models = {}\n",
        "\n",
        "    # Check DIN-DICE\n",
        "    if 'din_dice_model' in globals() and 'din_dice_results' in globals():\n",
        "        trained_models['DIN-DICE (Optimized)'] = {\n",
        "            'model': din_dice_model,\n",
        "            'results': din_dice_results,\n",
        "            'data_format': 'sequences'\n",
        "        }\n",
        "        print(\"DIN-DICE model found\")\n",
        "\n",
        "    # Check DIN-PReLU\n",
        "    if 'din_prelu_model' in globals() and 'din_prelu_results' in globals():\n",
        "        trained_models['DIN-PReLU (Optimized)'] = {\n",
        "            'model': din_prelu_model,\n",
        "            'results': din_prelu_results,\n",
        "            'data_format': 'sequences'\n",
        "        }\n",
        "        print(\"DIN-PReLU model found\")\n",
        "\n",
        "    # Check DeepFM\n",
        "    if 'deepfm_model' in globals() and 'deepfm_results' in globals():\n",
        "        trained_models['DeepFM'] = {\n",
        "            'model': deepfm_model,\n",
        "            'results': deepfm_results,\n",
        "            'data_format': 'simple'\n",
        "        }\n",
        "        print(\"DeepFM model found\")\n",
        "\n",
        "    # Check Baseline\n",
        "    if 'baseline_model' in globals() and 'baseline_results' in globals():\n",
        "        trained_models['Baseline'] = {\n",
        "            'model': baseline_model,\n",
        "            'results': baseline_results,\n",
        "            'data_format': 'simple'\n",
        "        }\n",
        "        print(\"Baseline model found\")\n",
        "\n",
        "    if not trained_models:\n",
        "        print(\"âŒ No trained models found! Please run training cells first.\")\n",
        "        return {'success': False, 'error': 'No trained models available'}\n",
        "\n",
        "    print(f\"Found {len(trained_models)} trained models: {list(trained_models.keys())}\")\n",
        "\n",
        "    # Prepare test data\n",
        "    test_data = model_data['splits']['test']\n",
        "\n",
        "    # Test data for sequence models (DIN variants)\n",
        "    test_data_sequences = {\n",
        "        'user_id': test_data['user_ids'],\n",
        "        'item_id': test_data['item_ids'],\n",
        "        'sequence': test_data['sequences'],\n",
        "        'seq_length': test_data['seq_lengths'],\n",
        "        'dense_features': test_data['dense_features']\n",
        "    }\n",
        "\n",
        "    # Test data for simple models (DeepFM, Baseline)\n",
        "    test_data_simple = {\n",
        "        'user_id': test_data['user_ids'],\n",
        "        'item_id': test_data['item_ids'],\n",
        "        'dense_features': test_data['dense_features']\n",
        "    }\n",
        "\n",
        "    test_labels = test_data['labels'].flatten()\n",
        "\n",
        "    print(f\"Test dataset info:\")\n",
        "    print(f\"    Test samples: {len(test_labels):,}\")\n",
        "    print(f\"    Test CTR: {test_labels.mean():.4f}\")\n",
        "    print(f\"    Positive samples: {test_labels.sum():,}\")\n",
        "    print(f\"    Negative samples: {len(test_labels) - test_labels.sum():,}\")\n",
        "\n",
        "    # Evaluation results storage\n",
        "    evaluation_results = {}\n",
        "\n",
        "    print(f\"\\nðŸ” Starting model evaluations...\")\n",
        "\n",
        "    # Evaluate each model\n",
        "    for model_name, model_info in trained_models.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ðŸ” Evaluating {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        model = model_info['model']\n",
        "        data_format = model_info['data_format']\n",
        "\n",
        "        try:\n",
        "            # Select appropriate test data format\n",
        "            if data_format == 'sequences':\n",
        "                test_x = test_data_sequences\n",
        "            else:\n",
        "                test_x = test_data_simple\n",
        "\n",
        "            print(f\"Model info:\")\n",
        "            print(f\"    Parameters: {model.count_params():,}\")\n",
        "            print(f\"    Data format: {data_format}\")\n",
        "\n",
        "            # Make predictions\n",
        "            print(f\"Making predictions...\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            predictions = model.predict(test_x, batch_size=512, verbose=0)\n",
        "            predictions = predictions.flatten()\n",
        "\n",
        "            prediction_time = time.time() - start_time\n",
        "\n",
        "            # Calculate key metrics\n",
        "            print(f\"Calculating key metrics: AUC and Log Loss...\")\n",
        "\n",
        "            # AUC\n",
        "            auc_score = tf.keras.metrics.AUC()\n",
        "            auc_score.update_state(test_labels, predictions)\n",
        "            auc = auc_score.result().numpy()\n",
        "\n",
        "            # ROC AUC (using sklearn for validation)\n",
        "            roc_auc = roc_auc_score(test_labels, predictions)\n",
        "\n",
        "            # Log Loss\n",
        "            log_loss_val = tf.keras.losses.BinaryCrossentropy()(test_labels, predictions).numpy()\n",
        "\n",
        "            # Store results\n",
        "            evaluation_results[model_name] = {\n",
        "                'auc': auc,\n",
        "                'roc_auc': roc_auc,\n",
        "                'log_loss': log_loss_val,\n",
        "                'prediction_time': prediction_time,\n",
        "                'model_params': model.count_params(),\n",
        "                'validation_auc': model_info['results']['best_val_auc'],\n",
        "                'training_time': model_info['results']['training_time'],\n",
        "                'success': True\n",
        "            }\n",
        "\n",
        "            # Print results\n",
        "            print(f\"{model_name} Evaluation Results:\")\n",
        "            print(f\"    AUC: {auc:.4f}\")\n",
        "            print(f\"    ROC AUC (sklearn): {roc_auc:.4f}\")\n",
        "            print(f\"    Log Loss: {log_loss_val:.4f}\")\n",
        "            print(f\"    Prediction Time: {prediction_time:.2f}s\")\n",
        "            print(f\"    Model Parameters: {model.count_params():,}\")\n",
        "            print(f\"    Validation AUC: {model_info['results']['best_val_auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error evaluating {model_name}: {e}\")\n",
        "            evaluation_results[model_name] = {'success': False, 'error': str(e)}\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Calculate the relative improvement over baseline based on AUC\n",
        "    if 'Baseline' in evaluation_results and evaluation_results['Baseline'].get('success'):\n",
        "        baseline_auc = evaluation_results['Baseline']['auc']\n",
        "\n",
        "        for model_name, results in evaluation_results.items():\n",
        "            if results.get('success'):\n",
        "                # Calculate RelaImpr as AUC improvement over baseline\n",
        "                if model_name != 'Baseline':\n",
        "                    model_auc = results['auc']\n",
        "                    # RelaImpr as percentage improvement over baseline AUC\n",
        "                    auc_relaimpr = ((model_auc / baseline_auc) - 1) * 100 if baseline_auc > 0 else 0\n",
        "                else:\n",
        "                    # Baseline has 0% improvement over itself\n",
        "                    auc_relaimpr = 0.0\n",
        "\n",
        "                evaluation_results[model_name]['relaimpr'] = auc_relaimpr\n",
        "\n",
        "    # Create results directory\n",
        "    os.makedirs('evaluation_results', exist_ok=True)\n",
        "\n",
        "    # Prepare data for CSV export\n",
        "    results_for_csv = []\n",
        "\n",
        "    # Create comprehensive comparison\n",
        "    print(f\"\\nSIMPLIFIED MODEL COMPARISON (Sorted by RelaImpr)\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Filter successful evaluations\n",
        "    successful_results = {k: v for k, v in evaluation_results.items() if v.get('success')}\n",
        "\n",
        "    if not successful_results:\n",
        "        print(\"âŒ No successful evaluations found!\")\n",
        "        return {'success': False, 'error': 'No successful evaluations'}\n",
        "\n",
        "    # MAIN COMPARISON TABLE WITH CORE METRICS - Diurutkan berdasarkan RelaImpr terendah\n",
        "    print(f\"{'Model':<20} {'AUC':<10} {'RelaImpr':<10} {'Log Loss':<10} {'Params':<12}\")\n",
        "    print(f\"{'-'*20} {'-'*10} {'-'*10} {'-'*10} {'-'*12}\")\n",
        "\n",
        "    # Sorting model names by RelaImpr (ascending - lowest first)\n",
        "    sorted_models = sorted(successful_results.keys(),\n",
        "                        key=lambda x: successful_results[x].get('relaimpr', 0.0))\n",
        "\n",
        "    for model_name in sorted_models:\n",
        "        results = successful_results[model_name]\n",
        "        # Add to CSV data\n",
        "        results_for_csv.append({\n",
        "            'model_name': model_name,\n",
        "            'auc': results['auc'],\n",
        "            'relaimpr': results.get('relaimpr', 0.0),\n",
        "            'log_loss': results['log_loss'],\n",
        "            'validation_auc': results['validation_auc'],\n",
        "            'prediction_time': results['prediction_time'],\n",
        "            'training_time': results['training_time'],\n",
        "            'parameters': results['model_params']\n",
        "        })\n",
        "\n",
        "        # Print table row with key metrics\n",
        "        print(f\"{model_name:<20} {results['auc']:<10.4f} {results.get('relaimpr', 0.0):<10.2f} \"\n",
        "            f\"{results['log_loss']:<10.4f} {results['model_params']:<12,}\")\n",
        "\n",
        "    # Find best model by different criteria\n",
        "    best_auc_model = max(successful_results.keys(), key=lambda x: successful_results[x]['auc'])\n",
        "    best_relaimpr_model = max(successful_results.keys(), key=lambda x: successful_results[x].get('relaimpr', 0.0))\n",
        "    best_logloss_model = min(successful_results.keys(), key=lambda x: successful_results[x]['log_loss'])\n",
        "\n",
        "    best_results = successful_results[best_auc_model]\n",
        "\n",
        "    print(f\"\\nBEST MODELS BY CRITERIA:\")\n",
        "    print(f\"    Best AUC: {best_auc_model} ({successful_results[best_auc_model]['auc']:.4f})\")\n",
        "    print(f\"    Best RelaImpr: {best_relaimpr_model} ({successful_results[best_relaimpr_model].get('relaimpr', 0.0):.2f}%)\")\n",
        "    print(f\"    Best Log Loss: {best_logloss_model} ({successful_results[best_logloss_model]['log_loss']:.4f})\")\n",
        "\n",
        "    # EXPORT RESULTS TO CSV\n",
        "    results_df = pd.DataFrame(results_for_csv)\n",
        "    csv_timestamp = current_timestamp.replace(' ', '_').replace(':', '-')\n",
        "    csv_path = f'evaluation_results/model_evaluation_simplified_{csv_timestamp}.csv'\n",
        "    results_df.to_csv(csv_path, index=False)\n",
        "    print(f\"\\nEvaluation results exported to CSV: {csv_path}\")\n",
        "\n",
        "    # PLOTS - using same model order as the table (sorted by RelaImpr)\n",
        "    models = sorted_models  # Using the same sorted order as the table\n",
        "\n",
        "    # 1. AUC Comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    test_aucs = [successful_results[m]['auc'] for m in models]\n",
        "    bars = plt.bar(models, test_aucs, color='skyblue', alpha=0.8)\n",
        "    plt.title('Test AUC Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('AUC Score')\n",
        "    plt.ylim(0, 1)\n",
        "    for bar, auc in zip(bars, test_aucs):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{auc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/auc_comparison.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 2. RelaImpr Comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    relaimpr_scores = [successful_results[m].get('relaimpr', 0.0) for m in models]\n",
        "    bars = plt.bar(models, relaimpr_scores, color='lightcoral', alpha=0.8)\n",
        "    plt.title('AUC-Based RelaImpr Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Relative Improvement (%)')\n",
        "    for bar, relaimpr in zip(bars, relaimpr_scores):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                f'{relaimpr:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/relaimpr_comparison.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 3. Log Loss Comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    log_losses = [successful_results[m]['log_loss'] for m in models]\n",
        "    bars = plt.bar(models, log_losses, color='lightgreen', alpha=0.8)\n",
        "    plt.title('Log Loss Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Log Loss')\n",
        "    for bar, loss in zip(bars, log_losses):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{loss:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/logloss_comparison.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Final summary section\n",
        "    print(f\"\\nEVALUATION SUMMARY:\")\n",
        "    print(f\"    Models evaluated: {len(successful_results)}\")\n",
        "    print(f\"    Best overall model: {best_auc_model}\")\n",
        "    print(f\"    Best test AUC: {best_results['auc']:.4f}\")\n",
        "    print(f\"    Best RelaImpr: {successful_results[best_relaimpr_model].get('relaimpr', 0.0):.1f}%\")\n",
        "    print(f\"    CSV Export: Results saved to {csv_path}\")\n",
        "    print(f\"    Plots: Saved to evaluation_results/ directory\")\n",
        "\n",
        "    if 'Baseline' in successful_results:\n",
        "        baseline_auc = successful_results['Baseline']['auc']\n",
        "        improvement = best_results['auc'] - baseline_auc\n",
        "        print(f\"    ðŸ“ˆ AUC improvement over baseline: {improvement:.4f} points ({improvement/baseline_auc*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nðŸŽ‰ EVALUATION COMPLETED SUCCESSFULLY!\")\n",
        "    print(f\"ðŸ“… Evaluation completed on: {current_timestamp}\")\n",
        "    print(f\"ðŸ‘¤ Evaluated by: {current_user}\")\n",
        "\n",
        "    return {\n",
        "        'success': True,\n",
        "        'evaluation_results': evaluation_results,\n",
        "        'best_model': best_auc_model,\n",
        "        'best_results': best_results,\n",
        "        'best_relaimpr_model': best_relaimpr_model,\n",
        "        'best_logloss_model': best_logloss_model,\n",
        "        'models_evaluated': len(successful_results),\n",
        "        'timestamp': current_timestamp,\n",
        "        'evaluator': current_user,\n",
        "        'csv_path': csv_path\n",
        "    }\n",
        "\n",
        "# Execute comprehensive evaluation\n",
        "print(f\"Starting model evaluation with simplified metrics (AUC, Log Loss, RelaImpr)...\")\n",
        "try:\n",
        "    final_evaluation = comprehensive_model_evaluation()\n",
        "\n",
        "    if final_evaluation['success']:\n",
        "        print(f\"\\nEVALUATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"{final_evaluation['models_evaluated']} models evaluated with core metrics\")\n",
        "        print(f\"Best performing model: {final_evaluation['best_model']}\")\n",
        "        print(f\"Best test AUC: {final_evaluation['best_results']['auc']:.4f}\")\n",
        "        print(f\"Best RelaImpr model: {final_evaluation['best_relaimpr_model']}\")\n",
        "        print(f\"Results exported to: {final_evaluation['csv_path']}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"âŒ Evaluation failed: {final_evaluation.get('error', 'Unknown error')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Evaluation error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "FuoNnVeoufUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83a42e3-01c0-4547-db22-c730cb93885d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CELL 8: MODEL EVALUATION & TESTING (SIMPLIFIED METRICS)\n",
            "============================================================\n",
            "Starting model evaluation with simplified metrics (AUC, Log Loss, RelaImpr)...\n",
            "ðŸ“Š Starting simplified model evaluation...\n",
            "DIN-DICE model found\n",
            "DIN-PReLU model found\n",
            "DeepFM model found\n",
            "Baseline model found\n",
            "Found 4 trained models: ['DIN-DICE (Optimized)', 'DIN-PReLU (Optimized)', 'DeepFM', 'Baseline']\n",
            "Test dataset info:\n",
            "    Test samples: 2,655,797\n",
            "    Test CTR: 0.0516\n",
            "    Positive samples: 136,973.0\n",
            "    Negative samples: 2,518,824.0\n",
            "\n",
            "ðŸ” Starting model evaluations...\n",
            "\n",
            "============================================================\n",
            "ðŸ” Evaluating DIN-DICE (Optimized)\n",
            "============================================================\n",
            "Model info:\n",
            "    Parameters: 63,660,002\n",
            "    Data format: sequences\n",
            "Making predictions...\n",
            "Calculating key metrics: AUC and Log Loss...\n",
            "DIN-DICE (Optimized) Evaluation Results:\n",
            "    AUC: 0.7315\n",
            "    ROC AUC (sklearn): 0.7321\n",
            "    Log Loss: 0.1836\n",
            "    Prediction Time: 15.34s\n",
            "    Model Parameters: 63,660,002\n",
            "    Validation AUC: 0.7312\n",
            "\n",
            "============================================================\n",
            "ðŸ” Evaluating DIN-PReLU (Optimized)\n",
            "============================================================\n",
            "Model info:\n",
            "    Parameters: 63,658,578\n",
            "    Data format: sequences\n",
            "Making predictions...\n",
            "Calculating key metrics: AUC and Log Loss...\n",
            "DIN-PReLU (Optimized) Evaluation Results:\n",
            "    AUC: 0.7321\n",
            "    ROC AUC (sklearn): 0.7325\n",
            "    Log Loss: 0.1832\n",
            "    Prediction Time: 12.80s\n",
            "    Model Parameters: 63,658,578\n",
            "    Validation AUC: 0.7318\n",
            "\n",
            "============================================================\n",
            "ðŸ” Evaluating DeepFM\n",
            "============================================================\n",
            "Model info:\n",
            "    Parameters: 63,643,189\n",
            "    Data format: simple\n",
            "Making predictions...\n",
            "Calculating key metrics: AUC and Log Loss...\n",
            "DeepFM Evaluation Results:\n",
            "    AUC: 0.6908\n",
            "    ROC AUC (sklearn): 0.6913\n",
            "    Log Loss: 0.1949\n",
            "    Prediction Time: 11.25s\n",
            "    Model Parameters: 63,643,189\n",
            "    Validation AUC: 0.6914\n",
            "\n",
            "============================================================\n",
            "ðŸ” Evaluating Baseline\n",
            "============================================================\n",
            "Model info:\n",
            "    Parameters: 63,641,217\n",
            "    Data format: simple\n",
            "Making predictions...\n",
            "Calculating key metrics: AUC and Log Loss...\n",
            "Baseline Evaluation Results:\n",
            "    AUC: 0.6908\n",
            "    ROC AUC (sklearn): 0.6914\n",
            "    Log Loss: 0.1886\n",
            "    Prediction Time: 10.34s\n",
            "    Model Parameters: 63,641,217\n",
            "    Validation AUC: 0.6915\n",
            "\n",
            "SIMPLIFIED MODEL COMPARISON (Sorted by RelaImpr)\n",
            "================================================================================\n",
            "Model                AUC        RelaImpr   Log Loss   Params      \n",
            "-------------------- ---------- ---------- ---------- ------------\n",
            "DeepFM               0.6908     -0.00      0.1949     63,643,189  \n",
            "Baseline             0.6908     0.00       0.1886     63,641,217  \n",
            "DIN-DICE (Optimized) 0.7315     5.89       0.1836     63,660,002  \n",
            "DIN-PReLU (Optimized) 0.7321     5.98       0.1832     63,658,578  \n",
            "\n",
            "BEST MODELS BY CRITERIA:\n",
            "    Best AUC: DIN-PReLU (Optimized) (0.7321)\n",
            "    Best RelaImpr: DIN-PReLU (Optimized) (5.98%)\n",
            "    Best Log Loss: DIN-PReLU (Optimized) (0.1832)\n",
            "\n",
            "Evaluation results exported to CSV: evaluation_results/model_evaluation_simplified_-.csv\n",
            "\n",
            "EVALUATION SUMMARY:\n",
            "    Models evaluated: 4\n",
            "    Best overall model: DIN-PReLU (Optimized)\n",
            "    Best test AUC: 0.7321\n",
            "    Best RelaImpr: 6.0%\n",
            "    CSV Export: Results saved to evaluation_results/model_evaluation_simplified_-.csv\n",
            "    Plots: Saved to evaluation_results/ directory\n",
            "    ðŸ“ˆ AUC improvement over baseline: 0.0413 points (6.0%)\n",
            "\n",
            "ðŸŽ‰ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "ðŸ“… Evaluation completed on: -\n",
            "ðŸ‘¤ Evaluated by: Muhammad Sultan Nurrochman\n",
            "\n",
            "EVALUATION COMPLETED SUCCESSFULLY!\n",
            "4 models evaluated with core metrics\n",
            "Best performing model: DIN-PReLU (Optimized)\n",
            "Best test AUC: 0.7321\n",
            "Best RelaImpr model: DIN-PReLU (Optimized)\n",
            "Results exported to: evaluation_results/model_evaluation_simplified_-.csv\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 9: ENHANCED MODEL VISUALIZATIONS\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CELL 9: ENHANCED MODEL VISUALIZATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from datetime import datetime\n",
        "\n",
        "# Current timestamp and user information\n",
        "current_timestamp = \"-\"\n",
        "current_user = \"Muhammad Sultan Nurrochman\"\n",
        "\n",
        "def create_enhanced_visualizations():\n",
        "    \"\"\"Create enhanced visualizations for model comparison with professional styling\"\"\"\n",
        "\n",
        "    print(\"ðŸ“Š Creating enhanced visualizations...\")\n",
        "\n",
        "    # Check if evaluation results exist\n",
        "    if 'final_evaluation' not in globals() or not final_evaluation.get('success', False):\n",
        "        print(\"âŒ No evaluation results found! Please run evaluation cell first.\")\n",
        "        return {'success': False, 'error': 'No evaluation results available'}\n",
        "\n",
        "    # Create directories for saving visualizations\n",
        "    os.makedirs('evaluation_results/visualizations', exist_ok=True)\n",
        "\n",
        "    # Get evaluation results\n",
        "    evaluation_results = final_evaluation['evaluation_results']\n",
        "    successful_results = {k: v for k, v in evaluation_results.items() if v.get('success')}\n",
        "\n",
        "    # Sort models by RelaImpr (ascending)\n",
        "    sorted_models = sorted(successful_results.keys(),\n",
        "                        key=lambda x: successful_results[x].get('relaimpr', 0.0))\n",
        "\n",
        "    # Extract metrics for visualization\n",
        "    metrics = {\n",
        "        'model_names': sorted_models,\n",
        "        'auc': [successful_results[m]['auc'] for m in sorted_models],\n",
        "        'relaimpr': [successful_results[m].get('relaimpr', 0.0) for m in sorted_models],\n",
        "        'log_loss': [successful_results[m]['log_loss'] for m in sorted_models],\n",
        "        'params': [successful_results[m]['model_params'] for m in sorted_models]\n",
        "    }\n",
        "\n",
        "    # Color palette\n",
        "    colors = {\n",
        "        'primary': '#4287f5',\n",
        "        'secondary': '#f54242',\n",
        "        'tertiary': '#42f59e',\n",
        "        'background': '#f7f9fc',\n",
        "        'grid': '#e0e0e0',\n",
        "        'text': '#333333'\n",
        "    }\n",
        "\n",
        "    # Set plotting style\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    sns.set_context(\"talk\")\n",
        "\n",
        "    # 1. ENHANCED AUC COMPARISON\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    ax = plt.gca()\n",
        "    bars = plt.bar(metrics['model_names'], metrics['auc'], color=colors['primary'], alpha=0.8, width=0.6)\n",
        "\n",
        "    # Add value labels on top of bars\n",
        "    for bar, auc in zip(bars, metrics['auc']):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
        "                f'{auc:.4f}', ha='center', va='bottom', fontweight='bold', color=colors['text'])\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('Model Performance: AUC Comparison', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.ylabel('AUC Score', fontsize=12, labelpad=10)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.xticks(rotation=15, ha='right')\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/enhanced_auc_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 2. ENHANCED RELAIMPR COMPARISON\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    # Create gradient colors based on RelaImpr values\n",
        "    norm = plt.Normalize(min(metrics['relaimpr']), max(metrics['relaimpr']))\n",
        "    colors_gradient = plt.cm.RdYlGn(norm(metrics['relaimpr']))\n",
        "\n",
        "    bars = plt.bar(metrics['model_names'], metrics['relaimpr'], color=colors_gradient, alpha=0.9, width=0.6)\n",
        "\n",
        "    # Add value labels on top of bars\n",
        "    for bar, relaimpr in zip(bars, metrics['relaimpr']):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5 if relaimpr >= 0 else bar.get_height() - 1.5,\n",
        "                f'{relaimpr:.2f}%', ha='center', va='bottom' if relaimpr >= 0 else 'top',\n",
        "                fontweight='bold', color='black')\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('AUC-Based Relative Improvement (RelaImpr)', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.ylabel('Improvement Over Baseline (%)', fontsize=12, labelpad=10)\n",
        "    plt.axhline(y=0, color='gray', linestyle='--', alpha=0.6)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.xticks(rotation=15, ha='right')\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/enhanced_relaimpr_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 3. ENHANCED LOG LOSS COMPARISON - FIXED VERSION\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    # Lower log loss is better, so we use a different approach:\n",
        "    # 1. Use the correct order in Normalize\n",
        "    norm = plt.Normalize(min(metrics['log_loss']), max(metrics['log_loss']))\n",
        "    # 2. Use a reversed colormap instead\n",
        "    colors_gradient = plt.cm.RdYlGn_r(norm(metrics['log_loss']))\n",
        "\n",
        "    bars = plt.bar(metrics['model_names'], metrics['log_loss'], color=colors_gradient, alpha=0.9, width=0.6)\n",
        "\n",
        "    # Add value labels on top of bars\n",
        "    for bar, loss in zip(bars, metrics['log_loss']):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{loss:.4f}', ha='center', va='bottom', fontweight='bold', color='black')\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('Model Error: Log Loss Comparison', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.ylabel('Log Loss (Lower is Better)', fontsize=12, labelpad=10)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.xticks(rotation=15, ha='right')\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/enhanced_logloss_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 4. MODEL SIZE VS PERFORMANCE\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Create scatter plot with size based on parameters\n",
        "    sizes = np.array(metrics['params']) / 10000  # Scale down for better visualization\n",
        "\n",
        "    scatter = plt.scatter(metrics['auc'], metrics['relaimpr'], s=sizes,\n",
        "                         c=metrics['log_loss'], cmap='coolwarm_r', alpha=0.7)\n",
        "\n",
        "    # Add model names as annotations\n",
        "    for i, model in enumerate(metrics['model_names']):\n",
        "        plt.annotate(model, (metrics['auc'][i], metrics['relaimpr'][i]),\n",
        "                    xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('Model Performance Analysis: AUC vs RelaImpr', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.xlabel('AUC Score', fontsize=12, labelpad=10)\n",
        "    plt.ylabel('RelaImpr (%)', fontsize=12, labelpad=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add colorbar for log loss\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Log Loss (Lower is Better)', rotation=270, labelpad=20)\n",
        "\n",
        "    # Add size legend\n",
        "    sizes_legend = [100000, 150000, 200000]\n",
        "    labels = [f'{s:,} params' for s in sizes_legend]\n",
        "\n",
        "    # Create dummy scatter points for the legend\n",
        "    legend_elements = []\n",
        "    for size, label in zip(sizes_legend, labels):\n",
        "        legend_elements.append(plt.Line2D([0], [0], marker='o', color='w',\n",
        "                              label=label, markerfacecolor='gray',\n",
        "                              markersize=np.sqrt(size/10000)))\n",
        "\n",
        "    plt.legend(handles=legend_elements, title=\"Model Size\", loc=\"upper left\")\n",
        "\n",
        "    # Add reference lines\n",
        "    plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/model_performance_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 5. COMBINED METRICS RADAR CHART\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Prepare metrics for radar chart\n",
        "    # We need to normalize all metrics to 0-1 scale\n",
        "    model_count = len(metrics['model_names'])\n",
        "    metrics_for_radar = [\n",
        "        'AUC',\n",
        "        'Inv. Log Loss',  # Inverse of log loss so higher is better\n",
        "        'RelaImpr',\n",
        "        'Inv. Model Size'  # Inverse of model size so smaller is better\n",
        "    ]\n",
        "\n",
        "    # Normalize metrics\n",
        "    max_log_loss = max(metrics['log_loss'])\n",
        "    min_log_loss = min(metrics['log_loss'])\n",
        "    max_relaimpr = max(metrics['relaimpr'])\n",
        "    min_relaimpr = min(metrics['relaimpr'])\n",
        "    max_params = max(metrics['params'])\n",
        "    min_params = min(metrics['params'])\n",
        "\n",
        "    # Create radar chart data\n",
        "    radar_data = []\n",
        "    for i, model in enumerate(metrics['model_names']):\n",
        "        # Normalize all values to 0-1 range where 1 is best\n",
        "        auc_norm = metrics['auc'][i]\n",
        "\n",
        "        # For log loss (lower is better), so invert the normalization\n",
        "        log_loss_norm = 1 - ((metrics['log_loss'][i] - min_log_loss) / (max_log_loss - min_log_loss)\n",
        "                             if max_log_loss != min_log_loss else 0)\n",
        "\n",
        "        # For RelaImpr, handle special case where all values might be negative\n",
        "        if max_relaimpr <= 0:\n",
        "            # All negative, so higher (less negative) is better\n",
        "            relaimpr_norm = (metrics['relaimpr'][i] - min_relaimpr) / (max_relaimpr - min_relaimpr) if max_relaimpr != min_relaimpr else 0\n",
        "        else:\n",
        "            # Some positive values exist\n",
        "            if min_relaimpr < 0:\n",
        "                # Map from min_relaimpr to max_relaimpr to 0-1 range\n",
        "                relaimpr_range = max_relaimpr - min_relaimpr\n",
        "                relaimpr_norm = (metrics['relaimpr'][i] - min_relaimpr) / relaimpr_range if relaimpr_range != 0 else 0\n",
        "            else:\n",
        "                # All positive, simply normalize\n",
        "                relaimpr_norm = (metrics['relaimpr'][i] - min_relaimpr) / (max_relaimpr - min_relaimpr) if max_relaimpr != min_relaimpr else 0\n",
        "\n",
        "        # For model size (lower is better), so invert the normalization\n",
        "        params_norm = 1 - ((metrics['params'][i] - min_params) / (max_params - min_params) if max_params != min_params else 0)\n",
        "\n",
        "        radar_data.append([auc_norm, log_loss_norm, relaimpr_norm, params_norm])\n",
        "\n",
        "    # Radar chart angles\n",
        "    angles = np.linspace(0, 2*np.pi, len(metrics_for_radar), endpoint=False).tolist()\n",
        "    angles += angles[:1]  # Close the loop\n",
        "\n",
        "    # Set up radar chart\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "\n",
        "    # Draw radar chart for each model\n",
        "    colormap = plt.cm.get_cmap('tab10', len(metrics['model_names']))\n",
        "\n",
        "    for i, model in enumerate(metrics['model_names']):\n",
        "        values = radar_data[i]\n",
        "        values += values[:1]  # Close the loop\n",
        "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=model, color=colormap(i))\n",
        "        ax.fill(angles, values, alpha=0.1, color=colormap(i))\n",
        "\n",
        "    # Set radar chart labels\n",
        "    ax.set_thetagrids(np.degrees(angles[:-1]), metrics_for_radar)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_rlabel_position(0)\n",
        "    plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=8)\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('Model Comparison: Multi-Metric Radar Analysis', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/radar_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"âœ… Enhanced visualizations created successfully!\")\n",
        "    print(f\"ðŸ“‚ Saved to: evaluation_results/visualizations/\")\n",
        "    print(f\"ðŸ“Š Visualizations include:\")\n",
        "    print(f\"    - Enhanced AUC comparison\")\n",
        "    print(f\"    - Enhanced RelaImpr comparison\")\n",
        "    print(f\"    - Enhanced Log Loss comparison\")\n",
        "    print(f\"    - Model performance analysis (AUC vs RelaImpr)\")\n",
        "    print(f\"    - Multi-metric radar analysis\")\n",
        "\n",
        "    return {\n",
        "        'success': True,\n",
        "        'visualization_path': 'evaluation_results/visualizations/',\n",
        "        'plots_created': 5\n",
        "    }\n",
        "\n",
        "# Execute enhanced visualizations\n",
        "print(f\"Creating enhanced visualizations for model comparison...\")\n",
        "try:\n",
        "    visualization_results = create_enhanced_visualizations()\n",
        "\n",
        "    if visualization_results['success']:\n",
        "        print(f\"\\nðŸŽ¨ VISUALIZATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"ðŸ“ˆ {visualization_results['plots_created']} high-quality plots created\")\n",
        "        print(f\"ðŸ“ Results saved to: {visualization_results['visualization_path']}\")\n",
        "    else:\n",
        "        print(f\"âŒ Visualization failed: {visualization_results.get('error', 'Unknown error')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Visualization error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "eMAyEE-FEi3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184f95a0-f4ef-4ef7-f81c-525397f8674d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CELL 9: ENHANCED MODEL VISUALIZATIONS\n",
            "============================================================\n",
            "Creating enhanced visualizations for model comparison...\n",
            "ðŸ“Š Creating enhanced visualizations...\n",
            "âœ… Enhanced visualizations created successfully!\n",
            "ðŸ“‚ Saved to: evaluation_results/visualizations/\n",
            "ðŸ“Š Visualizations include:\n",
            "    - Enhanced AUC comparison\n",
            "    - Enhanced RelaImpr comparison\n",
            "    - Enhanced Log Loss comparison\n",
            "    - Model performance analysis (AUC vs RelaImpr)\n",
            "    - Multi-metric radar analysis\n",
            "\n",
            "ðŸŽ¨ VISUALIZATION COMPLETED SUCCESSFULLY!\n",
            "ðŸ“ˆ 5 high-quality plots created\n",
            "ðŸ“ Results saved to: evaluation_results/visualizations/\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL: DIN SCENARIO IMPLEMENTATION (BASELINE, HISTORICAL)\n",
        "# =====================================================================\n",
        "\n",
        "# Impor library yang mungkin belum ada (asumsi)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Asumsi variabel-variabel ini sudah ada dari sel sebelumnya\n",
        "# model_data = ...\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DIN SCENARIO IMPLEMENTATION (BASELINE, HISTORICAL)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Definisikan fungsi untuk membuat model DIN dengan variasi fitur\n",
        "def create_din_model_with_features(features_to_use, best_params=None):\n",
        "    \"\"\"\n",
        "    Membuat model DIN dengan kombinasi fitur yang berbeda.\n",
        "\n",
        "    Args:\n",
        "        features_to_use: List fitur yang digunakan ['user_id', 'item_id', 'sequence']\n",
        "        best_params: Dictionary berisi parameter hasil tuning untuk menimpa default.\n",
        "\n",
        "    Returns:\n",
        "        Model DIN yang telah dikonfigurasi dan parameter yang digunakan.\n",
        "    \"\"\"\n",
        "    # 1. Mulai dengan parameter default.\n",
        "    params = {\n",
        "        'attention_hidden': 16,\n",
        "        'dropout_rate': 0.5,\n",
        "        'l2_reg': 1e-5,\n",
        "        'l2_dense': 1e-5,\n",
        "        'dice_alpha_init': 0.4,\n",
        "        'dice_beta_init': 1.5,\n",
        "        'dice_epsilon': 1e-9,\n",
        "        'learning_rate': 1e-4,\n",
        "        'batch_size': 4096,\n",
        "        'label_smoothing': 0.1,\n",
        "        'hidden_units': [64, 32]\n",
        "    }\n",
        "\n",
        "    # 2. Jika best_params diberikan, timpa default dengan SEMUA nilai dari best_params.\n",
        "    if best_params:\n",
        "        print(\"Menggunakan parameter dari hasil tuning (best_params) untuk menimpa default.\")\n",
        "        params.update(best_params)\n",
        "    else:\n",
        "        print(\"Menggunakan parameter default karena tidak ada best_params yang diberikan.\")\n",
        "\n",
        "    # Parameter Model\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = params['hidden_units']\n",
        "    attention_hidden = params['attention_hidden']\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = params['dropout_rate']\n",
        "    l2_reg = params['l2_reg']\n",
        "    l2_dense = params['l2_dense']\n",
        "\n",
        "    # Parameter untuk aktivasi DICE\n",
        "    dice_params = {\n",
        "        'alpha_init': params['dice_alpha_init'],\n",
        "        'beta_init': params['dice_beta_init'],\n",
        "        'epsilon': params['dice_epsilon']\n",
        "    }\n",
        "\n",
        "    # Definisikan nama model berdasarkan fitur yang digunakan\n",
        "    if set(features_to_use) == set(['user_id', 'item_id']):\n",
        "        model_name = 'din_baseline'\n",
        "        print(f\"Membuat Baseline DIN (Hanya User ID, Item ID)\")\n",
        "    elif set(features_to_use) == set(['user_id', 'item_id', 'sequence']):\n",
        "        model_name = 'din_historical'\n",
        "        print(f\"Membuat Historical DIN (User ID, Item ID, Sequence)\")\n",
        "    else:\n",
        "        model_name = 'din_custom'\n",
        "        print(f\"Membuat Custom DIN dengan fitur: {features_to_use}\")\n",
        "\n",
        "    # Siapkan input layers\n",
        "    inputs = {}\n",
        "    inputs['user_id'] = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    inputs['item_id'] = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "\n",
        "    if 'sequence' in features_to_use:\n",
        "        inputs['sequence'] = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "        inputs['seq_length'] = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    user_emb = user_embedding_layer(inputs['user_id'])\n",
        "    target_item_emb = item_embedding_layer(inputs['item_id'])\n",
        "    feature_list = [user_emb, target_item_emb]\n",
        "\n",
        "    if 'sequence' in features_to_use:\n",
        "        sequence_emb = item_embedding_layer(inputs['sequence'])\n",
        "\n",
        "        # Asumsi DINAttention dan SequencePooling sudah didefinisikan di tempat lain\n",
        "        attention_scores, attended_emb = DINAttention(\n",
        "            hidden_units=attention_hidden, max_seq_len=max_seq_len, activation_type='dice',\n",
        "            dice_alpha_init=dice_params['alpha_init'], dice_beta_init=dice_params['beta_init'],\n",
        "            dice_epsilon=dice_params['epsilon'], name='din_attention'\n",
        "        )([sequence_emb, target_item_emb])\n",
        "\n",
        "        pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "            [attention_scores, attended_emb, inputs['seq_length']]\n",
        "        )\n",
        "        feature_list.append(pooled_sequence)\n",
        "\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')(feature_list)\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units, name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "        # Asumsi DiceActivation sudah didefinisikan di tempat lain\n",
        "        x = DiceActivation(\n",
        "            name=f'dice_{i+1}', alpha_init=dice_params['alpha_init'],\n",
        "            beta_init=dice_params['beta_init'], epsilon=dice_params['epsilon']\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "    model = tf.keras.Model(inputs=list(inputs.values()), outputs=output, name=model_name)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'], clipnorm=0.5)\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=params['label_smoothing'])\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "    ]\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "    print(f\"Model {model_name} berhasil dibuat!\")\n",
        "    print(f\"Total parameter: {model.count_params():,}\")\n",
        "\n",
        "    return model, params\n",
        "\n",
        "# 2. Fungsi untuk melatih model dengan skenario fitur tertentu\n",
        "def train_din_scenario(scenario_name, features_to_use, best_params=None, epochs=15):\n",
        "    \"\"\"\n",
        "    Melatih model DIN dengan skenario fitur spesifik.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TRAINING {scenario_name}\")\n",
        "    print(f\"Fitur: {features_to_use}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model, params = create_din_model_with_features(features_to_use, best_params)\n",
        "\n",
        "    train_x, val_x, test_x = {}, {}, {}\n",
        "    train_x['user_id'] = model_data['splits']['train']['user_ids']\n",
        "    train_x['item_id'] = model_data['splits']['train']['item_ids']\n",
        "    val_x['user_id'] = model_data['splits']['val']['user_ids']\n",
        "    val_x['item_id'] = model_data['splits']['val']['item_ids']\n",
        "    test_x['user_id'] = model_data['splits']['test']['user_ids']\n",
        "    test_x['item_id'] = model_data['splits']['test']['item_ids']\n",
        "\n",
        "    if 'sequence' in features_to_use:\n",
        "        train_x['sequence'] = model_data['splits']['train']['sequences']\n",
        "        train_x['seq_length'] = model_data['splits']['train']['seq_lengths']\n",
        "        val_x['sequence'] = model_data['splits']['val']['sequences']\n",
        "        val_x['seq_length'] = model_data['splits']['val']['seq_lengths']\n",
        "        test_x['sequence'] = model_data['splits']['test']['sequences']\n",
        "        test_x['seq_length'] = model_data['splits']['test']['seq_lengths']\n",
        "\n",
        "    train_y = model_data['splits']['train']['labels']\n",
        "    val_y = model_data['splits']['val']['labels']\n",
        "    test_y = model_data['splits']['test']['labels']\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True, mode='max'),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, min_lr=1e-6, mode='max')\n",
        "    ]\n",
        "\n",
        "    os.makedirs(f'results/{scenario_name}', exist_ok=True)\n",
        "    checkpoint_path = f'results/{scenario_name}/model_checkpoint.weights.h5'\n",
        "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_auc', mode='max', save_best_only=True, save_weights_only=True)\n",
        "    callbacks.append(model_checkpoint)\n",
        "\n",
        "    csv_path = f'results/{scenario_name}/training_history.csv'\n",
        "    csv_logger = tf.keras.callbacks.CSVLogger(csv_path)\n",
        "    callbacks.append(csv_logger)\n",
        "\n",
        "    batch_size = params['batch_size']\n",
        "    print(f\"\\nMemulai training untuk {scenario_name}...\")\n",
        "    print(f\"Training dengan parameter: {json.dumps(params, indent=4)}\")\n",
        "\n",
        "    history = model.fit(\n",
        "        x=train_x, y=train_y,\n",
        "        validation_data=(val_x, val_y),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(f\"\\nEvaluasi {scenario_name} pada test set...\")\n",
        "    test_results = model.evaluate(test_x, test_y, verbose=1)\n",
        "    test_metrics = {\n",
        "        'test_loss': test_results[0], 'test_auc': test_results[1],\n",
        "    }\n",
        "\n",
        "    test_preds = model.predict(test_x, batch_size=batch_size)\n",
        "    test_metrics['test_logloss'] = log_loss(test_y, test_preds)\n",
        "\n",
        "    metrics_path = f'results/{scenario_name}/test_metrics.json'\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        json.dump(test_metrics, f, indent=4)\n",
        "\n",
        "    print(f\"\\nMetrik tes untuk {scenario_name}:\")\n",
        "    for metric, value in test_metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "    return model, history, test_metrics\n",
        "\n",
        "# 3. Jalankan eksperimen untuk setiap skenario\n",
        "# Gunakan parameter terbaik dari hasil tuning yang Anda berikan\n",
        "din_best_params = {\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 8192,\n",
        "    \"dropout_rate\": 0.4,\n",
        "    \"l2_reg\": 1e-05,\n",
        "    \"l2_dense\": 0.0001,\n",
        "    \"dice_alpha_init\": 0.35,\n",
        "    \"dice_beta_init\": 1.0,\n",
        "    \"dice_epsilon\": 1e-09,\n",
        "    \"attention_hidden\": 16,\n",
        "    \"label_smoothing\": 0.15,\n",
        "    \"hidden_units\": [128, 64]\n",
        "}\n",
        "\n",
        "# 3.1 Baseline DIN\n",
        "baseline_model, baseline_history, baseline_metrics = train_din_scenario(\n",
        "    scenario_name=\"baseline_din\",\n",
        "    features_to_use=['user_id', 'item_id'],\n",
        "    best_params=din_best_params,\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "# 3.2 Historical DIN\n",
        "historical_model, historical_history, historical_metrics = train_din_scenario(\n",
        "    scenario_name=\"historical_din\",\n",
        "    features_to_use=['user_id', 'item_id', 'sequence'],\n",
        "    best_params=din_best_params,\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "# 4. Visualisasikan dan analisis hasil (kode ini tetap sama seperti sebelumnya)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HASIL PERBANDINGAN SKENARIO DIN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "scenarios = ['Baseline DIN', 'Historical DIN']\n",
        "test_aucs = [baseline_metrics['test_auc'], historical_metrics['test_auc']]\n",
        "test_loglosses = [baseline_metrics['test_logloss'], historical_metrics['test_logloss']]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(scenarios, test_aucs, color=['lightblue', 'lightgreen'])\n",
        "plt.ylabel('Test AUC')\n",
        "plt.title('Perbandingan AUC antar Skenario DIN')\n",
        "plt.ylim(bottom=max(0, min(test_aucs) - 0.05), top=min(1.0, max(test_aucs) + 0.05))\n",
        "for i, v in enumerate(test_aucs):\n",
        "    plt.text(i, v + 0.002, f'{v:.4f}', ha='center')\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/din_scenarios_auc_comparison.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "results_summary = pd.DataFrame({\n",
        "    'Scenario': scenarios,\n",
        "    'Test AUC': test_aucs,\n",
        "    'Test Log Loss': test_loglosses,\n",
        "})\n",
        "\n",
        "print(\"\\nPerbandingan Metrik antar Skenario:\")\n",
        "print(results_summary.to_string(index=False))\n",
        "results_summary.to_csv('results/din_scenarios_comparison.csv', index=False)\n",
        "print(\"\\nHasil perbandingan disimpan di: results/din_scenarios_comparison.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EKSPERIMEN SKENARIO DIN SELESAI\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "6CZK3WF8ILW_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6f9fb95-2927-4639-e636-a2e93b35a510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIN SCENARIO IMPLEMENTATION (BASELINE, HISTORICAL)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TRAINING baseline_din\n",
            "Fitur: ['user_id', 'item_id']\n",
            "============================================================\n",
            "Menggunakan parameter dari hasil tuning (best_params) untuk menimpa default.\n",
            "Membuat Baseline DIN (Hanya User ID, Item ID)\n",
            "Model din_baseline berhasil dibuat!\n",
            "Total parameter: 63,651,137\n",
            "\n",
            "Memulai training untuk baseline_din...\n",
            "Training dengan parameter: {\n",
            "    \"attention_hidden\": 16,\n",
            "    \"dropout_rate\": 0.4,\n",
            "    \"l2_reg\": 1e-05,\n",
            "    \"l2_dense\": 0.0001,\n",
            "    \"dice_alpha_init\": 0.35,\n",
            "    \"dice_beta_init\": 1.0,\n",
            "    \"dice_epsilon\": 1e-09,\n",
            "    \"learning_rate\": 0.0001,\n",
            "    \"batch_size\": 8192,\n",
            "    \"label_smoothing\": 0.15,\n",
            "    \"hidden_units\": [\n",
            "        128,\n",
            "        64\n",
            "    ]\n",
            "}\n",
            "Epoch 1/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 19ms/step - auc: 0.5015 - loss: 0.8645 - val_auc: 0.5500 - val_loss: 0.4391 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 16ms/step - auc: 0.5084 - loss: 0.4461 - val_auc: 0.5866 - val_loss: 0.3965 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 16ms/step - auc: 0.5436 - loss: 0.3959 - val_auc: 0.6457 - val_loss: 0.3761 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 16ms/step - auc: 0.6581 - loss: 0.3740 - val_auc: 0.6555 - val_loss: 0.3679 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - auc: 0.7054 - loss: 0.3649 - val_auc: 0.6544 - val_loss: 0.3663 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - auc: 0.7299 - loss: 0.3615 - val_auc: 0.6356 - val_loss: 0.3706 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - auc: 0.7903 - loss: 0.3550 - val_auc: 0.5960 - val_loss: 0.3834 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - auc: 0.8512 - loss: 0.3448 - val_auc: 0.5494 - val_loss: 0.3881 - learning_rate: 5.0000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - auc: 0.8609 - loss: 0.3425 - val_auc: 0.5353 - val_loss: 0.3897 - learning_rate: 5.0000e-05\n",
            "\n",
            "Evaluasi baseline_din pada test set...\n",
            "\u001b[1m82994/82994\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 3ms/step - auc: 0.6546 - loss: 0.3687\n",
            "\u001b[1m325/325\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\n",
            "Metrik tes untuk baseline_din:\n",
            "  test_loss: 0.3686\n",
            "  test_auc: 0.6549\n",
            "  test_logloss: 0.2248\n",
            "\n",
            "============================================================\n",
            "TRAINING historical_din\n",
            "Fitur: ['user_id', 'item_id', 'sequence']\n",
            "============================================================\n",
            "Menggunakan parameter dari hasil tuning (best_params) untuk menimpa default.\n",
            "Membuat Historical DIN (User ID, Item ID, Sequence)\n",
            "Model din_historical berhasil dibuat!\n",
            "Total parameter: 63,657,570\n",
            "\n",
            "Memulai training untuk historical_din...\n",
            "Training dengan parameter: {\n",
            "    \"attention_hidden\": 16,\n",
            "    \"dropout_rate\": 0.4,\n",
            "    \"l2_reg\": 1e-05,\n",
            "    \"l2_dense\": 0.0001,\n",
            "    \"dice_alpha_init\": 0.35,\n",
            "    \"dice_beta_init\": 1.0,\n",
            "    \"dice_epsilon\": 1e-09,\n",
            "    \"learning_rate\": 0.0001,\n",
            "    \"batch_size\": 8192,\n",
            "    \"label_smoothing\": 0.15,\n",
            "    \"hidden_units\": [\n",
            "        128,\n",
            "        64\n",
            "    ]\n",
            "}\n",
            "Epoch 1/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 23ms/step - auc: 0.5007 - loss: 0.8847 - val_auc: 0.5469 - val_loss: 0.4473 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 19ms/step - auc: 0.5075 - loss: 0.4523 - val_auc: 0.5846 - val_loss: 0.3983 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 19ms/step - auc: 0.5399 - loss: 0.3972 - val_auc: 0.6438 - val_loss: 0.3766 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 19ms/step - auc: 0.6505 - loss: 0.3746 - val_auc: 0.6548 - val_loss: 0.3682 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 19ms/step - auc: 0.7010 - loss: 0.3655 - val_auc: 0.6548 - val_loss: 0.3665 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 18ms/step - auc: 0.7267 - loss: 0.3621 - val_auc: 0.6373 - val_loss: 0.3708 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 18ms/step - auc: 0.7886 - loss: 0.3559 - val_auc: 0.5977 - val_loss: 0.3814 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 18ms/step - auc: 0.8578 - loss: 0.3439 - val_auc: 0.5330 - val_loss: 0.3916 - learning_rate: 5.0000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 18ms/step - auc: 0.8707 - loss: 0.3405 - val_auc: 0.5170 - val_loss: 0.3953 - learning_rate: 5.0000e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 18ms/step - auc: 0.8810 - loss: 0.3366 - val_auc: 0.5293 - val_loss: 0.3963 - learning_rate: 5.0000e-05\n",
            "\n",
            "Evaluasi historical_din pada test set...\n",
            "\u001b[1m82994/82994\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3ms/step - auc: 0.6536 - loss: 0.3673\n",
            "\u001b[1m325/325\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\n",
            "Metrik tes untuk historical_din:\n",
            "  test_loss: 0.3672\n",
            "  test_auc: 0.6541\n",
            "  test_logloss: 0.2257\n",
            "\n",
            "============================================================\n",
            "HASIL PERBANDINGAN SKENARIO DIN\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perbandingan Metrik antar Skenario:\n",
            "      Scenario  Test AUC  Test Log Loss\n",
            "  Baseline DIN  0.654923       0.224782\n",
            "Historical DIN  0.654080       0.225716\n",
            "\n",
            "Hasil perbandingan disimpan di: results/din_scenarios_comparison.csv\n",
            "\n",
            "============================================================\n",
            "EKSPERIMEN SKENARIO DIN SELESAI\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k6HC2kfKX26p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}