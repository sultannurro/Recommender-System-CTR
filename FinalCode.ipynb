{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 1: SETUP SEDERHANA - HARDCODED SEMUA\n",
        "# =====================================================================\n",
        "\n",
        "# Mount drive dan import libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DIN IMPLEMENTATION - HARDCODED SIMPLE VERSION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Set seeds\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "# Paths\n",
        "ROOT_PATH = '/content/drive/MyDrive/TA/DIEN/DIEN-tf2/new/dataset'\n",
        "CHECKPOINT_ROOT = '/content/drive/MyDrive/TA/TAOBAO/checkpoints'\n",
        "SAVE_PATH = '/content/drive/MyDrive/TA/TAOBAO/models'\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(CHECKPOINT_ROOT, exist_ok=True)\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# File paths\n",
        "RAW_SAMPLE_PATH = os.path.join(ROOT_PATH, 'raw_sample.csv')\n",
        "AD_FEATURE_PATH = os.path.join(ROOT_PATH, 'ad_feature.csv')\n",
        "USER_PROFILE_PATH = os.path.join(ROOT_PATH, 'user_profile.csv')\n",
        "USER_BEHAVIOR_PATH = os.path.join(ROOT_PATH, 'UserBehavior.csv')\n",
        "\n",
        "# HARDCODED SAMPLING - hanya 2 parameter\n",
        "RAW_SAMPLE_SIZE = 26557961\n",
        "USER_BEHAVIOR_SAMPLE_SIZE = 50000000\n",
        "\n",
        "print(f\"Setup completed\")\n",
        "print(f\"Raw sample size: {RAW_SAMPLE_SIZE:,}\")\n",
        "print(f\"User behavior size: {USER_BEHAVIOR_SAMPLE_SIZE:,}\")\n",
        "print(f\"Models: DIN-DICE, DIN-PReLU, DeepFM, Baseline\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ STEP 1 COMPLETED!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2YDHJg4t8xh",
        "outputId": "1ef783ae-d889-4988-d3a4-25249409756d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "================================================================================\n",
            "DIN IMPLEMENTATION - HARDCODED SIMPLE VERSION\n",
            "================================================================================\n",
            "TensorFlow version: 2.18.0\n",
            "Setup completed\n",
            "Raw sample size: 26,557,961\n",
            "User behavior size: 50,000,000\n",
            "Models: DIN-DICE, DIN-PReLU, DeepFM, Baseline\n",
            "\n",
            "ðŸŽ¯ STEP 1 COMPLETED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "nama_folder = \"tuning_results\"\n",
        "din_dice = 'din_dice'\n",
        "din_prelu = 'din_prelu'\n",
        "deepfm = 'deepfm'\n",
        "baseline = 'baseline'\n",
        "\n",
        "os.makedirs(nama_folder)\n",
        "os.makedirs(os.path.join(nama_folder, din_dice))\n",
        "os.makedirs(os.path.join(nama_folder, din_prelu))\n",
        "os.makedirs(os.path.join(nama_folder, deepfm))\n",
        "os.makedirs(os.path.join(nama_folder, baseline))"
      ],
      "metadata": {
        "id": "kMsa90d3ID2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 2: DATA LOADING DENGAN HEAD INSPECTION\n",
        "# =====================================================================\n",
        "\n",
        "def load_data_simple():\n",
        "    \"\"\"Load data dengan head inspection untuk setiap dataset\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DATA LOADING DENGAN HEAD INSPECTION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        # 1. RAW SAMPLE\n",
        "        print(f\"\\nðŸ“Š 1. LOADING RAW SAMPLE...\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Load dan inspect head\n",
        "        raw_sample = pd.read_csv(RAW_SAMPLE_PATH)\n",
        "        print(f\"ðŸ“‹ Raw Sample Shape: {raw_sample.shape}\")\n",
        "        print(f\"ðŸ“‹ Raw Sample Columns: {list(raw_sample.columns)}\")\n",
        "        print(f\"\\nðŸ” Raw Sample Head (5 rows):\")\n",
        "        print(raw_sample.head())\n",
        "\n",
        "        print(f\"\\nRaw Sample Info:\")\n",
        "        print(f\"    Data types: {raw_sample.dtypes.value_counts().to_dict()}\")\n",
        "        print(f\"    Missing values: {raw_sample.isnull().sum().sum()}\")\n",
        "        if 'clk' in raw_sample.columns:\n",
        "            print(f\"    CTR: {raw_sample['clk'].mean():.4f}\")\n",
        "\n",
        "        # Drop data leakage\n",
        "        if 'nonclk' in raw_sample.columns:\n",
        "            raw_sample = raw_sample.drop('nonclk', axis=1)\n",
        "            print(f\"    Removed nonclk feature\")\n",
        "\n",
        "        # Sampling stratified\n",
        "        if len(raw_sample) > RAW_SAMPLE_SIZE:\n",
        "            ctr = raw_sample['clk'].mean()\n",
        "            pos_data = raw_sample[raw_sample['clk'] == 1]\n",
        "            neg_data = raw_sample[raw_sample['clk'] == 0]\n",
        "\n",
        "            pos_samples = int(RAW_SAMPLE_SIZE * ctr)\n",
        "            neg_samples = RAW_SAMPLE_SIZE - pos_samples\n",
        "\n",
        "            sampled_pos = pos_data.sample(n=min(pos_samples, len(pos_data)), random_state=1234)\n",
        "            sampled_neg = neg_data.sample(n=min(neg_samples, len(neg_data)), random_state=1234)\n",
        "\n",
        "            raw_sample = pd.concat([sampled_pos, sampled_neg], ignore_index=True)\n",
        "            raw_sample = raw_sample.sample(frac=1, random_state=1234).reset_index(drop=True)\n",
        "\n",
        "            print(f\"    Sampled to {RAW_SAMPLE_SIZE:,} rows\")\n",
        "\n",
        "        print(f\"    Final Raw Sample: {raw_sample.shape}, CTR: {raw_sample['clk'].mean():.4f}\")\n",
        "\n",
        "        # 2. AD FEATURES\n",
        "        print(f\"\\nðŸ·ï¸ 2. LOADING AD FEATURES...\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        ad_features = pd.read_csv(AD_FEATURE_PATH)\n",
        "        print(f\"Ad Features Shape: {ad_features.shape}\")\n",
        "        print(f\"Ad Features Columns: {list(ad_features.columns)}\")\n",
        "        print(f\"\\nðŸ” Ad Features Head (5 rows):\")\n",
        "        print(ad_features.head())\n",
        "\n",
        "        print(f\"\\nAd Features Info:\")\n",
        "        print(f\"    Data types: {ad_features.dtypes.value_counts().to_dict()}\")\n",
        "        print(f\"    Missing values: {ad_features.isnull().sum().sum()}\")\n",
        "        print(f\"    Unique items: {ad_features['adgroup_id'].nunique():,}\")\n",
        "        if 'price' in ad_features.columns:\n",
        "            price_stats = ad_features['price'].describe()\n",
        "            print(f\"    Price range: [{price_stats['min']:.2f}, {price_stats['max']:.2f}]\")\n",
        "            print(f\"    Price missing: {ad_features['price'].isnull().sum():,}\")\n",
        "\n",
        "        # 3. USER PROFILES\n",
        "        print(f\"\\nðŸ‘¤ 3. LOADING USER PROFILES...\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        user_profiles = pd.read_csv(USER_PROFILE_PATH)\n",
        "        print(f\"User Profiles Shape: {user_profiles.shape}\")\n",
        "        print(f\"User Profiles Columns: {list(user_profiles.columns)}\")\n",
        "        print(f\"\\nUser Profiles Head (5 rows):\")\n",
        "        print(user_profiles.head())\n",
        "\n",
        "        print(f\"\\nUser Profiles Info:\")\n",
        "        print(f\"    Data types: {user_profiles.dtypes.value_counts().to_dict()}\")\n",
        "        print(f\"    Missing values: {user_profiles.isnull().sum().sum()}\")\n",
        "        print(f\"    Unique users: {user_profiles['userid'].nunique():,}\")\n",
        "\n",
        "        # Gender distribution if available\n",
        "        if 'final_gender_code' in user_profiles.columns:\n",
        "            gender_dist = user_profiles['final_gender_code'].value_counts().head()\n",
        "            print(f\"    Gender distribution: {gender_dist.to_dict()}\")\n",
        "\n",
        "        # Age level distribution if available\n",
        "        if 'age_level' in user_profiles.columns:\n",
        "            age_dist = user_profiles['age_level'].value_counts().head()\n",
        "            print(f\"    Age level distribution: {age_dist.to_dict()}\")\n",
        "\n",
        "        # 4. USER BEHAVIOR\n",
        "        print(f\"\\n4. LOADING USER BEHAVIOR...\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Load first chunk to show head\n",
        "        first_chunk = pd.read_csv(USER_BEHAVIOR_PATH,\n",
        "                                header=None,\n",
        "                                names=['user_id', 'item_id', 'category_id', 'behavior_type', 'timestamp'],\n",
        "                                nrows=10)\n",
        "\n",
        "        print(f\"ðŸ“‹ User Behavior Columns: {list(first_chunk.columns)}\")\n",
        "        print(f\"\\nðŸ” User Behavior Head (5 rows):\")\n",
        "        print(first_chunk.head())\n",
        "\n",
        "        print(f\"\\nðŸ“Š User Behavior Preview Info:\")\n",
        "        print(f\"    Data types: {first_chunk.dtypes.to_dict()}\")\n",
        "        print(f\"    Behavior types: {first_chunk['behavior_type'].value_counts().to_dict()}\")\n",
        "\n",
        "        # Convert sample timestamps\n",
        "        sample_timestamps = first_chunk['timestamp'].head(3)\n",
        "        readable_times = [pd.to_datetime(ts, unit='s').strftime('%Y-%m-%d %H:%M:%S') for ts in sample_timestamps]\n",
        "        print(f\"    Sample timestamps: {readable_times}\")\n",
        "\n",
        "        # Load full behavior data in chunks\n",
        "        print(f\"\\nðŸ”„ Loading full user behavior data...\")\n",
        "        chunks = []\n",
        "        total_rows = 0\n",
        "\n",
        "        for i, chunk in enumerate(pd.read_csv(USER_BEHAVIOR_PATH,\n",
        "                                header=None,\n",
        "                                names=['user_id', 'item_id', 'category_id', 'behavior_type', 'timestamp'],\n",
        "                                chunksize=500000)):\n",
        "            chunks.append(chunk)\n",
        "            total_rows += len(chunk)\n",
        "            print(f\"    Chunk {i+1}: {len(chunk):,} rows (Total: {total_rows:,})\")\n",
        "\n",
        "            if total_rows >= USER_BEHAVIOR_SAMPLE_SIZE:\n",
        "                break\n",
        "\n",
        "        user_behavior = pd.concat(chunks, ignore_index=True)\n",
        "        if len(user_behavior) > USER_BEHAVIOR_SAMPLE_SIZE:\n",
        "            user_behavior = user_behavior.sample(n=USER_BEHAVIOR_SAMPLE_SIZE, random_state=1234).reset_index(drop=True)\n",
        "\n",
        "        print(f\"    Final User Behavior: {user_behavior.shape}\")\n",
        "        print(f\"    Final behavior types: {user_behavior['behavior_type'].value_counts().to_dict()}\")\n",
        "        print(f\"    Unique users: {user_behavior['user_id'].nunique():,}\")\n",
        "        print(f\"    Unique items: {user_behavior['item_id'].nunique():,}\")\n",
        "\n",
        "        # 5. DATASET OVERLAP ANALYSIS\n",
        "        print(f\"\\n5. DATASET OVERLAP ANALYSIS\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Convert IDs to string for consistent comparison\n",
        "        raw_users = set(raw_sample['user'].astype(str))\n",
        "        profile_users = set(user_profiles['userid'].astype(str))\n",
        "        behavior_users = set(user_behavior['user_id'].astype(str))\n",
        "\n",
        "        raw_items = set(raw_sample['adgroup_id'].astype(str))\n",
        "        ad_items = set(ad_features['adgroup_id'].astype(str))\n",
        "        behavior_items = set(user_behavior['item_id'].astype(str))\n",
        "\n",
        "        # User overlaps\n",
        "        raw_profile_overlap = len(raw_users & profile_users)\n",
        "        raw_behavior_overlap = len(raw_users & behavior_users)\n",
        "        all_user_overlap = len(raw_users & profile_users & behavior_users)\n",
        "\n",
        "        print(f\"USER OVERLAPS:\")\n",
        "        print(f\"    Raw sample users: {len(raw_users):,}\")\n",
        "        print(f\"    Profile users: {len(profile_users):,}\")\n",
        "        print(f\"    Behavior users: {len(behavior_users):,}\")\n",
        "        print(f\"    Raw âˆ© Profiles: {raw_profile_overlap:,} ({raw_profile_overlap/len(raw_users)*100:.1f}%)\")\n",
        "        print(f\"    Raw âˆ© Behavior: {raw_behavior_overlap:,} ({raw_behavior_overlap/len(raw_users)*100:.1f}%)\")\n",
        "        print(f\"    All 3 datasets: {all_user_overlap:,} ({all_user_overlap/len(raw_users)*100:.1f}%)\")\n",
        "\n",
        "        # Item overlaps\n",
        "        raw_ad_overlap = len(raw_items & ad_items)\n",
        "        raw_behavior_item_overlap = len(raw_items & behavior_items)\n",
        "\n",
        "        print(f\"\\nITEM OVERLAPS:\")\n",
        "        print(f\"    Raw sample items: {len(raw_items):,}\")\n",
        "        print(f\"    Ad feature items: {len(ad_items):,}\")\n",
        "        print(f\"    Behavior items: {len(behavior_items):,}\")\n",
        "        print(f\"    Raw âˆ© Ad features: {raw_ad_overlap:,} ({raw_ad_overlap/len(raw_items)*100:.1f}%)\")\n",
        "        print(f\"    Raw âˆ© Behavior: {raw_behavior_item_overlap:,} ({raw_behavior_item_overlap/len(raw_items)*100:.1f}%)\")\n",
        "\n",
        "        # 6. SUMMARY\n",
        "        print(f\"\\n6. DATA LOADING SUMMARY\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Raw Sample: {raw_sample.shape} | CTR: {raw_sample['clk'].mean():.4f}\")\n",
        "        print(f\"Ad Features: {ad_features.shape} | Items: {ad_features['adgroup_id'].nunique():,}\")\n",
        "        print(f\"User Profiles: {user_profiles.shape} | Users: {user_profiles['userid'].nunique():,}\")\n",
        "        print(f\"User Behavior: {user_behavior.shape} | Users: {user_behavior['user_id'].nunique():,}\")\n",
        "        print(f\"Data quality: Good overlaps for feature engineering\")\n",
        "\n",
        "        return raw_sample, ad_features, user_profiles, user_behavior\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, None, None\n",
        "\n",
        "# Execute loading with detailed inspection\n",
        "print(\"ðŸš€ Loading data with detailed inspection...\")\n",
        "raw_sample, ad_features, user_profiles, user_behavior = load_data_simple()\n",
        "\n",
        "if raw_sample is not None:\n",
        "    print(f\"\\nSTEP 2 COMPLETED!\")\n",
        "    print(f\"All data loaded with complete head inspection\")\n",
        "    print(f\"Dataset overlaps analyzed\")\n",
        "    print(f\"Data quality verified\")\n",
        "else:\n",
        "    print(f\"âŒ STEP 2 FAILED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjCqtk-QuAEJ",
        "outputId": "cece3e0e-578a-43ec-fc8f-8c05818afdc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Loading data with detailed inspection...\n",
            "\n",
            "============================================================\n",
            "DATA LOADING DENGAN HEAD INSPECTION\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š 1. LOADING RAW SAMPLE...\n",
            "----------------------------------------\n",
            "ðŸ“‹ Raw Sample Shape: (26557961, 6)\n",
            "ðŸ“‹ Raw Sample Columns: ['user', 'time_stamp', 'adgroup_id', 'pid', 'nonclk', 'clk']\n",
            "\n",
            "ðŸ” Raw Sample Head (5 rows):\n",
            "     user  time_stamp  adgroup_id          pid  nonclk  clk\n",
            "0  581738  1494137644           1  430548_1007       1    0\n",
            "1  449818  1494638778           3  430548_1007       1    0\n",
            "2  914836  1494650879           4  430548_1007       1    0\n",
            "3  914836  1494651029           5  430548_1007       1    0\n",
            "4  399907  1494302958           8  430548_1007       1    0\n",
            "\n",
            "Raw Sample Info:\n",
            "    Data types: {dtype('int64'): 5, dtype('O'): 1}\n",
            "    Missing values: 0\n",
            "    CTR: 0.0514\n",
            "    Removed nonclk feature\n",
            "    Final Raw Sample: (26557961, 5), CTR: 0.0514\n",
            "\n",
            "ðŸ·ï¸ 2. LOADING AD FEATURES...\n",
            "----------------------------------------\n",
            "Ad Features Shape: (846811, 6)\n",
            "Ad Features Columns: ['adgroup_id', 'cate_id', 'campaign_id', 'customer', 'brand', 'price']\n",
            "\n",
            "ðŸ” Ad Features Head (5 rows):\n",
            "   adgroup_id  cate_id  campaign_id  customer     brand   price\n",
            "0       63133     6406        83237         1   95471.0  170.00\n",
            "1      313401     6406        83237         1   87331.0  199.00\n",
            "2      248909      392        83237         1   32233.0   38.00\n",
            "3      208458      392        83237         1  174374.0  139.00\n",
            "4      110847     7211       135256         2  145952.0   32.99\n",
            "\n",
            "Ad Features Info:\n",
            "    Data types: {dtype('int64'): 4, dtype('float64'): 2}\n",
            "    Missing values: 246330\n",
            "    Unique items: 846,811\n",
            "    Price range: [0.01, 99999999.00]\n",
            "    Price missing: 0\n",
            "\n",
            "ðŸ‘¤ 3. LOADING USER PROFILES...\n",
            "----------------------------------------\n",
            "User Profiles Shape: (1061768, 9)\n",
            "User Profiles Columns: ['userid', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level', 'pvalue_level', 'shopping_level', 'occupation', 'new_user_class_level ']\n",
            "\n",
            "User Profiles Head (5 rows):\n",
            "   userid  cms_segid  cms_group_id  final_gender_code  age_level  \\\n",
            "0     234          0             5                  2          5   \n",
            "1     523          5             2                  2          2   \n",
            "2     612          0             8                  1          2   \n",
            "3    1670          0             4                  2          4   \n",
            "4    2545          0            10                  1          4   \n",
            "\n",
            "   pvalue_level  shopping_level  occupation  new_user_class_level   \n",
            "0           NaN               3           0                    3.0  \n",
            "1           1.0               3           1                    2.0  \n",
            "2           2.0               3           0                    NaN  \n",
            "3           NaN               1           0                    NaN  \n",
            "4           NaN               3           0                    NaN  \n",
            "\n",
            "User Profiles Info:\n",
            "    Data types: {dtype('int64'): 7, dtype('float64'): 2}\n",
            "    Missing values: 920837\n",
            "    Unique users: 1,061,768\n",
            "    Gender distribution: {2: 684251, 1: 377517}\n",
            "    Age level distribution: {3: 307340, 4: 261751, 5: 214462, 2: 189617, 1: 65568}\n",
            "\n",
            "4. LOADING USER BEHAVIOR...\n",
            "----------------------------------------\n",
            "ðŸ“‹ User Behavior Columns: ['user_id', 'item_id', 'category_id', 'behavior_type', 'timestamp']\n",
            "\n",
            "ðŸ” User Behavior Head (5 rows):\n",
            "   user_id  item_id  category_id behavior_type   timestamp\n",
            "0        1  2268318      2520377            pv  1511544070\n",
            "1        1  2333346      2520771            pv  1511561733\n",
            "2        1  2576651       149192            pv  1511572885\n",
            "3        1  3830808      4181361            pv  1511593493\n",
            "4        1  4365585      2520377            pv  1511596146\n",
            "\n",
            "ðŸ“Š User Behavior Preview Info:\n",
            "    Data types: {'user_id': dtype('int64'), 'item_id': dtype('int64'), 'category_id': dtype('int64'), 'behavior_type': dtype('O'), 'timestamp': dtype('int64')}\n",
            "    Behavior types: {'pv': 10}\n",
            "    Sample timestamps: ['2017-11-24 17:21:10', '2017-11-24 22:15:33', '2017-11-25 01:21:25']\n",
            "\n",
            "ðŸ”„ Loading full user behavior data...\n",
            "    Chunk 1: 500,000 rows (Total: 500,000)\n",
            "    Chunk 2: 500,000 rows (Total: 1,000,000)\n",
            "    Chunk 3: 500,000 rows (Total: 1,500,000)\n",
            "    Chunk 4: 500,000 rows (Total: 2,000,000)\n",
            "    Chunk 5: 500,000 rows (Total: 2,500,000)\n",
            "    Chunk 6: 500,000 rows (Total: 3,000,000)\n",
            "    Chunk 7: 500,000 rows (Total: 3,500,000)\n",
            "    Chunk 8: 500,000 rows (Total: 4,000,000)\n",
            "    Chunk 9: 500,000 rows (Total: 4,500,000)\n",
            "    Chunk 10: 500,000 rows (Total: 5,000,000)\n",
            "    Chunk 11: 500,000 rows (Total: 5,500,000)\n",
            "    Chunk 12: 500,000 rows (Total: 6,000,000)\n",
            "    Chunk 13: 500,000 rows (Total: 6,500,000)\n",
            "    Chunk 14: 500,000 rows (Total: 7,000,000)\n",
            "    Chunk 15: 500,000 rows (Total: 7,500,000)\n",
            "    Chunk 16: 500,000 rows (Total: 8,000,000)\n",
            "    Chunk 17: 500,000 rows (Total: 8,500,000)\n",
            "    Chunk 18: 500,000 rows (Total: 9,000,000)\n",
            "    Chunk 19: 500,000 rows (Total: 9,500,000)\n",
            "    Chunk 20: 500,000 rows (Total: 10,000,000)\n",
            "    Chunk 21: 500,000 rows (Total: 10,500,000)\n",
            "    Chunk 22: 500,000 rows (Total: 11,000,000)\n",
            "    Chunk 23: 500,000 rows (Total: 11,500,000)\n",
            "    Chunk 24: 500,000 rows (Total: 12,000,000)\n",
            "    Chunk 25: 500,000 rows (Total: 12,500,000)\n",
            "    Chunk 26: 500,000 rows (Total: 13,000,000)\n",
            "    Chunk 27: 500,000 rows (Total: 13,500,000)\n",
            "    Chunk 28: 500,000 rows (Total: 14,000,000)\n",
            "    Chunk 29: 500,000 rows (Total: 14,500,000)\n",
            "    Chunk 30: 500,000 rows (Total: 15,000,000)\n",
            "    Chunk 31: 500,000 rows (Total: 15,500,000)\n",
            "    Chunk 32: 500,000 rows (Total: 16,000,000)\n",
            "    Chunk 33: 500,000 rows (Total: 16,500,000)\n",
            "    Chunk 34: 500,000 rows (Total: 17,000,000)\n",
            "    Chunk 35: 500,000 rows (Total: 17,500,000)\n",
            "    Chunk 36: 500,000 rows (Total: 18,000,000)\n",
            "    Chunk 37: 500,000 rows (Total: 18,500,000)\n",
            "    Chunk 38: 500,000 rows (Total: 19,000,000)\n",
            "    Chunk 39: 500,000 rows (Total: 19,500,000)\n",
            "    Chunk 40: 500,000 rows (Total: 20,000,000)\n",
            "    Chunk 41: 500,000 rows (Total: 20,500,000)\n",
            "    Chunk 42: 500,000 rows (Total: 21,000,000)\n",
            "    Chunk 43: 500,000 rows (Total: 21,500,000)\n",
            "    Chunk 44: 500,000 rows (Total: 22,000,000)\n",
            "    Chunk 45: 500,000 rows (Total: 22,500,000)\n",
            "    Chunk 46: 500,000 rows (Total: 23,000,000)\n",
            "    Chunk 47: 500,000 rows (Total: 23,500,000)\n",
            "    Chunk 48: 500,000 rows (Total: 24,000,000)\n",
            "    Chunk 49: 500,000 rows (Total: 24,500,000)\n",
            "    Chunk 50: 500,000 rows (Total: 25,000,000)\n",
            "    Chunk 51: 500,000 rows (Total: 25,500,000)\n",
            "    Chunk 52: 500,000 rows (Total: 26,000,000)\n",
            "    Chunk 53: 500,000 rows (Total: 26,500,000)\n",
            "    Chunk 54: 500,000 rows (Total: 27,000,000)\n",
            "    Chunk 55: 500,000 rows (Total: 27,500,000)\n",
            "    Chunk 56: 500,000 rows (Total: 28,000,000)\n",
            "    Chunk 57: 500,000 rows (Total: 28,500,000)\n",
            "    Chunk 58: 500,000 rows (Total: 29,000,000)\n",
            "    Chunk 59: 500,000 rows (Total: 29,500,000)\n",
            "    Chunk 60: 500,000 rows (Total: 30,000,000)\n",
            "    Chunk 61: 500,000 rows (Total: 30,500,000)\n",
            "    Chunk 62: 500,000 rows (Total: 31,000,000)\n",
            "    Chunk 63: 500,000 rows (Total: 31,500,000)\n",
            "    Chunk 64: 500,000 rows (Total: 32,000,000)\n",
            "    Chunk 65: 500,000 rows (Total: 32,500,000)\n",
            "    Chunk 66: 500,000 rows (Total: 33,000,000)\n",
            "    Chunk 67: 500,000 rows (Total: 33,500,000)\n",
            "    Chunk 68: 500,000 rows (Total: 34,000,000)\n",
            "    Chunk 69: 500,000 rows (Total: 34,500,000)\n",
            "    Chunk 70: 500,000 rows (Total: 35,000,000)\n",
            "    Chunk 71: 500,000 rows (Total: 35,500,000)\n",
            "    Chunk 72: 500,000 rows (Total: 36,000,000)\n",
            "    Chunk 73: 500,000 rows (Total: 36,500,000)\n",
            "    Chunk 74: 500,000 rows (Total: 37,000,000)\n",
            "    Chunk 75: 500,000 rows (Total: 37,500,000)\n",
            "    Chunk 76: 500,000 rows (Total: 38,000,000)\n",
            "    Chunk 77: 500,000 rows (Total: 38,500,000)\n",
            "    Chunk 78: 500,000 rows (Total: 39,000,000)\n",
            "    Chunk 79: 500,000 rows (Total: 39,500,000)\n",
            "    Chunk 80: 500,000 rows (Total: 40,000,000)\n",
            "    Chunk 81: 500,000 rows (Total: 40,500,000)\n",
            "    Chunk 82: 500,000 rows (Total: 41,000,000)\n",
            "    Chunk 83: 500,000 rows (Total: 41,500,000)\n",
            "    Chunk 84: 500,000 rows (Total: 42,000,000)\n",
            "    Chunk 85: 500,000 rows (Total: 42,500,000)\n",
            "    Chunk 86: 500,000 rows (Total: 43,000,000)\n",
            "    Chunk 87: 500,000 rows (Total: 43,500,000)\n",
            "    Chunk 88: 500,000 rows (Total: 44,000,000)\n",
            "    Chunk 89: 500,000 rows (Total: 44,500,000)\n",
            "    Chunk 90: 500,000 rows (Total: 45,000,000)\n",
            "    Chunk 91: 500,000 rows (Total: 45,500,000)\n",
            "    Chunk 92: 500,000 rows (Total: 46,000,000)\n",
            "    Chunk 93: 500,000 rows (Total: 46,500,000)\n",
            "    Chunk 94: 500,000 rows (Total: 47,000,000)\n",
            "    Chunk 95: 500,000 rows (Total: 47,500,000)\n",
            "    Chunk 96: 500,000 rows (Total: 48,000,000)\n",
            "    Chunk 97: 500,000 rows (Total: 48,500,000)\n",
            "    Chunk 98: 500,000 rows (Total: 49,000,000)\n",
            "    Chunk 99: 500,000 rows (Total: 49,500,000)\n",
            "    Chunk 100: 500,000 rows (Total: 50,000,000)\n",
            "    Final User Behavior: (50000000, 5)\n",
            "    Final behavior types: {'pv': 44770345, 'cart': 2775654, 'fav': 1449282, 'buy': 1004719}\n",
            "    Unique users: 492,944\n",
            "    Unique items: 3,220,204\n",
            "\n",
            "5. DATASET OVERLAP ANALYSIS\n",
            "----------------------------------------\n",
            "USER OVERLAPS:\n",
            "    Raw sample users: 1,141,729\n",
            "    Profile users: 1,061,768\n",
            "    Behavior users: 492,944\n",
            "    Raw âˆ© Profiles: 1,061,768 (93.0%)\n",
            "    Raw âˆ© Behavior: 492,944 (43.2%)\n",
            "    All 3 datasets: 457,598 (40.1%)\n",
            "\n",
            "ITEM OVERLAPS:\n",
            "    Raw sample items: 846,811\n",
            "    Ad feature items: 846,811\n",
            "    Behavior items: 3,220,204\n",
            "    Raw âˆ© Ad features: 846,811 (100.0%)\n",
            "    Raw âˆ© Behavior: 527,787 (62.3%)\n",
            "\n",
            "6. DATA LOADING SUMMARY\n",
            "----------------------------------------\n",
            "Raw Sample: (26557961, 5) | CTR: 0.0514\n",
            "Ad Features: (846811, 6) | Items: 846,811\n",
            "User Profiles: (1061768, 9) | Users: 1,061,768\n",
            "User Behavior: (50000000, 5) | Users: 492,944\n",
            "Data quality: Good overlaps for feature engineering\n",
            "\n",
            "STEP 2 COMPLETED!\n",
            "All data loaded with complete head inspection\n",
            "Dataset overlaps analyzed\n",
            "Data quality verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # =====================================================================\n",
        "# STEP 3: FEATURE ENGINEERING SEDERHANA\n",
        "# ======================================================================\n",
        "\n",
        "def create_features_simple():\n",
        "    \"\"\"Feature engineering sederhana berdasarkan EDA\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FEATURE ENGINEERING SEDERHANA\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        # Start with raw sample\n",
        "        data = raw_sample.copy()\n",
        "        print(f\"Starting: {data.shape}\")\n",
        "\n",
        "        # 1. TEMPORAL FEATURES\n",
        "        print(f\"\\nCreating temporal features...\")\n",
        "        data['datetime'] = pd.to_datetime(data['time_stamp'], unit='s')\n",
        "        data['hour'] = data['datetime'].dt.hour\n",
        "        data['day_of_week'] = data['datetime'].dt.dayofweek\n",
        "        data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)\n",
        "        data['is_peak_hour'] = data['hour'].isin([20, 17, 18]).astype(int)\n",
        "\n",
        "        # Hour CTR\n",
        "        hour_ctr = data.groupby('hour')['clk'].mean()\n",
        "        data['hour_ctr'] = data['hour'].map(hour_ctr)\n",
        "\n",
        "        print(f\"    Temporal features created\")\n",
        "\n",
        "        # 2. MERGE AD FEATURES (Brand + Category priority dari EDA)\n",
        "        print(f\"\\nMerging ad features...\")\n",
        "        data = data.merge(\n",
        "            ad_features[['adgroup_id', 'cate_id', 'brand', 'price']],\n",
        "            on='adgroup_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # 3. PRICE FEATURES\n",
        "        print(f\"\\nCreating price features...\")\n",
        "        data['price'] = pd.to_numeric(data['price'], errors='coerce')\n",
        "        data['price'] = data['price'].fillna(data['price'].median())\n",
        "        data['price_log'] = np.log1p(data['price'])\n",
        "        data['price_percentile'] = data['price'].rank(pct=True)\n",
        "        data['is_high_price'] = (data['price_percentile'] >= 0.8).astype(int)\n",
        "\n",
        "        # 4. ITEM POPULARITY (EDA high importance)\n",
        "        print(f\"\\nCreating item features...\")\n",
        "        item_stats = data.groupby('adgroup_id').agg({\n",
        "            'clk': ['count', 'sum', 'mean'],\n",
        "            'user': 'nunique'\n",
        "        }).reset_index()\n",
        "        item_stats.columns = ['adgroup_id', 'impressions', 'clicks', 'item_ctr', 'unique_users']\n",
        "        item_stats = item_stats.fillna(0)\n",
        "\n",
        "        # Popularity score\n",
        "        item_stats['popularity_score'] = (\n",
        "            np.log1p(item_stats['clicks']) * 0.4 +\n",
        "            item_stats['item_ctr'] * 0.6\n",
        "        )\n",
        "\n",
        "        # Merge item features\n",
        "        data = data.merge(\n",
        "            item_stats[['adgroup_id', 'item_ctr', 'popularity_score']],\n",
        "            on='adgroup_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # 5. USER PROFILES\n",
        "        print(f\"\\nProcessing user profiles...\")\n",
        "        user_profiles_clean = user_profiles.copy()\n",
        "\n",
        "        # Fill missing\n",
        "        categorical_cols = ['final_gender_code', 'age_level', 'shopping_level']\n",
        "        for col in categorical_cols:\n",
        "            if col in user_profiles_clean.columns:\n",
        "                user_profiles_clean[col] = user_profiles_clean[col].fillna(-1)\n",
        "\n",
        "        if 'pvalue_level' in user_profiles_clean.columns:\n",
        "            user_profiles_clean['pvalue_level'] = user_profiles_clean['pvalue_level'].fillna(\n",
        "                user_profiles_clean['pvalue_level'].median()\n",
        "            )\n",
        "\n",
        "        # Merge profiles\n",
        "        data = data.merge(\n",
        "            user_profiles_clean[['userid', 'final_gender_code', 'age_level', 'shopping_level', 'pvalue_level']],\n",
        "            left_on='user',\n",
        "            right_on='userid',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # 6. USER BEHAVIOR (EDA: 46% overlap)\n",
        "        print(f\"\\nCreating behavior features...\")\n",
        "        overlapping_users = set(data['user'].astype(str)) & set(user_behavior['user_id'].astype(str))\n",
        "        behavior_filtered = user_behavior[user_behavior['user_id'].astype(str).isin(overlapping_users)].copy()\n",
        "\n",
        "        if len(behavior_filtered) > 0:\n",
        "            # Behavior weights\n",
        "            behavior_weights = {'pv': 1.0, 'fav': 2.0, 'cart': 3.0, 'buy': 5.0}\n",
        "            behavior_filtered['behavior_weight'] = behavior_filtered['behavior_type'].map(behavior_weights)\n",
        "\n",
        "            # User aggregation\n",
        "            user_behavior_agg = behavior_filtered.groupby('user_id').agg({\n",
        "                'item_id': 'count',\n",
        "                'category_id': 'nunique',\n",
        "                'behavior_weight': ['sum', 'mean'],\n",
        "                'behavior_type': [\n",
        "                    lambda x: (x == 'buy').sum()\n",
        "                ]\n",
        "            }).reset_index()\n",
        "\n",
        "            user_behavior_agg.columns = [\n",
        "                'user_id', 'total_interactions', 'unique_categories',\n",
        "                'engagement_score', 'avg_behavior_weight', 'buy_count'\n",
        "            ]\n",
        "\n",
        "            # Additional features\n",
        "            user_behavior_agg['conversion_rate'] = user_behavior_agg['buy_count'] / (user_behavior_agg['total_interactions'] + 1)\n",
        "            user_behavior_agg['is_buyer'] = (user_behavior_agg['buy_count'] > 0).astype(int)\n",
        "\n",
        "            # Merge\n",
        "            user_behavior_agg['user_id'] = user_behavior_agg['user_id'].astype(str)\n",
        "            data['user_str'] = data['user'].astype(str)\n",
        "            data = data.merge(user_behavior_agg, left_on='user_str', right_on='user_id', how='left')\n",
        "            data = data.drop(['user_str', 'user_id'], axis=1, errors='ignore')\n",
        "\n",
        "        # Fill missing behavior features\n",
        "        behavior_cols = ['total_interactions', 'engagement_score', 'conversion_rate', 'is_buyer']\n",
        "        for col in behavior_cols:\n",
        "            if col in data.columns:\n",
        "                data[col] = data[col].fillna(0)\n",
        "\n",
        "        # 7. CATEGORICAL ENCODING\n",
        "        print(f\"\\nEncoding categories...\")\n",
        "        categorical_features = ['final_gender_code', 'age_level', 'shopping_level', 'cate_id', 'brand']\n",
        "        label_encoders = {}\n",
        "\n",
        "        for col in categorical_features:\n",
        "            if col in data.columns:\n",
        "                data[col] = data[col].astype(str)\n",
        "                if data[col].nunique() > 1:\n",
        "                    le = LabelEncoder()\n",
        "                    data[col] = le.fit_transform(data[col])\n",
        "                    label_encoders[col] = le\n",
        "\n",
        "        # 8. FINAL SELECTION\n",
        "        print(f\"\\nFinal feature selection...\")\n",
        "        feature_cols = [\n",
        "            'user', 'adgroup_id',  # IDs\n",
        "            'cate_id', 'brand',\n",
        "            'hour', 'is_peak_hour', 'hour_ctr', 'is_weekend', 'day_of_week', 'time_stamp', # Temporal\n",
        "            'price_log', 'is_high_price', 'price_percentile',  # Price\n",
        "            'item_ctr', 'popularity_score',  # Item\n",
        "            'final_gender_code', 'age_level', 'shopping_level', 'pvalue_level',  # Profile\n",
        "            'clk'  # Target\n",
        "        ]\n",
        "\n",
        "        # Add behavior if available\n",
        "        if 'total_interactions' in data.columns:\n",
        "            feature_cols.extend(['total_interactions', 'engagement_score', 'is_buyer', 'conversion_rate', 'unique_categories'])\n",
        "\n",
        "        # Keep only existing\n",
        "        available_cols = [col for col in feature_cols if col in data.columns]\n",
        "        final_data = data[available_cols].copy()\n",
        "\n",
        "        # 9. CLEAN MISSING\n",
        "        print(f\"\\nðŸ§¹ Cleaning missing values...\")\n",
        "        for col in final_data.columns:\n",
        "            if final_data[col].isnull().sum() > 0:\n",
        "                if final_data[col].dtype in ['int64', 'float64']:\n",
        "                    final_data[col] = final_data[col].fillna(0)\n",
        "                else:\n",
        "                    final_data[col] = final_data[col].fillna(-1)\n",
        "\n",
        "        print(f\"    Final shape: {final_data.shape}\")\n",
        "        print(f\"    CTR preserved: {final_data['clk'].mean():.4f}\")\n",
        "\n",
        "        feature_list = [col for col in available_cols if col not in ['user', 'adgroup_id', 'clk']]\n",
        "\n",
        "        return final_data, label_encoders, feature_list\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, None\n",
        "\n",
        "# Execute feature engineering\n",
        "print(\"Creating features...\")\n",
        "feature_data, label_encoders, feature_list = create_features_simple()\n",
        "\n",
        "if feature_data is not None:\n",
        "    print(f\"\\nSTEP 3 COMPLETED!\")\n",
        "    print(f\"Features: {len(feature_list)}\")\n",
        "    print(f\"Shape: {feature_data.shape}\")\n",
        "    print(f\"CTR: {feature_data['clk'].mean():.4f}\")\n",
        "else:\n",
        "    print(f\"âŒ STEP 3 FAILED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXKHYH5ruJEe",
        "outputId": "2ea0180a-45b0-4558-c1d6-56c99b1595ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating features...\n",
            "\n",
            "============================================================\n",
            "FEATURE ENGINEERING SEDERHANA\n",
            "============================================================\n",
            "Starting: (26557961, 5)\n",
            "\n",
            "Creating temporal features...\n",
            "    Temporal features created\n",
            "\n",
            "Merging ad features...\n",
            "\n",
            "Creating price features...\n",
            "\n",
            "Creating item features...\n",
            "\n",
            "Processing user profiles...\n",
            "\n",
            "Creating behavior features...\n",
            "\n",
            "Encoding categories...\n",
            "\n",
            "Final feature selection...\n",
            "\n",
            "ðŸ§¹ Cleaning missing values...\n",
            "    Final shape: (26557961, 25)\n",
            "    CTR preserved: 0.0514\n",
            "\n",
            "STEP 3 COMPLETED!\n",
            "Features: 22\n",
            "Shape: (26557961, 25)\n",
            "CTR: 0.0514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 4: MODEL DATA PREPARATION - TEMPORAL SPLIT\n",
        "# =====================================================================\n",
        "\n",
        "def prepare_model_data():\n",
        "    \"\"\"Prepare data dengan temporal split\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MODEL DATA PREPARATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        print(f\"Starting: {feature_data.shape}\")\n",
        "\n",
        "        # 1. SEPARATE TARGET AND FEATURES\n",
        "        y = feature_data['clk'].values.astype(np.float32)\n",
        "        X = feature_data.drop('clk', axis=1).copy()\n",
        "\n",
        "        print(f\"    Target shape: {y.shape}, CTR: {y.mean():.4f}\")\n",
        "\n",
        "        # 2. CREATE ID MAPPINGS\n",
        "        print(f\"\\nCreating ID mappings...\")\n",
        "\n",
        "        # User mappings\n",
        "        unique_users = sorted(X['user'].unique())\n",
        "        user_to_idx = {uid: idx + 1 for idx, uid in enumerate(unique_users)}\n",
        "        user_to_idx[0] = 0  # Unknown\n",
        "\n",
        "        # Item mappings\n",
        "        unique_items = sorted(X['adgroup_id'].unique())\n",
        "        item_to_idx = {iid: idx + 1 for idx, iid in enumerate(unique_items)}\n",
        "        item_to_idx[0] = 0  # Unknown\n",
        "\n",
        "        # Convert\n",
        "        user_ids = np.array([user_to_idx.get(uid, 0) for uid in X['user']], dtype=np.int32)\n",
        "        item_ids = np.array([item_to_idx.get(iid, 0) for iid in X['adgroup_id']], dtype=np.int32)\n",
        "\n",
        "        n_users = len(unique_users) + 1\n",
        "        n_items = len(unique_items) + 1\n",
        "\n",
        "        print(f\"    Users: {n_users:,}, Items: {n_items:,}\")\n",
        "\n",
        "        # 3. CREATE SEQUENCES (simple version)\n",
        "        print(f\"\\nCreating sequences...\")\n",
        "\n",
        "        # Sort by user and timestamp for sequences\n",
        "        sequence_data = X.copy()\n",
        "        sequence_data['user_id_mapped'] = user_ids\n",
        "        sequence_data['item_id_mapped'] = item_ids\n",
        "        sequence_data['target'] = y\n",
        "\n",
        "        if 'time_stamp' in sequence_data.columns:\n",
        "            sequence_data = sequence_data.sort_values(['user', 'time_stamp'])\n",
        "        else:\n",
        "            sequence_data = sequence_data.sort_values(['user'])\n",
        "\n",
        "        # Build sequences\n",
        "        max_seq_len = 8  # Hardcoded\n",
        "        sequences = np.zeros((len(sequence_data), max_seq_len), dtype=np.int32)\n",
        "        seq_lengths = np.ones(len(sequence_data), dtype=np.int32)\n",
        "\n",
        "        user_sequences = {}\n",
        "        for idx, row in sequence_data.iterrows():\n",
        "            user_id = row['user']\n",
        "            item_id = row['item_id_mapped']\n",
        "\n",
        "            if user_id not in user_sequences:\n",
        "                user_sequences[user_id] = []\n",
        "            user_sequences[user_id].append(item_id)\n",
        "\n",
        "        # Fill sequences\n",
        "        for idx, row in sequence_data.iterrows():\n",
        "            user_id = row['user']\n",
        "            current_item = row['item_id_mapped']\n",
        "            user_history = user_sequences[user_id]\n",
        "\n",
        "            try:\n",
        "                current_pos = user_history.index(current_item)\n",
        "                history = user_history[:current_pos] if current_pos > 0 else [current_item]\n",
        "            except ValueError:\n",
        "                history = [current_item]\n",
        "\n",
        "            seq_len = min(len(history), max_seq_len)\n",
        "            if seq_len > 0:\n",
        "                sequences[idx, :seq_len] = history[-seq_len:]\n",
        "                seq_lengths[idx] = seq_len\n",
        "\n",
        "        print(f\"    Sequences: {sequences.shape}, avg length: {seq_lengths.mean():.2f}\")\n",
        "\n",
        "        # 4. DENSE FEATURES\n",
        "        print(f\"\\nPreparing dense features...\")\n",
        "        dense_feature_cols = [col for col in X.columns\n",
        "                             if col not in ['user', 'adgroup_id', 'time_stamp', 'datetime', 'userid']\n",
        "                             and X[col].dtype in ['int64', 'float64']]\n",
        "\n",
        "        dense_features = X[dense_feature_cols].values.astype(np.float32)\n",
        "        dense_features = np.nan_to_num(dense_features, nan=0.0)\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        dense_features = scaler.fit_transform(dense_features)\n",
        "\n",
        "        print(f\"    Dense features: {dense_features.shape}\")\n",
        "\n",
        "        # 5. TEMPORAL SPLIT (EDA recommended: 80/10/10)\n",
        "        print(f\"\\nCreating temporal split...\")\n",
        "\n",
        "        # Sort by timestamp for temporal split\n",
        "        if 'time_stamp' in feature_data.columns:\n",
        "            sorted_data = feature_data.sort_values('time_stamp').reset_index(drop=True)\n",
        "            sorted_indices = sorted_data.index.values\n",
        "\n",
        "            # Get original order back\n",
        "            original_order = np.argsort(sequence_data.index)\n",
        "            user_ids = user_ids[original_order]\n",
        "            item_ids = item_ids[original_order]\n",
        "            sequences = sequences[original_order]\n",
        "            seq_lengths = seq_lengths[original_order]\n",
        "            dense_features = dense_features[original_order]\n",
        "            y = y[original_order]\n",
        "\n",
        "            # Create temporal split\n",
        "            n_samples = len(y)\n",
        "            train_end = int(0.80 * n_samples)\n",
        "            val_end = int(0.90 * n_samples)\n",
        "\n",
        "            train_idx = np.arange(0, train_end)\n",
        "            val_idx = np.arange(train_end, val_end)\n",
        "            test_idx = np.arange(val_end, n_samples)\n",
        "\n",
        "            print(f\"    Temporal split: {len(train_idx)}/{len(val_idx)}/{len(test_idx)}\")\n",
        "\n",
        "        else:\n",
        "            # Fallback to stratified split\n",
        "            indices = np.arange(len(y))\n",
        "            temp_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=1234, stratify=y)\n",
        "            train_idx, val_idx = train_test_split(temp_idx, test_size=0.125, random_state=1234, stratify=y[temp_idx])\n",
        "\n",
        "            print(f\"    Stratified split: {len(train_idx)}/{len(val_idx)}/{len(test_idx)}\")\n",
        "\n",
        "        def get_split_data(idx):\n",
        "            return {\n",
        "                'user_ids': user_ids[idx],\n",
        "                'item_ids': item_ids[idx],\n",
        "                'sequences': sequences[idx],\n",
        "                'seq_lengths': seq_lengths[idx],\n",
        "                'dense_features': dense_features[idx],\n",
        "                'labels': y[idx].reshape(-1, 1)\n",
        "            }\n",
        "\n",
        "        splits = {\n",
        "            'train': get_split_data(train_idx),\n",
        "            'val': get_split_data(val_idx),\n",
        "            'test': get_split_data(test_idx)\n",
        "        }\n",
        "\n",
        "        # Verify splits\n",
        "        for split_name, split_data in splits.items():\n",
        "            split_ctr = split_data['labels'].mean()\n",
        "            print(f\"    {split_name}: {len(split_data['labels']):,} samples, CTR: {split_ctr:.4f}\")\n",
        "\n",
        "        # 6. CREATE TF DATASETS\n",
        "        print(f\"\\nCreating TensorFlow datasets...\")\n",
        "\n",
        "        def create_tf_dataset(split_data, batch_size=256, shuffle=True):\n",
        "            dataset = tf.data.Dataset.from_tensor_slices({\n",
        "                'user_id': split_data['user_ids'],\n",
        "                'item_id': split_data['item_ids'],\n",
        "                'sequence': split_data['sequences'],\n",
        "                'seq_length': split_data['seq_lengths'],\n",
        "                'dense_features': split_data['dense_features'],\n",
        "                'label': split_data['labels']\n",
        "            })\n",
        "\n",
        "            if shuffle:\n",
        "                dataset = dataset.shuffle(5000, seed=1234)\n",
        "\n",
        "            dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "            dataset = dataset.prefetch(2)\n",
        "            return dataset\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = create_tf_dataset(splits['train'], batch_size=256, shuffle=True)\n",
        "        val_dataset = create_tf_dataset(splits['val'], batch_size=256, shuffle=False)\n",
        "        test_dataset = create_tf_dataset(splits['test'], batch_size=256, shuffle=False)\n",
        "\n",
        "        # Verify pipeline\n",
        "        sample_batch = next(iter(train_dataset))\n",
        "        print(f\"    Batch shapes:\")\n",
        "        for key, value in sample_batch.items():\n",
        "            print(f\"      {key}: {value.shape}\")\n",
        "\n",
        "        return {\n",
        "            'train_dataset': train_dataset,\n",
        "            'val_dataset': val_dataset,\n",
        "            'test_dataset': test_dataset,\n",
        "            'splits': splits,\n",
        "            'model_params': {\n",
        "                'n_users': n_users,\n",
        "                'n_items': n_items,\n",
        "                'dense_feature_dim': dense_features.shape[1],\n",
        "                'max_sequence_length': max_seq_len,\n",
        "                'embedding_dim': 32,  # Hardcoded\n",
        "                'hidden_units': [64, 32],  # Hardcoded\n",
        "            },\n",
        "            'preprocessing': {\n",
        "                'user_to_idx': user_to_idx,\n",
        "                'item_to_idx': item_to_idx,\n",
        "                'scaler': scaler,\n",
        "                'dense_feature_cols': dense_feature_cols,\n",
        "                'label_encoders': label_encoders\n",
        "            }\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Execute model preparation\n",
        "print(\"Preparing model data...\")\n",
        "model_data = prepare_model_data()\n",
        "splits = model_data['splits']\n",
        "if model_data is not None:\n",
        "    print(f\"\\n COMPLETED!\")\n",
        "    print(f\"Temporal split created\")\n",
        "    print(f\"TensorFlow datasets ready\")\n",
        "    print(f\"Users: {model_data['model_params']['n_users']:,}\")\n",
        "    print(f\"Items: {model_data['model_params']['n_items']:,}\")\n",
        "    print(f\"Dense features: {model_data['model_params']['dense_feature_dim']}\")\n",
        "else:\n",
        "    print(f\"âŒ STEP 4 FAILED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdDn1UmEvZG6",
        "outputId": "9ff12f6a-fb4a-470c-d2f7-d906e5e0272a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing model data...\n",
            "\n",
            "============================================================\n",
            "MODEL DATA PREPARATION\n",
            "============================================================\n",
            "Starting: (26557961, 25)\n",
            "    Target shape: (26557961,), CTR: 0.0514\n",
            "\n",
            "Creating ID mappings...\n",
            "    Users: 1,141,730, Items: 846,812\n",
            "\n",
            "Creating sequences...\n",
            "    Sequences: (26557961, 8), avg length: 6.64\n",
            "\n",
            "Preparing dense features...\n",
            "    Dense features: (26557961, 19)\n",
            "\n",
            "Creating temporal split...\n",
            "    Temporal split: 21246368/2655796/2655797\n",
            "    train: 21,246,368 samples, CTR: 0.0515\n",
            "    val: 2,655,796 samples, CTR: 0.0511\n",
            "    test: 2,655,797 samples, CTR: 0.0516\n",
            "\n",
            "Creating TensorFlow datasets...\n",
            "    Batch shapes:\n",
            "      user_id: (256,)\n",
            "      item_id: (256,)\n",
            "      sequence: (256, 8)\n",
            "      seq_length: (256,)\n",
            "      dense_features: (256, 19)\n",
            "      label: (256, 1)\n",
            "\n",
            " COMPLETED!\n",
            "Temporal split created\n",
            "TensorFlow datasets ready\n",
            "Users: 1,141,730\n",
            "Items: 846,812\n",
            "Dense features: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# STEP 5: LAYER DEFINITIONS ONLY\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LAYER DEFINITIONS ONLY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "class DiceActivation(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    DICE activation dari paper DIN dengan parameter optimal dari tuning\n",
        "\n",
        "    Paper: Deep Interest Network for Click-Through Rate Prediction\n",
        "    Formula: Dice(x) = p(x) * x + (1 - p(x)) * Î± * x\n",
        "    dimana p(x) = sigmoid((x - E[x]) / sqrt(Var[x] + Îµ) * Î²)\n",
        "    \"\"\"\n",
        "    def __init__(self, axis=-1, epsilon=8.84e-09, alpha_init=0.4515, beta_init=1.6703, **kwargs):\n",
        "        super(DiceActivation, self).__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "        self.epsilon = epsilon\n",
        "        self.alpha_init = alpha_init  # Store alpha_init parameter\n",
        "        self.beta_init = beta_init    # Store beta_init parameter\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        param_shape = input_shape[1:]\n",
        "\n",
        "        # Alpha: parameter untuk mengontrol negative part\n",
        "        self.alpha = self.add_weight(\n",
        "            name='alpha',\n",
        "            shape=param_shape,\n",
        "            initializer=tf.keras.initializers.Constant(self.alpha_init),  # Use the parameter\n",
        "            trainable=True,\n",
        "            constraint=tf.keras.constraints.NonNeg()\n",
        "        )\n",
        "\n",
        "        # Beta: parameter untuk scaling normalization\n",
        "        self.beta = self.add_weight(\n",
        "            name='beta',\n",
        "            shape=param_shape,\n",
        "            initializer=tf.keras.initializers.Constant(self.beta_init),  # Use the parameter\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        super(DiceActivation, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # Compute batch statistics\n",
        "        if training:\n",
        "            mean = tf.reduce_mean(inputs, axis=0, keepdims=True)\n",
        "            variance = tf.reduce_mean(\n",
        "                tf.square(inputs - mean),\n",
        "                axis=0,\n",
        "                keepdims=True\n",
        "            )\n",
        "        else:\n",
        "            mean = tf.reduce_mean(inputs, axis=0, keepdims=True)\n",
        "            variance = tf.reduce_mean(\n",
        "                tf.square(inputs - mean),\n",
        "                axis=0,\n",
        "                keepdims=True\n",
        "            )\n",
        "\n",
        "        # Normalize dengan epsilon optimal\n",
        "        normalized = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
        "        scaled = normalized * self.beta\n",
        "        prob = tf.nn.sigmoid(scaled)\n",
        "\n",
        "        # DICE output\n",
        "        output = prob * inputs + (1.0 - prob) * self.alpha * inputs\n",
        "        return output\n",
        "\n",
        "class DINAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    DIN Attention mechanism dengan dukungan untuk DICE dan PReLU activations\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_units=16, max_seq_len=8, activation_type='dice',\n",
        "                 dice_alpha_init=0.4515, dice_beta_init=1.6703, dice_epsilon=8.84e-09,\n",
        "                 prelu_alpha_init=0.4515, **kwargs):\n",
        "        super(DINAttention, self).__init__(**kwargs)\n",
        "        self.hidden_units = hidden_units\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.activation_type = activation_type\n",
        "\n",
        "        # Parameter untuk DICE\n",
        "        self.dice_alpha_init = dice_alpha_init\n",
        "        self.dice_beta_init = dice_beta_init\n",
        "        self.dice_epsilon = dice_epsilon\n",
        "\n",
        "        # Parameter untuk PReLU\n",
        "        self.prelu_alpha_init = prelu_alpha_init\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Dense layer tanpa aktivasi\n",
        "        self.attention_dense = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(self.hidden_units, activation=None),\n",
        "            name='attention_dense_td'\n",
        "        )\n",
        "\n",
        "        # Inisialisasi activation layer berdasarkan jenis\n",
        "        if self.activation_type.lower() == 'dice':\n",
        "            self.activation = DiceActivation(\n",
        "                alpha_init=self.dice_alpha_init,\n",
        "                beta_init=self.dice_beta_init,\n",
        "                epsilon=self.dice_epsilon,\n",
        "                name='attention_dice'\n",
        "            )\n",
        "        else:  # Default to PReLU if not DICE\n",
        "            self.activation = tf.keras.layers.PReLU(\n",
        "                alpha_initializer=tf.keras.initializers.Constant(self.prelu_alpha_init),\n",
        "                name='attention_prelu'\n",
        "            )\n",
        "\n",
        "        # Output layer\n",
        "        self.attention_output = tf.keras.layers.TimeDistributed(\n",
        "            tf.keras.layers.Dense(1),\n",
        "            name='attention_output_td'\n",
        "        )\n",
        "        super(DINAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        sequence_emb, target_item_emb = inputs\n",
        "\n",
        "        # Create custom layer for tile operation\n",
        "        class TileLayer(tf.keras.layers.Layer):\n",
        "            def __init__(self, max_seq_len):\n",
        "                super().__init__()\n",
        "                self.max_seq_len = max_seq_len\n",
        "\n",
        "            def call(self, x):\n",
        "                return tf.tile(\n",
        "                    tf.expand_dims(x, axis=1),\n",
        "                    [1, self.max_seq_len, 1]\n",
        "                )\n",
        "\n",
        "        tile_layer = TileLayer(self.max_seq_len)\n",
        "        target_expanded = tile_layer(target_item_emb)\n",
        "\n",
        "        # Element-wise operations\n",
        "        element_wise_product = tf.keras.layers.Multiply()([sequence_emb, target_expanded])\n",
        "        element_wise_diff = tf.keras.layers.Subtract()([sequence_emb, target_expanded])\n",
        "\n",
        "        # Concatenate features\n",
        "        attention_input = tf.keras.layers.Concatenate(axis=-1)([\n",
        "            sequence_emb,\n",
        "            target_expanded,\n",
        "            element_wise_product,\n",
        "            element_wise_diff\n",
        "        ])\n",
        "\n",
        "        # Apply attention network dengan aktivasi yang dipilih\n",
        "        attention_hidden = self.attention_dense(attention_input)\n",
        "        attention_hidden = self.activation(attention_hidden)  # Menggunakan activation layer\n",
        "        attention_scores = self.attention_output(attention_hidden)\n",
        "\n",
        "        return attention_scores, sequence_emb\n",
        "\n",
        "class SequencePooling(tf.keras.layers.Layer):\n",
        "    \"\"\"Pooling layer untuk sequence dengan attention weights\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SequencePooling, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention_scores, sequence_emb, seq_lengths = inputs\n",
        "\n",
        "        max_seq_len = tf.shape(attention_scores)[1]\n",
        "\n",
        "        # Create sequence mask\n",
        "        seq_mask = tf.sequence_mask(seq_lengths, max_seq_len, dtype=tf.float32)\n",
        "        seq_mask = tf.expand_dims(seq_mask, axis=-1)\n",
        "\n",
        "        # Apply mask to attention scores\n",
        "        masked_scores = attention_scores + (1.0 - seq_mask) * (-1e9)\n",
        "\n",
        "        # Softmax normalization\n",
        "        attention_weights = tf.nn.softmax(masked_scores, axis=1)\n",
        "\n",
        "        # Weighted sum\n",
        "        attended_sequence = tf.reduce_sum(sequence_emb * attention_weights, axis=1)\n",
        "\n",
        "        return attended_sequence\n",
        "\n",
        "print(f\"LAYER DEFINITIONS COMPLETED!\")"
      ],
      "metadata": {
        "id": "jV422avAwM0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9652ea1-8a42-4505-f11c-a35a90888654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "LAYER DEFINITIONS ONLY\n",
            "============================================================\n",
            "LAYER DEFINITIONS COMPLETED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6A: CREATE DIN-DICE MODEL (OPTIMIZED)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATE DIN-DICE MODEl\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_din_dice_model():\n",
        "\n",
        "    # Model parameters from tuning\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = [64, 32]\n",
        "    attention_hidden = 16\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = 0.5445\n",
        "    l2_reg = 0.0001305\n",
        "    l2_dense = 4.86e-05\n",
        "    dice_alpha_init = 0.4515\n",
        "    dice_beta_init = 1.6703\n",
        "    dice_epsilon = 8.84e-09\n",
        "\n",
        "    print(f\"    Users: {n_users:,}\")\n",
        "    print(f\"    Items: {n_items:,}\")\n",
        "    print(f\"    Embedding dim: {embedding_dim}\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Attention hidden: {attention_hidden}\")\n",
        "    print(f\"    Max seq len: {max_seq_len}\")\n",
        "    print(f\"    Dense features: {dense_feature_dim}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 regularization (embedding): {l2_reg:.6f}\")\n",
        "    print(f\"    L2 regularization (dense): {l2_dense:.6f}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "    seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    target_item_emb = item_embedding_layer(item_input)\n",
        "    sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "    # DIN Attention mechanism dengan attention_hidden optimal\n",
        "    attention_scores, attended_emb = DINAttention(\n",
        "        hidden_units=attention_hidden,\n",
        "        max_seq_len=max_seq_len,\n",
        "        activation_type='dice',\n",
        "        dice_alpha_init=dice_alpha_init,  # Dari parameter tuning\n",
        "        dice_beta_init=dice_beta_init,    # Dari parameter tuning\n",
        "        dice_epsilon=dice_epsilon,        # Dari parameter tuning\n",
        "        name='din_attention'\n",
        "    )([sequence_emb, target_item_emb])\n",
        "\n",
        "    # Sequence pooling\n",
        "    pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "        [attention_scores, attended_emb, seq_length_input]\n",
        "    )\n",
        "\n",
        "    # Feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        target_item_emb,\n",
        "        pooled_sequence,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK dengan DICE activation\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "\n",
        "        # DICE activation dari tuning\n",
        "        x = DiceActivation(name=f'dice_{i+1}')(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='din_dice_optimized'  # Renamed to reflect optimization\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DIN-DICE model\n",
        "print(f\"Creating DIN-DICE model...\")\n",
        "try:\n",
        "    din_dice_model = create_din_dice_model()\n",
        "\n",
        "    # COMPILE SETTINGS\n",
        "    learning_rate = 5.95e-05\n",
        "    label_smoothing = 0.1462\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-8,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    # LOSS dengan label smoothing\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "\n",
        "    din_dice_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(f\"DIN-DICE model created successfully !\")\n",
        "    print(f\"Model summary:\")\n",
        "    print(f\"    Total parameters: {din_dice_model.count_params():,}\")\n",
        "    print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in din_dice_model.trainable_weights]):,}\")\n",
        "\n",
        "    print(f\"\\nCONFIGURATION APPLIED:\")\n",
        "    print(f\"    Learning rate: {learning_rate:.6f}\")\n",
        "    print(f\"    Dropout rate: {0.5445:.4f}\")\n",
        "    print(f\"    L2 embedding: {0.0001305:.6f}\")\n",
        "    print(f\"    L2 dense: {4.86e-05:.6f}\")\n",
        "    print(f\"    DICE Î±_init: 0.4515\")\n",
        "    print(f\"    DICE Î²_init: 1.6703\")\n",
        "    print(f\"    DICE Îµ: 8.84e-09\")\n",
        "    print(f\"    Label smoothing: {0.1462:.4f}\")\n",
        "\n",
        "    # Test model dengan sample batch\n",
        "    print(f\"\\nðŸ§ª Testing OPTIMIZED DIN-DICE model...\")\n",
        "    test_batch = {\n",
        "        'user_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'item_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'sequence': tf.constant([[1, 2, 0, 0, 0, 0, 0, 0], [1, 2, 3, 0, 0, 0, 0, 0]], dtype=tf.int32),\n",
        "        'seq_length': tf.constant([2, 3], dtype=tf.int32),\n",
        "        'dense_features': tf.random.normal((2, model_data['model_params']['dense_feature_dim']))\n",
        "    }\n",
        "\n",
        "    test_output = din_dice_model(test_batch, training=False)\n",
        "    print(f\"    Model test successful!\")\n",
        "    print(f\"    Input batch size: 2\")\n",
        "    print(f\"    Output shape: {test_output.shape}\")\n",
        "    print(f\"    Output range: [{float(tf.reduce_min(test_output)):.4f}, {float(tf.reduce_max(test_output)):.4f}]\")\n",
        "\n",
        "    # Model architecture summary\n",
        "    print(f\"\\nFULLY DIN-DICE Architecture Summary:\")\n",
        "    din_dice_model.summary(show_trainable=False)\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to create DIN-DICE model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    din_dice_model = None\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "24hBL2DQwU4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ccf4440-63c0-4696-ac57-b371041b1ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATE DIN-DICE MODEl\n",
            "============================================================\n",
            "Creating DIN-DICE model...\n",
            "    Users: 1,141,730\n",
            "    Items: 846,812\n",
            "    Embedding dim: 32\n",
            "    Hidden units: [64, 32]\n",
            "    Attention hidden: 16\n",
            "    Max seq len: 8\n",
            "    Dense features: 19\n",
            "    Dropout rate: 0.5445\n",
            "    L2 regularization (embedding): 0.000131\n",
            "    L2 regularization (dense): 0.000049\n",
            "DIN-DICE model created successfully !\n",
            "Model summary:\n",
            "    Total parameters: 63,645,794\n",
            "    Trainable parameters: 63,645,602\n",
            "\n",
            "CONFIGURATION APPLIED:\n",
            "    Learning rate: 0.000060\n",
            "    Dropout rate: 0.5445\n",
            "    L2 embedding: 0.000131\n",
            "    L2 dense: 0.000049\n",
            "    DICE Î±_init: 0.4515\n",
            "    DICE Î²_init: 1.6703\n",
            "    DICE Îµ: 8.84e-09\n",
            "    Label smoothing: 0.1462\n",
            "\n",
            "ðŸ§ª Testing OPTIMIZED DIN-DICE model...\n",
            "    Model test successful!\n",
            "    Input batch size: 2\n",
            "    Output shape: (2, 1)\n",
            "    Output range: [0.4628, 0.4737]\n",
            "\n",
            "FULLY DIN-DICE Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"din_dice_optimized\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"din_dice_optimized\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚ \u001b[38;5;34m27,097,984\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚ sequence[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ din_attention       â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m),    â”‚      \u001b[38;5;34m2,337\u001b[0m â”‚ item_embedding[\u001b[38;5;34m1\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDINAttention\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)]    â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ seq_length          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m36,535,360\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence_pooling    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ din_attention[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mSequencePooling\u001b[0m)   â”‚                   â”‚            â”‚ din_attention[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ seq_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ sequence_poolingâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m7,424\u001b[0m â”‚ feature_concat[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dice_1              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mDiceActivation\u001b[0m)    â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dice_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dice_2              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚         \u001b[38;5;34m64\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mDiceActivation\u001b[0m)    â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dice_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,097,984</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚ sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ din_attention       â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>),    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,337</span> â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DINAttention</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]    â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ seq_length          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">36,535,360</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence_pooling    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ din_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequencePooling</span>)   â”‚                   â”‚            â”‚ din_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ seq_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ sequence_poolingâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,424</span> â”‚ feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dice_1              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiceActivation</span>)    â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dice_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dice_2              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DiceActivation</span>)    â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dice_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,645,794\u001b[0m (242.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,645,794</span> (242.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,645,602\u001b[0m (242.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,645,602</span> (242.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6B: CREATE DIN-PRELU MODEL (OPTIMIZED)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATE DIN-PRELU MODEL (FULLY OPTIMIZED)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_din_prelu_model():\n",
        "    \"\"\"Create DIN model dengan PReLU activation dan parameter optimal dari tuning\"\"\"\n",
        "\n",
        "    # Model parameters from tuning\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = [64, 32]\n",
        "    attention_hidden = 16\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = 0.5445\n",
        "    l2_reg = 0.0001305\n",
        "    l2_dense = 4.86e-05\n",
        "    prelu_alpha_init = 0.4515\n",
        "\n",
        "    print(f\"    Users: {n_users:,}\")\n",
        "    print(f\"    Items: {n_items:,}\")\n",
        "    print(f\"    Embedding dim: {embedding_dim}\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Attention hidden: {attention_hidden}\")\n",
        "    print(f\"    Max seq len: {max_seq_len}\")\n",
        "    print(f\"    Dense features: {dense_feature_dim}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 regularization (embedding): {l2_reg:.6f}\")\n",
        "    print(f\"    L2 regularization (dense): {l2_dense:.6f}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "    seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    target_item_emb = item_embedding_layer(item_input)\n",
        "    sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "    # DIN Attention mechanism\n",
        "    attention_scores, attended_emb = DINAttention(\n",
        "        hidden_units=attention_hidden,\n",
        "        max_seq_len=max_seq_len,\n",
        "        activation_type='prelu',\n",
        "        prelu_alpha_init=prelu_alpha_init,  # Dari parameter tuning\n",
        "        name='din_attention'\n",
        "    )([sequence_emb, target_item_emb])\n",
        "\n",
        "    # Sequence pooling\n",
        "    pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "        [attention_scores, attended_emb, seq_length_input]\n",
        "    )\n",
        "\n",
        "    # Feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        target_item_emb,\n",
        "        pooled_sequence,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK dengan PReLU activation\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "\n",
        "        # PReLU activation dengan alpha init sama dengan DICE alpha\n",
        "        x = tf.keras.layers.PReLU(\n",
        "            alpha_initializer=tf.keras.initializers.Constant(0.4948),\n",
        "            name=f'prelu_{i+1}'\n",
        "        )(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='din_prelu_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DIN-PReLU model\n",
        "print(f\"Creating DIN-PReLU model with OPTIMAL TUNING PARAMETERS...\")\n",
        "try:\n",
        "    din_prelu_model = create_din_prelu_model()\n",
        "\n",
        "    # COMPILE SETTINGS\n",
        "    learning_rate = 5.95e-05\n",
        "    label_smoothing = 0.1462\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-8,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    # LOSS dengan label smoothing\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "\n",
        "    din_prelu_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(f\"DIN-PReLU model created successfully!\")\n",
        "    print(f\"Model summary:\")\n",
        "    print(f\"    Total parameters: {din_prelu_model.count_params():,}\")\n",
        "    print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in din_prelu_model.trainable_weights]):,}\")\n",
        "\n",
        "    print(f\"\\nFULLY OPTIMIZED CONFIGURATION APPLIED FROM TUNING:\")\n",
        "    print(f\"    Learning rate: {learning_rate:.6f}\")\n",
        "    print(f\"    Dropout rate: {0.5445:.4f} \")\n",
        "    print(f\"    L2 embedding: {0.0001305:.6f} L\")\n",
        "    print(f\"    L2 dense: {4.86e-05:.6f} \")\n",
        "    print(f\"    PReLU Î±_init: 0.4515\")\n",
        "    print(f\"    Label smoothing: {0.1462:.4f}L\")\n",
        "    print(f\"    Batch size: 4096\")\n",
        "\n",
        "    # Test model dengan sample batch\n",
        "    print(f\"\\nTesting OPTIMIZED DIN-PReLU model...\")\n",
        "    test_batch = {\n",
        "        'user_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'item_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'sequence': tf.constant([[1, 2, 0, 0, 0, 0, 0, 0], [1, 2, 3, 0, 0, 0, 0, 0]], dtype=tf.int32),\n",
        "        'seq_length': tf.constant([2, 3], dtype=tf.int32),\n",
        "        'dense_features': tf.random.normal((2, model_data['model_params']['dense_feature_dim']))\n",
        "    }\n",
        "\n",
        "    test_output = din_prelu_model(test_batch, training=False)\n",
        "    print(f\"    Model test successful!\")\n",
        "    print(f\"    Input batch size: 2\")\n",
        "    print(f\"    Output shape: {test_output.shape}\")\n",
        "    print(f\"    Output range: [{float(tf.reduce_min(test_output)):.4f}, {float(tf.reduce_max(test_output)):.4f}]\")\n",
        "\n",
        "    # Model architecture summary\n",
        "    print(f\"\\nðŸ“‹ FULLY DIN-PReLU Architecture Summary:\")\n",
        "    din_prelu_model.summary(show_trainable=False)\n",
        "\n",
        "    # Compare dengan DIN-DICE\n",
        "    if 'din_dice_model' in globals() and din_dice_model is not None:\n",
        "        print(f\"\\nComparison with DIN-DICE:\")\n",
        "        print(f\"    DIN-DICE params: {din_dice_model.count_params():,}\")\n",
        "        print(f\"    DIN-PReLU params: {din_prelu_model.count_params():,}\")\n",
        "        if din_prelu_model.count_params() == din_dice_model.count_params():\n",
        "            print(f\"    Same parameter count - perfect for fair comparison!\")\n",
        "        else:\n",
        "            diff = din_prelu_model.count_params() - din_dice_model.count_params()\n",
        "            print(f\"    Parameter difference: {diff:+,}\")\n",
        "\n",
        "        print(f\"\\nACTIVATION COMPARISON:\")\n",
        "        print(f\"    DIN-DICE: DICE activation with Î±_init=0.4948, Î²_init=1.6584, Îµ=3.95e-09\")\n",
        "        print(f\"    DIN-PReLU: PReLU activation with Î±_init=0.4948\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to create DIN-PReLU model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    din_prelu_model = None\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "dVWcvw1f1phG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "515c4eb1-9374-4037-b55a-deb2874106c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATE DIN-PRELU MODEL (FULLY OPTIMIZED)\n",
            "============================================================\n",
            "Creating DIN-PReLU model with OPTIMAL TUNING PARAMETERS...\n",
            "    Users: 1,141,730\n",
            "    Items: 846,812\n",
            "    Embedding dim: 32\n",
            "    Hidden units: [64, 32]\n",
            "    Attention hidden: 16\n",
            "    Max seq len: 8\n",
            "    Dense features: 19\n",
            "    Dropout rate: 0.5445\n",
            "    L2 regularization (embedding): 0.000131\n",
            "    L2 regularization (dense): 0.000049\n",
            "DIN-PReLU model created successfully!\n",
            "Model summary:\n",
            "    Total parameters: 63,645,570\n",
            "    Trainable parameters: 63,645,378\n",
            "\n",
            "FULLY OPTIMIZED CONFIGURATION APPLIED FROM TUNING:\n",
            "    Learning rate: 0.000060\n",
            "    Dropout rate: 0.5445 \n",
            "    L2 embedding: 0.000131 L\n",
            "    L2 dense: 0.000049 \n",
            "    PReLU Î±_init: 0.4515\n",
            "    Label smoothing: 0.1462L\n",
            "    Batch size: 4096\n",
            "\n",
            "Testing OPTIMIZED DIN-PReLU model...\n",
            "    Model test successful!\n",
            "    Input batch size: 2\n",
            "    Output shape: (2, 1)\n",
            "    Output range: [0.5214, 0.5841]\n",
            "\n",
            "ðŸ“‹ FULLY DIN-PReLU Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"din_prelu_optimized\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"din_prelu_optimized\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚ \u001b[38;5;34m27,097,984\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚ sequence[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ din_attention       â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m),    â”‚      \u001b[38;5;34m2,209\u001b[0m â”‚ item_embedding[\u001b[38;5;34m1\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDINAttention\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)]    â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ seq_length          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m36,535,360\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence_pooling    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ din_attention[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mSequencePooling\u001b[0m)   â”‚                   â”‚            â”‚ din_attention[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ seq_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ sequence_poolingâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m7,424\u001b[0m â”‚ feature_concat[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ prelu_1 (\u001b[38;5;33mPReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚         \u001b[38;5;34m64\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ prelu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ prelu_2 (\u001b[38;5;33mPReLU\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚         \u001b[38;5;34m32\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ prelu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,097,984</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚ sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ din_attention       â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>),    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,209</span> â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DINAttention</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]    â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ seq_length          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">36,535,360</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ sequence_pooling    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ din_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SequencePooling</span>)   â”‚                   â”‚            â”‚ din_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ seq_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ sequence_poolingâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,424</span> â”‚ feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ prelu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ prelu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ prelu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ prelu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,645,570\u001b[0m (242.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,645,570</span> (242.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,645,378\u001b[0m (242.79 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,645,378</span> (242.79 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison with DIN-DICE:\n",
            "    DIN-DICE params: 63,645,794\n",
            "    DIN-PReLU params: 63,645,570\n",
            "    Parameter difference: -224\n",
            "\n",
            "ACTIVATION COMPARISON:\n",
            "    DIN-DICE: DICE activation with Î±_init=0.4948, Î²_init=1.6584, Îµ=3.95e-09\n",
            "    DIN-PReLU: PReLU activation with Î±_init=0.4948\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6C: CREATE DEEPFM MODEL\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATE DEEPFM MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_deepfm_model():\n",
        "    \"\"\"Create DeepFM model dengan optimal parameters - tanpa sequence features\"\"\"\n",
        "\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = [128, 64, 32]\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "\n",
        "    print(f\"ðŸ”§ Creating DeepFM model with OPTIMAL parameters...\")\n",
        "    print(f\"    Users: {n_users:,}\")\n",
        "    print(f\"    Items: {n_items:,}\")\n",
        "    print(f\"    Embedding dim: {embedding_dim}\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Dense features: {dense_feature_dim}\")\n",
        "    print(f\"    Note: No sequence features (DeepFM baseline)\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "    # FM PART: Factorization Machine component\n",
        "    print(f\"    Building FM component...\")\n",
        "\n",
        "    # âœ… OPTIMAL LINEAR PART dengan L2 regularization\n",
        "    user_linear = tf.keras.layers.Dense(1, use_bias=False, name='user_linear',\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(0.005))(user_emb)\n",
        "    item_linear = tf.keras.layers.Dense(1, use_bias=False, name='item_linear',\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(0.005))(item_emb)\n",
        "    dense_linear = tf.keras.layers.Dense(1, use_bias=False, name='dense_linear',\n",
        "                                        kernel_regularizer=tf.keras.regularizers.l2(0.005))(dense_input)\n",
        "\n",
        "    # INTERACTION PART dengan L2 regularization\n",
        "    # User-Item interaction\n",
        "    user_item_interaction = tf.keras.layers.Multiply(name='user_item_mult')([user_emb, item_emb])\n",
        "\n",
        "    # User-Dense interaction\n",
        "    user_dense_proj = tf.keras.layers.Dense(embedding_dim, name='user_dense_proj',\n",
        "                                           kernel_regularizer=tf.keras.regularizers.l2(0.005))(dense_input)\n",
        "    user_dense_interaction = tf.keras.layers.Multiply(name='user_dense_mult')([user_emb, user_dense_proj])\n",
        "\n",
        "    # Item-Dense interaction\n",
        "    item_dense_proj = tf.keras.layers.Dense(embedding_dim, name='item_dense_proj',\n",
        "                                           kernel_regularizer=tf.keras.regularizers.l2(0.005))(dense_input)\n",
        "    item_dense_interaction = tf.keras.layers.Multiply(name='item_dense_mult')([item_emb, item_dense_proj])\n",
        "\n",
        "    # Sum all interactions\n",
        "    fm_interactions = tf.keras.layers.Add(name='fm_interactions')([\n",
        "        user_item_interaction,\n",
        "        user_dense_interaction,\n",
        "        item_dense_interaction\n",
        "    ])\n",
        "    fm_interaction_sum = tf.keras.layers.Dense(1, name='fm_interaction_sum',\n",
        "                                              kernel_regularizer=tf.keras.regularizers.l2(0.005))(fm_interactions)\n",
        "\n",
        "    # FM output\n",
        "    fm_output = tf.keras.layers.Add(name='fm_output')([\n",
        "        user_linear,\n",
        "        item_linear,\n",
        "        dense_linear,\n",
        "        fm_interaction_sum\n",
        "    ])\n",
        "\n",
        "    # DEEP PART: Deep Neural Network component\n",
        "    print(f\"    Building Deep component...\")\n",
        "\n",
        "    # Concatenate all features untuk deep part\n",
        "    deep_features = tf.keras.layers.Concatenate(name='deep_features')([\n",
        "        user_emb,\n",
        "        item_emb,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK\n",
        "    x = deep_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation='relu',\n",
        "            name=f'deep_dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.005)\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(0.5, name=f'deep_dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'deep_bn_{i+1}')(x)\n",
        "\n",
        "    # DEEP OUTPUT\n",
        "    deep_output = tf.keras.layers.Dense(1, name='deep_output',\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(0.0005))(x)\n",
        "\n",
        "    # COMBINE FM + DEEP\n",
        "    print(f\"    Combining FM + Deep components...\")\n",
        "    combined_output = tf.keras.layers.Add(name='fm_deep_combine')([fm_output, deep_output])\n",
        "\n",
        "    # Final activation\n",
        "    final_output = tf.keras.layers.Activation('sigmoid', name='final_output')(combined_output)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, dense_input],\n",
        "        outputs=final_output,\n",
        "        name='deepfm'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Dataset adapter for DeepFM (remove sequence features)\n",
        "def create_deepfm_dataset():\n",
        "    \"\"\"Create dataset untuk DeepFM (tanpa sequence features)\"\"\"\n",
        "\n",
        "    # Get original splits\n",
        "    splits = model_data['splits']\n",
        "\n",
        "    # Create new splits without sequence features\n",
        "    deepfm_splits = {}\n",
        "\n",
        "    for split_name in ['train', 'val', 'test']:\n",
        "        deepfm_splits[split_name] = {\n",
        "            'user_ids': splits[split_name]['user_ids'],\n",
        "            'item_ids': splits[split_name]['item_ids'],\n",
        "            'dense_features': splits[split_name]['dense_features'],\n",
        "            'labels': splits[split_name]['labels']\n",
        "        }\n",
        "\n",
        "    print(f\"ðŸ“Š DeepFM dataset created:\")\n",
        "    for split_name, split_data in deepfm_splits.items():\n",
        "        print(f\"    {split_name}: {len(split_data['labels']):,} samples\")\n",
        "\n",
        "    return deepfm_splits\n",
        "\n",
        "# Create DeepFM model\n",
        "print(f\"ðŸš€ Creating DeepFM model...\")\n",
        "try:\n",
        "    deepfm_model = create_deepfm_model()\n",
        "\n",
        "    # Create DeepFM dataset\n",
        "    deepfm_data = create_deepfm_dataset()\n",
        "\n",
        "    # COMPILE SETTINGS\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.0001,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-8,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    # LOSS dengan label smoothing\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)\n",
        "\n",
        "    deepfm_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(f\"DeepFM model created successfully with OPTIMAL parameters!\")\n",
        "    print(f\"Model summary:\")\n",
        "    print(f\"    Total parameters: {deepfm_model.count_params():,}\")\n",
        "    print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in deepfm_model.trainable_weights]):,}\")\n",
        "\n",
        "    print(f\"\\nOPTIMAL CONFIGURATION APPLIED:\")\n",
        "    print(f\"    Learning rate: 0.0001\")\n",
        "    print(f\"    Dropout: 0.5 \")\n",
        "    print(f\"    L2 embedding: 0.0005 \")\n",
        "    print(f\"    L2 dense: 0.005 \")\n",
        "    print(f\"    L2 output: 0.0005 \")\n",
        "    print(f\"    Gradient clip: 0.5\")\n",
        "    print(f\"    Label smoothing: 0.1\")\n",
        "\n",
        "    # Test model dengan sample batch\n",
        "    print(f\"\\nTesting DeepFM model...\")\n",
        "    test_batch = {\n",
        "        'user_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'item_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'dense_features': tf.random.normal((2, model_data['model_params']['dense_feature_dim']))\n",
        "    }\n",
        "\n",
        "    test_output = deepfm_model(test_batch, training=False)\n",
        "    print(f\"    Model test successful!\")\n",
        "    print(f\"    Input batch size: 2\")\n",
        "    print(f\"    Output shape: {test_output.shape}\")\n",
        "    print(f\"    Output range: [{float(tf.reduce_min(test_output)):.4f}, {float(tf.reduce_max(test_output)):.4f}]\")\n",
        "\n",
        "    # Model architecture summary\n",
        "    print(f\"\\nDeepFM Architecture Summary:\")\n",
        "    deepfm_model.summary(show_trainable=False)\n",
        "\n",
        "    # Compare dengan DIN models\n",
        "    print(f\"\\nComparison with DIN models:\")\n",
        "    if 'din_dice_model' in globals() and din_dice_model is not None:\n",
        "        print(f\"    DIN-DICE params: {din_dice_model.count_params():,}\")\n",
        "    if 'din_prelu_model' in globals() and din_prelu_model is not None:\n",
        "        print(f\"    DIN-PReLU params: {din_prelu_model.count_params():,}\")\n",
        "    print(f\"    DeepFM params: {deepfm_model.count_params():,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to create DeepFM model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    deepfm_model = None\n",
        "    deepfm_data = None\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "SXIccZkA91vx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3549c937-2c2b-4b50-ef3d-32154b6a0b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATE DEEPFM MODEL\n",
            "============================================================\n",
            "ðŸš€ Creating DeepFM model...\n",
            "ðŸ”§ Creating DeepFM model with OPTIMAL parameters...\n",
            "    Users: 1,141,730\n",
            "    Items: 846,812\n",
            "    Embedding dim: 32\n",
            "    Hidden units: [128, 64, 32]\n",
            "    Dense features: 19\n",
            "    Note: No sequence features (DeepFM baseline)\n",
            "    Building FM component...\n",
            "    Building Deep component...\n",
            "    Combining FM + Deep components...\n",
            "ðŸ“Š DeepFM dataset created:\n",
            "    train: 21,246,368 samples\n",
            "    val: 2,655,796 samples\n",
            "    test: 2,655,797 samples\n",
            "DeepFM model created successfully with OPTIMAL parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,656,757\n",
            "    Trainable parameters: 63,656,309\n",
            "\n",
            "OPTIMAL CONFIGURATION APPLIED:\n",
            "    Learning rate: 0.0001\n",
            "    Dropout: 0.5 \n",
            "    L2 embedding: 0.0005 \n",
            "    L2 dense: 0.005 \n",
            "    L2 output: 0.0005 \n",
            "    Gradient clip: 0.5\n",
            "    Label smoothing: 0.1\n",
            "\n",
            "Testing DeepFM model...\n",
            "    Model test successful!\n",
            "    Input batch size: 2\n",
            "    Output shape: (2, 1)\n",
            "    Output range: [0.5827, 0.7174]\n",
            "\n",
            "DeepFM Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"deepfm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"deepfm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m36,535,360\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m27,097,984\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_features       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m10,752\u001b[0m â”‚ deep_features[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ deep_dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ deep_dropout_1[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_2        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ deep_bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_2      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ deep_dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_dense_proj     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m640\u001b[0m â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_dense_proj     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m640\u001b[0m â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ deep_dropout_2[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_item_mult      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_dense_mult     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ user_dense_proj[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_dense_mult     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚                   â”‚            â”‚ item_dense_proj[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_3        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ deep_bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_interactions     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_item_mult[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ user_dense_mult[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ item_dense_mult[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_3      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ deep_dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_linear (\u001b[38;5;33mDense\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m32\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_linear (\u001b[38;5;33mDense\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m32\u001b[0m â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_linear        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m19\u001b[0m â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_interaction_sum  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ fm_interactions[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ deep_dropout_3[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_output (\u001b[38;5;33mAdd\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_linear[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ item_linear[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_linear[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ fm_interaction_sâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_output (\u001b[38;5;33mDense\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ deep_bn_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_deep_combine     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fm_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mAdd\u001b[0m)               â”‚                   â”‚            â”‚ deep_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ final_output        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ fm_deep_combine[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">36,535,360</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,097,984</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_features       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,752</span> â”‚ deep_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ deep_dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ deep_dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_2        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ deep_bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_2      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ deep_dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_dense_proj     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_dense_proj     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ deep_dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_item_mult      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_dense_mult     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ user_dense_proj[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_dense_mult     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚                   â”‚            â”‚ item_dense_proj[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dense_3        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ deep_bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_interactions     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_item_mult[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ user_dense_mult[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ item_dense_mult[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_dropout_3      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ deep_dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_linear (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_linear (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_linear        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span> â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_interaction_sum  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ fm_interactions[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_bn_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ deep_dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_linear[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ item_linear[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_linear[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ fm_interaction_sâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ deep_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ deep_bn_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ fm_deep_combine     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fm_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               â”‚                   â”‚            â”‚ deep_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ final_output        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ fm_deep_combine[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,656,757\u001b[0m (242.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,656,757</span> (242.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,656,309\u001b[0m (242.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,656,309</span> (242.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison with DIN models:\n",
            "    DIN-DICE params: 63,645,794\n",
            "    DIN-PReLU params: 63,645,570\n",
            "    DeepFM params: 63,656,757\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6D: CREATE BASELINE MODEL\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATE BASELINE MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def create_baseline_model():\n",
        "    \"\"\"Create simple baseline model dengan optimal parameters - basic feedforward network\"\"\"\n",
        "\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = [128, 64, 32]\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "\n",
        "    print(f\"ðŸ”§ Creating Baseline model with OPTIMAL parameters...\")\n",
        "    print(f\"    Users: {n_users:,}\")\n",
        "    print(f\"    Items: {n_items:,}\")\n",
        "    print(f\"    Embedding dim: {embedding_dim}\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Dense features: {dense_feature_dim}\")\n",
        "    print(f\"    Note: Simple feedforward network (no FM, no attention)\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "    # Simple feature concatenation\n",
        "    print(f\"    Building simple concatenation...\")\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        item_emb,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # FEEDFORWARD NETWORK\n",
        "    print(f\"    ðŸ”§ Building feedforward network...\")\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation='relu',\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(0.005)\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(0.5, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(0.0005))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='baseline'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Dataset adapter for Baseline\n",
        "def create_baseline_dataset():\n",
        "    \"\"\"Create dataset untuk Baseline (tanpa sequence features)\"\"\"\n",
        "\n",
        "    # Get original splits\n",
        "    splits = model_data['splits']\n",
        "\n",
        "    # Create new splits without sequence features\n",
        "    baseline_splits = {}\n",
        "\n",
        "    for split_name in ['train', 'val', 'test']:\n",
        "        baseline_splits[split_name] = {\n",
        "            'user_ids': splits[split_name]['user_ids'],\n",
        "            'item_ids': splits[split_name]['item_ids'],\n",
        "            'dense_features': splits[split_name]['dense_features'],\n",
        "            'labels': splits[split_name]['labels']\n",
        "        }\n",
        "\n",
        "    print(f\"Baseline dataset created:\")\n",
        "    for split_name, split_data in baseline_splits.items():\n",
        "        print(f\"    {split_name}: {len(split_data['labels']):,} samples\")\n",
        "\n",
        "    return baseline_splits\n",
        "\n",
        "# TRAINING CONFIGURATION\n",
        "def get_simple_training_config():\n",
        "    \"\"\"Get optimal training configuration untuk baseline models\"\"\"\n",
        "    return {\n",
        "        'epochs': 20,\n",
        "        'batch_size': 2048,\n",
        "        'validation_freq': 1,\n",
        "        'callbacks': [\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_auc',\n",
        "                patience=4,\n",
        "                mode='max',\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_auc',\n",
        "                factor=0.5,\n",
        "                patience=3,\n",
        "                mode='max',\n",
        "                min_lr=1e-6,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "    }\n",
        "\n",
        "# Create Baseline model\n",
        "print(f\"Creating Baseline model...\")\n",
        "try:\n",
        "    baseline_model = create_baseline_model()\n",
        "\n",
        "    # Create Baseline dataset\n",
        "    baseline_data = create_baseline_dataset()\n",
        "\n",
        "    # Get training configuration\n",
        "    baseline_config = get_simple_training_config()\n",
        "\n",
        "    # âœ… OPTIMAL COMPILE SETTINGS\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=0.0001,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.999,\n",
        "        epsilon=1e-8,\n",
        "        clipnorm=0.5\n",
        "    )\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "\n",
        "    # LOSS dengan label smoothing\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)\n",
        "\n",
        "    baseline_model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=loss,\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    print(f\"Baseline model created successfully!\")\n",
        "    print(f\"Model summary:\")\n",
        "    print(f\"    Total parameters: {baseline_model.count_params():,}\")\n",
        "    print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in baseline_model.trainable_weights]):,}\")\n",
        "\n",
        "\n",
        "    # Test model dengan sample batch\n",
        "    print(f\"\\nTesting Baseline model...\")\n",
        "    test_batch = {\n",
        "        'user_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'item_id': tf.constant([1, 2], dtype=tf.int32),\n",
        "        'dense_features': tf.random.normal((2, model_data['model_params']['dense_feature_dim']))\n",
        "    }\n",
        "\n",
        "    test_output = baseline_model(test_batch, training=False)\n",
        "    print(f\"    Model test successful!\")\n",
        "    print(f\"    Input batch size: 2\")\n",
        "    print(f\"    Output shape: {test_output.shape}\")\n",
        "    print(f\"    Output range: [{float(tf.reduce_min(test_output)):.4f}, {float(tf.reduce_max(test_output)):.4f}]\")\n",
        "\n",
        "    # Model architecture summary\n",
        "    print(f\"\\nBaseline Architecture Summary:\")\n",
        "    baseline_model.summary(show_trainable=False)\n",
        "\n",
        "    # Training configuration summary\n",
        "    print(f\"\\nOPTIMAL Training Configuration:\")\n",
        "    print(f\"    Epochs: {baseline_config['epochs']}\")\n",
        "    print(f\"    Batch size: {baseline_config['batch_size']} (optimized)\")\n",
        "    print(f\"    Early stopping: val_auc (patience=4)\")\n",
        "    print(f\"    LR reduction: val_auc (patience=3, factor=0.5)\")\n",
        "\n",
        "    # Final comparison dengan all models\n",
        "    print(f\"\\nALL MODELS PARAMETER COMPARISON:\")\n",
        "    if 'din_dice_model' in globals() and din_dice_model is not None:\n",
        "        print(f\"    DIN-DICE:  {din_dice_model.count_params():,} params\")\n",
        "    if 'din_prelu_model' in globals() and din_prelu_model is not None:\n",
        "        print(f\"    DIN-PReLU: {din_prelu_model.count_params():,} params\")\n",
        "    if 'deepfm_model' in globals() and deepfm_model is not None:\n",
        "        print(f\"    DeepFM:    {deepfm_model.count_params():,} params\")\n",
        "    print(f\"    Baseline:  {baseline_model.count_params():,} params\")\n",
        "\n",
        "    print(f\"\\nBASELINE MODEL READY FOR TRAINING!\")\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Failed to create Baseline model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    baseline_model = None\n",
        "    baseline_data = None\n",
        "    baseline_config = None\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "ry9m6i1A93i6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea3a01f6-67ca-47c5-ec69-a02255973f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATE BASELINE MODEL\n",
            "============================================================\n",
            "Creating Baseline model...\n",
            "ðŸ”§ Creating Baseline model with OPTIMAL parameters...\n",
            "    Users: 1,141,730\n",
            "    Items: 846,812\n",
            "    Embedding dim: 32\n",
            "    Hidden units: [128, 64, 32]\n",
            "    Dense features: 19\n",
            "    Note: Simple feedforward network (no FM, no attention)\n",
            "    Building simple concatenation...\n",
            "    ðŸ”§ Building feedforward network...\n",
            "Baseline dataset created:\n",
            "    train: 21,246,368 samples\n",
            "    val: 2,655,796 samples\n",
            "    test: 2,655,797 samples\n",
            "Baseline model created successfully!\n",
            "Model summary:\n",
            "    Total parameters: 63,655,361\n",
            "    Trainable parameters: 63,654,913\n",
            "\n",
            "Testing Baseline model...\n",
            "    Model test successful!\n",
            "    Input batch size: 2\n",
            "    Output shape: (2, 1)\n",
            "    Output range: [0.4112, 0.4461]\n",
            "\n",
            "Baseline Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"baseline\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"baseline\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m36,535,360\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚ \u001b[38;5;34m27,097,984\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m83\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ user_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ item_embedding[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m10,752\u001b[0m â”‚ feature_concat[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ bn_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ bn_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_3                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (\u001b[38;5;33mDense\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ bn_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ user_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">36,535,360</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ item_embedding      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">27,097,984</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_features      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ feature_concat      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ dense_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,752</span> â”‚ feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_1                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ bn_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ bn_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bn_3                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ bn_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,655,361\u001b[0m (242.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,655,361</span> (242.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,654,913\u001b[0m (242.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,654,913</span> (242.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OPTIMAL Training Configuration:\n",
            "    Epochs: 20\n",
            "    Batch size: 2048 (optimized)\n",
            "    Early stopping: val_auc (patience=4)\n",
            "    LR reduction: val_auc (patience=3, factor=0.5)\n",
            "\n",
            "ALL MODELS PARAMETER COMPARISON:\n",
            "    DIN-DICE:  63,645,794 params\n",
            "    DIN-PReLU: 63,645,570 params\n",
            "    DeepFM:    63,656,757 params\n",
            "    Baseline:  63,655,361 params\n",
            "\n",
            "BASELINE MODEL READY FOR TRAINING!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6E: TRAINING FUNCTIONS DEFINITIONS (TEST ONLY AT END)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING FUNCTIONS DEFINITIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def manual_training_loop_din_dice(model=None, batch_size=2048, epochs=15, early_stopping_patience=4, save_csv=False):\n",
        "    \"\"\"Custom training loop for DIN-DICE model with test set evaluation only at the end\"\"\"\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"STARTING DIN-DICE TRAINING:\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
        "\n",
        "    # If no model is provided, use the global model\n",
        "    if model is None:\n",
        "        model = din_dice_model\n",
        "\n",
        "    # Get data from global splits\n",
        "    train_x = {\n",
        "        'user_id': splits['train']['user_ids'],\n",
        "        'item_id': splits['train']['item_ids'],\n",
        "        'sequence': splits['train']['sequences'],\n",
        "        'seq_length': splits['train']['seq_lengths'],\n",
        "        'dense_features': splits['train']['dense_features']\n",
        "    }\n",
        "    val_x = {\n",
        "        'user_id': splits['val']['user_ids'],\n",
        "        'item_id': splits['val']['item_ids'],\n",
        "        'sequence': splits['val']['sequences'],\n",
        "        'seq_length': splits['val']['seq_lengths'],\n",
        "        'dense_features': splits['val']['dense_features']\n",
        "    }\n",
        "    test_x = {\n",
        "        'user_id': splits['test']['user_ids'],\n",
        "        'item_id': splits['test']['item_ids'],\n",
        "        'sequence': splits['test']['sequences'],\n",
        "        'seq_length': splits['test']['seq_lengths'],\n",
        "        'dense_features': splits['test']['dense_features']\n",
        "    }\n",
        "\n",
        "    train_y = splits['train']['labels'].flatten()\n",
        "    val_y = splits['val']['labels'].flatten()\n",
        "    test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "    # Setup optimizer, loss and metrics\n",
        "    optimizer = tf.keras.optimizers.Adam(clipnorm=0.5)\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "    train_loss_metric = tf.keras.metrics.Mean()\n",
        "    train_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "    val_loss_metric = tf.keras.metrics.Mean()\n",
        "    val_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "    # History tracking\n",
        "    history = {\n",
        "        'loss': [],\n",
        "        'auc': [],\n",
        "        'val_loss': [],\n",
        "        'val_auc': []\n",
        "    }\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_auc = 0.0\n",
        "    patience_counter = 0\n",
        "    best_epoch = 0\n",
        "    best_weights = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Reset metrics\n",
        "        train_loss_metric.reset_state()\n",
        "        train_auc_metric.reset_state()\n",
        "        val_loss_metric.reset_state()\n",
        "        val_auc_metric.reset_state()\n",
        "\n",
        "        # Training phase\n",
        "        n_train_batches = (len(train_y) + batch_size - 1) // batch_size\n",
        "        indices = np.random.permutation(len(train_y))\n",
        "\n",
        "        for batch_idx in range(n_train_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(train_y))\n",
        "            batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "            # Create batch\n",
        "            batch_x = {k: tf.convert_to_tensor(v[batch_indices]) for k, v in train_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(train_y[batch_indices])\n",
        "\n",
        "            # Training step\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = model(batch_x, training=True)\n",
        "                predictions = tf.squeeze(predictions)\n",
        "                loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "            # Apply gradients\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            # Update metrics\n",
        "            train_loss_metric.update_state(loss)\n",
        "            train_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # Print progress\n",
        "            if (batch_idx + 1) % 100 == 0:\n",
        "                print(f\"  Batch {batch_idx + 1}/{n_train_batches}\")\n",
        "\n",
        "        # Validation phase\n",
        "        n_val_batches = (len(val_y) + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in range(n_val_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(val_y))\n",
        "\n",
        "            # Create batch\n",
        "            batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in val_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(val_y[start_idx:end_idx])\n",
        "\n",
        "            # Validation step\n",
        "            predictions = model(batch_x, training=False)\n",
        "            predictions = tf.squeeze(predictions)\n",
        "            loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "            # Update metrics\n",
        "            val_loss_metric.update_state(loss)\n",
        "            val_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "        # Get epoch results\n",
        "        epoch_train_loss = train_loss_metric.result().numpy()\n",
        "        epoch_train_auc = train_auc_metric.result().numpy()\n",
        "        epoch_val_loss = val_loss_metric.result().numpy()\n",
        "        epoch_val_auc = val_auc_metric.result().numpy()\n",
        "\n",
        "        # Store history\n",
        "        history['loss'].append(epoch_train_loss)\n",
        "        history['auc'].append(epoch_train_auc)\n",
        "        history['val_loss'].append(epoch_val_loss)\n",
        "        history['val_auc'].append(epoch_val_auc)\n",
        "\n",
        "        # Print results (only train and validation)\n",
        "        print(f\"  Train Loss: {epoch_train_loss:.4f}, AUC: {epoch_train_auc:.4f}\")\n",
        "        print(f\"  Val   Loss: {epoch_val_loss:.4f}, AUC: {epoch_val_auc:.4f}\")\n",
        "\n",
        "        # Check early stopping\n",
        "        if epoch_val_auc > best_val_auc:\n",
        "            best_val_auc = epoch_val_auc\n",
        "            best_epoch = epoch\n",
        "            patience_counter = 0\n",
        "            best_weights = model.get_weights()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "            break\n",
        "\n",
        "    # Restore best weights\n",
        "    if best_weights is not None:\n",
        "        model.set_weights(best_weights)\n",
        "\n",
        "    # NOW EVALUATE ON TEST SET (only once, after training is complete)\n",
        "    print(f\"\\nTraining completed. Evaluating final model on test set...\")\n",
        "\n",
        "    test_auc_metric = tf.keras.metrics.AUC()\n",
        "    all_test_preds = []\n",
        "    all_test_labels = []\n",
        "\n",
        "    n_test_batches = (len(test_y) + batch_size - 1) // batch_size\n",
        "    for batch_idx in range(n_test_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min(start_idx + batch_size, len(test_y))\n",
        "\n",
        "        # Create batch\n",
        "        batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in test_x.items()}\n",
        "        batch_y = tf.convert_to_tensor(test_y[start_idx:end_idx])\n",
        "\n",
        "        # Test step\n",
        "        predictions = model(batch_x, training=False)\n",
        "        predictions = tf.squeeze(predictions)\n",
        "\n",
        "        # Update metrics\n",
        "        test_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "        # Store predictions for log loss calculation\n",
        "        all_test_preds.append(predictions.numpy())\n",
        "        all_test_labels.append(batch_y.numpy())\n",
        "\n",
        "    # Calculate test metrics\n",
        "    best_test_auc = test_auc_metric.result().numpy()\n",
        "    all_test_preds = np.concatenate(all_test_preds)\n",
        "    all_test_labels = np.concatenate(all_test_labels)\n",
        "    best_test_logloss = log_loss(all_test_labels, all_test_preds)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nFINAL RESULTS:\")\n",
        "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
        "    print(f\"  Best validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"  Test AUC: {best_test_auc:.4f}\")\n",
        "    print(f\"  Test log loss: {best_test_logloss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "    # Create history plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['auc'], label='Train AUC')\n",
        "    plt.plot(history['val_auc'], label='Val AUC')\n",
        "    plt.axhline(y=best_test_auc, color='r', linestyle='--', label='Test AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('AUC Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.axhline(y=best_test_logloss, color='r', linestyle='--', label='Test LogLoss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('din_dice_training_history.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to CSV\n",
        "    if save_csv:\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame({\n",
        "            'epoch': range(1, len(history['loss']) + 1),\n",
        "            'train_loss': history['loss'],\n",
        "            'train_auc': history['auc'],\n",
        "            'val_loss': history['val_loss'],\n",
        "            'val_auc': history['val_auc'],\n",
        "        })\n",
        "\n",
        "        # Add test results only for best epoch\n",
        "        results_df['test_auc'] = np.nan\n",
        "        results_df['test_logloss'] = np.nan\n",
        "        results_df.loc[best_epoch, 'test_auc'] = best_test_auc\n",
        "        results_df.loc[best_epoch, 'test_logloss'] = best_test_logloss\n",
        "\n",
        "        results_df.to_csv('din_dice_training_results.csv', index=False)\n",
        "        print(f\"Training results saved to din_dice_training_results.csv\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'success': True,\n",
        "        'best_epoch': best_epoch + 1,\n",
        "        'best_val_auc': best_val_auc,\n",
        "        'best_test_auc': best_test_auc,\n",
        "        'best_test_logloss': best_test_logloss,\n",
        "        'history': {\n",
        "            'loss': history['loss'],\n",
        "            'auc': history['auc'],\n",
        "            'val_loss': history['val_loss'],\n",
        "            'val_auc': history['val_auc'],\n",
        "            'test_auc': best_test_auc,  # Just the final value\n",
        "            'test_logloss': best_test_logloss  # Just the final value\n",
        "        },\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "def manual_training_loop_din_prelu(model=None, batch_size=2048, epochs=15, early_stopping_patience=4, save_csv=False):\n",
        "    \"\"\"Custom training loop for DIN-PReLU model with test set evaluation only at the end\"\"\"\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"STARTING DIN-PReLU TRAINING:\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
        "    print(f\"  Test set evaluation: Only at end of training\")\n",
        "\n",
        "    # If no model is provided, use the global model\n",
        "    if model is None:\n",
        "        model = din_prelu_model\n",
        "\n",
        "    # Get data from global splits\n",
        "    train_x = {\n",
        "        'user_id': splits['train']['user_ids'],\n",
        "        'item_id': splits['train']['item_ids'],\n",
        "        'sequence': splits['train']['sequences'],\n",
        "        'seq_length': splits['train']['seq_lengths'],\n",
        "        'dense_features': splits['train']['dense_features']\n",
        "    }\n",
        "    val_x = {\n",
        "        'user_id': splits['val']['user_ids'],\n",
        "        'item_id': splits['val']['item_ids'],\n",
        "        'sequence': splits['val']['sequences'],\n",
        "        'seq_length': splits['val']['seq_lengths'],\n",
        "        'dense_features': splits['val']['dense_features']\n",
        "    }\n",
        "    test_x = {\n",
        "        'user_id': splits['test']['user_ids'],\n",
        "        'item_id': splits['test']['item_ids'],\n",
        "        'sequence': splits['test']['sequences'],\n",
        "        'seq_length': splits['test']['seq_lengths'],\n",
        "        'dense_features': splits['test']['dense_features']\n",
        "    }\n",
        "\n",
        "    train_y = splits['train']['labels'].flatten()\n",
        "    val_y = splits['val']['labels'].flatten()\n",
        "    test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "    # Setup optimizer, loss and metrics\n",
        "    optimizer = tf.keras.optimizers.Adam(clipnorm=0.5)\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "    train_loss_metric = tf.keras.metrics.Mean()\n",
        "    train_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "    val_loss_metric = tf.keras.metrics.Mean()\n",
        "    val_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "    # History tracking\n",
        "    history = {\n",
        "        'loss': [],\n",
        "        'auc': [],\n",
        "        'val_loss': [],\n",
        "        'val_auc': []\n",
        "    }\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_val_auc = 0.0\n",
        "    patience_counter = 0\n",
        "    best_epoch = 0\n",
        "    best_weights = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Reset metrics\n",
        "        train_loss_metric.reset_state()\n",
        "        train_auc_metric.reset_state()\n",
        "        val_loss_metric.reset_state()\n",
        "        val_auc_metric.reset_state()\n",
        "\n",
        "        # Training phase\n",
        "        n_train_batches = (len(train_y) + batch_size - 1) // batch_size\n",
        "        indices = np.random.permutation(len(train_y))\n",
        "\n",
        "        for batch_idx in range(n_train_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(train_y))\n",
        "            batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "            # Create batch\n",
        "            batch_x = {k: tf.convert_to_tensor(v[batch_indices]) for k, v in train_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(train_y[batch_indices])\n",
        "\n",
        "            # Training step\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions = model(batch_x, training=True)\n",
        "                predictions = tf.squeeze(predictions)\n",
        "                loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "            # Apply gradients\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            # Update metrics\n",
        "            train_loss_metric.update_state(loss)\n",
        "            train_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # Print progress\n",
        "            if (batch_idx + 1) % 100 == 0:\n",
        "                print(f\"  Batch {batch_idx + 1}/{n_train_batches}\")\n",
        "\n",
        "        # Validation phase\n",
        "        n_val_batches = (len(val_y) + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in range(n_val_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(val_y))\n",
        "\n",
        "            # Create batch\n",
        "            batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in val_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(val_y[start_idx:end_idx])\n",
        "\n",
        "            # Validation step\n",
        "            predictions = model(batch_x, training=False)\n",
        "            predictions = tf.squeeze(predictions)\n",
        "            loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "            # Update metrics\n",
        "            val_loss_metric.update_state(loss)\n",
        "            val_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "        # Get epoch results\n",
        "        epoch_train_loss = train_loss_metric.result().numpy()\n",
        "        epoch_train_auc = train_auc_metric.result().numpy()\n",
        "        epoch_val_loss = val_loss_metric.result().numpy()\n",
        "        epoch_val_auc = val_auc_metric.result().numpy()\n",
        "\n",
        "        # Store history\n",
        "        history['loss'].append(epoch_train_loss)\n",
        "        history['auc'].append(epoch_train_auc)\n",
        "        history['val_loss'].append(epoch_val_loss)\n",
        "        history['val_auc'].append(epoch_val_auc)\n",
        "\n",
        "        # Print results (only train and validation)\n",
        "        print(f\"  Train Loss: {epoch_train_loss:.4f}, AUC: {epoch_train_auc:.4f}\")\n",
        "        print(f\"  Val   Loss: {epoch_val_loss:.4f}, AUC: {epoch_val_auc:.4f}\")\n",
        "\n",
        "        # Check early stopping\n",
        "        if epoch_val_auc > best_val_auc:\n",
        "            best_val_auc = epoch_val_auc\n",
        "            best_epoch = epoch\n",
        "            patience_counter = 0\n",
        "            best_weights = model.get_weights()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "            break\n",
        "\n",
        "    # Restore best weights\n",
        "    if best_weights is not None:\n",
        "        model.set_weights(best_weights)\n",
        "\n",
        "    # NOW EVALUATE ON TEST SET (only once, after training is complete)\n",
        "    print(f\"\\nTraining completed. Evaluating final model on test set...\")\n",
        "\n",
        "    test_auc_metric = tf.keras.metrics.AUC()\n",
        "    all_test_preds = []\n",
        "    all_test_labels = []\n",
        "\n",
        "    n_test_batches = (len(test_y) + batch_size - 1) // batch_size\n",
        "    for batch_idx in range(n_test_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min(start_idx + batch_size, len(test_y))\n",
        "\n",
        "        # Create batch\n",
        "        batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in test_x.items()}\n",
        "        batch_y = tf.convert_to_tensor(test_y[start_idx:end_idx])\n",
        "\n",
        "        # Test step\n",
        "        predictions = model(batch_x, training=False)\n",
        "        predictions = tf.squeeze(predictions)\n",
        "\n",
        "        # Update metrics\n",
        "        test_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "        # Store predictions for log loss calculation\n",
        "        all_test_preds.append(predictions.numpy())\n",
        "        all_test_labels.append(batch_y.numpy())\n",
        "\n",
        "    # Calculate test metrics\n",
        "    best_test_auc = test_auc_metric.result().numpy()\n",
        "    all_test_preds = np.concatenate(all_test_preds)\n",
        "    all_test_labels = np.concatenate(all_test_labels)\n",
        "    best_test_logloss = log_loss(all_test_labels, all_test_preds)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nFINAL RESULTS:\")\n",
        "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
        "    print(f\"  Best validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"  Test AUC: {best_test_auc:.4f}\")\n",
        "    print(f\"  Test log loss: {best_test_logloss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "    # Create history plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['auc'], label='Train AUC')\n",
        "    plt.plot(history['val_auc'], label='Val AUC')\n",
        "    plt.axhline(y=best_test_auc, color='r', linestyle='--', label='Test AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('AUC Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.axhline(y=best_test_logloss, color='r', linestyle='--', label='Test LogLoss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('din_prelu_training_history.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to CSV\n",
        "    if save_csv:\n",
        "        # Create results DataFrame\n",
        "        results_df = pd.DataFrame({\n",
        "            'epoch': range(1, len(history['loss']) + 1),\n",
        "            'train_loss': history['loss'],\n",
        "            'train_auc': history['auc'],\n",
        "            'val_loss': history['val_loss'],\n",
        "            'val_auc': history['val_auc'],\n",
        "        })\n",
        "\n",
        "        # Add test results only for best epoch\n",
        "        results_df['test_auc'] = np.nan\n",
        "        results_df['test_logloss'] = np.nan\n",
        "        results_df.loc[best_epoch, 'test_auc'] = best_test_auc\n",
        "        results_df.loc[best_epoch, 'test_logloss'] = best_test_logloss\n",
        "\n",
        "        results_df.to_csv('din_prelu_training_results.csv', index=False)\n",
        "        print(f\"Training results saved to din_prelu_training_results.csv\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'success': True,\n",
        "        'best_epoch': best_epoch + 1,\n",
        "        'best_val_auc': best_val_auc,\n",
        "        'best_test_auc': best_test_auc,\n",
        "        'best_test_logloss': best_test_logloss,\n",
        "        'history': {\n",
        "            'loss': history['loss'],\n",
        "            'auc': history['auc'],\n",
        "            'val_loss': history['val_loss'],\n",
        "            'val_auc': history['val_auc'],\n",
        "            'test_auc': best_test_auc,  # Just the final value\n",
        "            'test_logloss': best_test_logloss  # Just the final value\n",
        "        },\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "def create_deepfm_dataset():\n",
        "    \"\"\"Create dataset for DeepFM model\"\"\"\n",
        "    print(f\"Creating DeepFM dataset...\")\n",
        "\n",
        "    # Use global splits\n",
        "    deepfm_train_x = {\n",
        "        'user_id': splits['train']['user_ids'],\n",
        "        'item_id': splits['train']['item_ids'],\n",
        "        'dense_features': splits['train']['dense_features']\n",
        "    }\n",
        "    deepfm_val_x = {\n",
        "        'user_id': splits['val']['user_ids'],\n",
        "        'item_id': splits['val']['item_ids'],\n",
        "        'dense_features': splits['val']['dense_features']\n",
        "    }\n",
        "    deepfm_test_x = {\n",
        "        'user_id': splits['test']['user_ids'],\n",
        "        'item_id': splits['test']['item_ids'],\n",
        "        'dense_features': splits['test']['dense_features']\n",
        "    }\n",
        "\n",
        "    deepfm_train_y = splits['train']['labels'].flatten()\n",
        "    deepfm_val_y = splits['val']['labels'].flatten()\n",
        "    deepfm_test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "    # Return dataset\n",
        "    return {\n",
        "        'train_x': deepfm_train_x,\n",
        "        'train_y': deepfm_train_y,\n",
        "        'val_x': deepfm_val_x,\n",
        "        'val_y': deepfm_val_y,\n",
        "        'test_x': deepfm_test_x,\n",
        "        'test_y': deepfm_test_y\n",
        "    }\n",
        "\n",
        "def train_deepfm_model(model=None, batch_size=2048, epochs=15, early_stopping_patience=4, save_csv=False):\n",
        "    \"\"\"Train DeepFM model with test set evaluation only at the end\"\"\"\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"STARTING DEEPFM TRAINING:\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
        "    print(f\"  Test set evaluation: Only at end of training\")\n",
        "\n",
        "    # If no model is provided, use the global model\n",
        "    if model is None:\n",
        "        model = deepfm_model\n",
        "\n",
        "    # Get dataset\n",
        "    dataset = create_deepfm_dataset()\n",
        "\n",
        "    # Create custom callback to avoid test set evaluation during training\n",
        "    class NoTestCallback(tf.keras.callbacks.Callback):\n",
        "        def __init__(self):\n",
        "            super(NoTestCallback, self).__init__()\n",
        "            self.best_val_auc = 0\n",
        "            self.best_weights = None\n",
        "            self.patience_counter = 0\n",
        "            self.best_epoch = 0\n",
        "            self.patience = early_stopping_patience\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            current_val_auc = logs.get('val_auc')\n",
        "            if current_val_auc > self.best_val_auc:\n",
        "                self.best_val_auc = current_val_auc\n",
        "                self.best_epoch = epoch\n",
        "                self.patience_counter = 0\n",
        "                self.best_weights = self.model.get_weights()\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            if self.patience_counter >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "\n",
        "        def on_train_end(self, logs=None):\n",
        "            # Restore best weights\n",
        "            if self.best_weights is not None:\n",
        "                self.model.set_weights(self.best_weights)\n",
        "                print(f\"Restored best weights from epoch {self.best_epoch + 1}\")\n",
        "\n",
        "    # Custom callback\n",
        "    no_test_callback = NoTestCallback()\n",
        "\n",
        "    # Fit model\n",
        "    history = model.fit(\n",
        "        x=dataset['train_x'],\n",
        "        y=dataset['train_y'],\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(dataset['val_x'], dataset['val_y']),\n",
        "        callbacks=[no_test_callback],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # NOW EVALUATE ON TEST SET (only once, after training is complete)\n",
        "    print(f\"\\nTraining completed. Evaluating final model on test set...\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_results = model.evaluate(\n",
        "        x=dataset['test_x'],\n",
        "        y=dataset['test_y'],\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Calculate test log loss\n",
        "    test_preds = model.predict(dataset['test_x'], batch_size=batch_size)\n",
        "    test_logloss = log_loss(dataset['test_y'], test_preds)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Get best values\n",
        "    best_epoch = no_test_callback.best_epoch\n",
        "    best_val_auc = no_test_callback.best_val_auc\n",
        "    best_test_auc = test_results[1]  # AUC is the second metric\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nFINAL RESULTS:\")\n",
        "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
        "    print(f\"  Best validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"  Test AUC: {best_test_auc:.4f}\")\n",
        "    print(f\"  Test Log Loss: {test_logloss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "    # Create history plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['auc'], label='Train AUC')\n",
        "    plt.plot(history.history['val_auc'], label='Val AUC')\n",
        "    plt.axhline(y=best_test_auc, color='r', linestyle='--', label='Test AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('AUC Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.axhline(y=test_logloss, color='r', linestyle='--', label='Test LogLoss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('deepfm_training_history.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to CSV\n",
        "    if save_csv:\n",
        "        # Create results DataFrame\n",
        "        epochs_completed = len(history.history['loss'])\n",
        "        results_df = pd.DataFrame({\n",
        "            'epoch': range(1, epochs_completed + 1),\n",
        "            'train_loss': history.history['loss'],\n",
        "            'train_auc': history.history['auc'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'val_auc': history.history['val_auc']\n",
        "        })\n",
        "\n",
        "        # Add test results only for best epoch\n",
        "        results_df['test_auc'] = np.nan\n",
        "        results_df['test_logloss'] = np.nan\n",
        "        results_df.loc[best_epoch, 'test_auc'] = best_test_auc\n",
        "        results_df.loc[best_epoch, 'test_logloss'] = test_logloss\n",
        "\n",
        "        results_df.to_csv('deepfm_training_results.csv', index=False)\n",
        "        print(f\"Training results saved to deepfm_training_results.csv\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'success': True,\n",
        "        'best_epoch': best_epoch + 1,\n",
        "        'best_val_auc': best_val_auc,\n",
        "        'best_test_auc': best_test_auc,\n",
        "        'best_test_logloss': test_logloss,\n",
        "        'history': {\n",
        "            'loss': history.history['loss'],\n",
        "            'auc': history.history['auc'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'val_auc': history.history['val_auc'],\n",
        "            'test_auc': best_test_auc,  # Just the final value\n",
        "            'test_logloss': test_logloss  # Just the final value\n",
        "        },\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "def create_baseline_dataset():\n",
        "    \"\"\"Create dataset for Baseline model\"\"\"\n",
        "    print(f\"Creating Baseline dataset...\")\n",
        "\n",
        "    # Use global splits\n",
        "    baseline_train_x = {\n",
        "        'user_id': splits['train']['user_ids'],\n",
        "        'item_id': splits['train']['item_ids'],\n",
        "        'dense_features': splits['train']['dense_features']\n",
        "    }\n",
        "    baseline_val_x = {\n",
        "        'user_id': splits['val']['user_ids'],\n",
        "        'item_id': splits['val']['item_ids'],\n",
        "        'dense_features': splits['val']['dense_features']\n",
        "    }\n",
        "    baseline_test_x = {\n",
        "        'user_id': splits['test']['user_ids'],\n",
        "        'item_id': splits['test']['item_ids'],\n",
        "        'dense_features': splits['test']['dense_features']\n",
        "    }\n",
        "\n",
        "    baseline_train_y = splits['train']['labels'].flatten()\n",
        "    baseline_val_y = splits['val']['labels'].flatten()\n",
        "    baseline_test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "    # Return dataset\n",
        "    return {\n",
        "        'train_x': baseline_train_x,\n",
        "        'train_y': baseline_train_y,\n",
        "        'val_x': baseline_val_x,\n",
        "        'val_y': baseline_val_y,\n",
        "        'test_x': baseline_test_x,\n",
        "        'test_y': baseline_test_y\n",
        "    }\n",
        "\n",
        "def train_baseline_model(model=None, batch_size=2048, epochs=15, early_stopping_patience=4, save_csv=False):\n",
        "    \"\"\"Train Baseline model with test set evaluation only at the end\"\"\"\n",
        "    # Start timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"STARTING BASELINE TRAINING:\")\n",
        "    print(f\"  Batch size: {batch_size}\")\n",
        "    print(f\"  Epochs: {epochs}\")\n",
        "    print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
        "    print(f\"  Test set evaluation: Only at end of training\")\n",
        "\n",
        "    # If no model is provided, use the global model\n",
        "    if model is None:\n",
        "        model = baseline_model\n",
        "\n",
        "    # Get dataset\n",
        "    dataset = create_baseline_dataset()\n",
        "\n",
        "    # Create custom callback to avoid test set evaluation during training\n",
        "    class NoTestCallback(tf.keras.callbacks.Callback):\n",
        "        def __init__(self):\n",
        "            super(NoTestCallback, self).__init__()\n",
        "            self.best_val_auc = 0\n",
        "            self.best_weights = None\n",
        "            self.patience_counter = 0\n",
        "            self.best_epoch = 0\n",
        "            self.patience = early_stopping_patience\n",
        "\n",
        "        def on_epoch_end(self, epoch, logs=None):\n",
        "            current_val_auc = logs.get('val_auc')\n",
        "            if current_val_auc > self.best_val_auc:\n",
        "                self.best_val_auc = current_val_auc\n",
        "                self.best_epoch = epoch\n",
        "                self.patience_counter = 0\n",
        "                self.best_weights = self.model.get_weights()\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            if self.patience_counter >= self.patience:\n",
        "                self.model.stop_training = True\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "\n",
        "        def on_train_end(self, logs=None):\n",
        "            # Restore best weights\n",
        "            if self.best_weights is not None:\n",
        "                self.model.set_weights(self.best_weights)\n",
        "                print(f\"Restored best weights from epoch {self.best_epoch + 1}\")\n",
        "\n",
        "    # Custom callback\n",
        "    no_test_callback = NoTestCallback()\n",
        "\n",
        "    # Fit model\n",
        "    history = model.fit(\n",
        "        x=dataset['train_x'],\n",
        "        y=dataset['train_y'],\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(dataset['val_x'], dataset['val_y']),\n",
        "        callbacks=[no_test_callback],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # NOW EVALUATE ON TEST SET (only once, after training is complete)\n",
        "    print(f\"\\nTraining completed. Evaluating final model on test set...\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_results = model.evaluate(\n",
        "        x=dataset['test_x'],\n",
        "        y=dataset['test_y'],\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Calculate test log loss\n",
        "    test_preds = model.predict(dataset['test_x'], batch_size=batch_size)\n",
        "    test_logloss = log_loss(dataset['test_y'], test_preds)\n",
        "\n",
        "    # Calculate training time\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Get best values\n",
        "    best_epoch = no_test_callback.best_epoch\n",
        "    best_val_auc = no_test_callback.best_val_auc\n",
        "    best_test_auc = test_results[1]  # AUC is the second metric\n",
        "\n",
        "    # Final evaluation\n",
        "    print(f\"\\nFINAL RESULTS:\")\n",
        "    print(f\"  Best epoch: {best_epoch + 1}\")\n",
        "    print(f\"  Best validation AUC: {best_val_auc:.4f}\")\n",
        "    print(f\"  Test AUC: {best_test_auc:.4f}\")\n",
        "    print(f\"  Test Log Loss: {test_logloss:.4f}\")\n",
        "    print(f\"  Training time: {training_time:.1f}s\")\n",
        "\n",
        "    # Create history plot\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot AUC\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['auc'], label='Train AUC')\n",
        "    plt.plot(history.history['val_auc'], label='Val AUC')\n",
        "    plt.axhline(y=best_test_auc, color='r', linestyle='--', label='Test AUC')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title('AUC Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.axhline(y=test_logloss, color='r', linestyle='--', label='Test LogLoss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss Metrics')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('baseline_training_history.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Save results to CSV\n",
        "    if save_csv:\n",
        "        # Create results DataFrame\n",
        "        epochs_completed = len(history.history['loss'])\n",
        "        results_df = pd.DataFrame({\n",
        "            'epoch': range(1, epochs_completed + 1),\n",
        "            'train_loss': history.history['loss'],\n",
        "            'train_auc': history.history['auc'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'val_auc': history.history['val_auc']\n",
        "        })\n",
        "\n",
        "        # Add test results only for best epoch\n",
        "        results_df['test_auc'] = np.nan\n",
        "        results_df['test_logloss'] = np.nan\n",
        "        results_df.loc[best_epoch, 'test_auc'] = best_test_auc\n",
        "        results_df.loc[best_epoch, 'test_logloss'] = test_logloss\n",
        "\n",
        "        results_df.to_csv('baseline_training_results.csv', index=False)\n",
        "        print(f\"Training results saved to baseline_training_results.csv\")\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        'success': True,\n",
        "        'best_epoch': best_epoch + 1,\n",
        "        'best_val_auc': best_val_auc,\n",
        "        'best_test_auc': best_test_auc,\n",
        "        'best_test_logloss': test_logloss,\n",
        "        'history': {\n",
        "            'loss': history.history['loss'],\n",
        "            'auc': history.history['auc'],\n",
        "            'val_loss': history.history['val_loss'],\n",
        "            'val_auc': history.history['val_auc'],\n",
        "            'test_auc': best_test_auc,  # Just the final value\n",
        "            'test_logloss': test_logloss  # Just the final value\n",
        "        },\n",
        "        'training_time': training_time\n",
        "    }\n",
        "\n",
        "print(f\"Training functions defined successfully!\")"
      ],
      "metadata": {
        "id": "WDMS2kAgimRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932e92e9-00c6-4bd8-e13b-7690ddb058bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING FUNCTIONS DEFINITIONS\n",
            "============================================================\n",
            "Training functions defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna -q"
      ],
      "metadata": {
        "id": "nV_CWrXdh0hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2799e9-2be5-4675-be53-f7ea026b6cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/242.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6F-OPTUNA: HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "import random\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "import optuna  # Import optuna library\n",
        "\n",
        "class ModelTuner:\n",
        "    \"\"\"Framework untuk hyperparameter tuning dengan evaluasi di validation dan test set\"\"\"\n",
        "\n",
        "    def __init__(self, model_type, model_data, subsample_fraction=None, random_seed=42,\n",
        "                 save_dir='tuning_results', current_user=\"heryyy\", current_time=\"-\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model_type: String ('DIN-DICE', 'DIN-PReLU', 'DeepFM', 'Baseline')\n",
        "            model_data: Dictionary dengan train, val, test datasets\n",
        "            subsample_fraction: Fraksi data training yang digunakan untuk tuning (None = full dataset)\n",
        "            random_seed: Random seed untuk subsample reproducibility\n",
        "            save_dir: Direktori untuk menyimpan hasil tuning\n",
        "        \"\"\"\n",
        "        self.model_type = model_type\n",
        "        self.original_model_data = model_data\n",
        "        self.subsample_fraction = subsample_fraction\n",
        "        self.random_seed = random_seed\n",
        "        self.save_dir = save_dir\n",
        "        self.results = []\n",
        "        self.best_params = None\n",
        "        self.best_val_auc = 0\n",
        "        self.best_test_auc = 0\n",
        "        self.best_test_logloss = float('inf')\n",
        "        self.current_user = current_user\n",
        "        self.current_time = current_time\n",
        "        self.optuna_study = None\n",
        "\n",
        "        # Buat direktori jika belum ada\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # CSV file untuk tracking hasil trial\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.csv_path = os.path.join(save_dir, f'{model_type}_tuning_results_{timestamp}.csv')\n",
        "\n",
        "        # Inisialisasi parameter search space\n",
        "        self._init_search_space()\n",
        "\n",
        "        # Siapkan data (subsampled jika diperlukan)\n",
        "        self.model_data = self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        \"\"\"Prepare data for tuning - create subsample if requested\"\"\"\n",
        "        if self.subsample_fraction is None or self.subsample_fraction >= 1.0:\n",
        "            return self.original_model_data\n",
        "\n",
        "        # Create subsample dari data training\n",
        "        subsampled_data = {\n",
        "            'splits': {\n",
        "                'train': {},\n",
        "                'val': self.original_model_data['splits']['val'],\n",
        "                'test': self.original_model_data['splits']['test']\n",
        "            },\n",
        "            'model_params': self.original_model_data['model_params']\n",
        "        }\n",
        "\n",
        "        # Ambil info dari data training\n",
        "        train_data = self.original_model_data['splits']['train']\n",
        "        n_samples = len(train_data['labels'])\n",
        "        subsample_size = int(n_samples * self.subsample_fraction)\n",
        "\n",
        "        print(f\"Creating {self.subsample_fraction*100:.1f}% subsample of training data...\")\n",
        "        print(f\"  Original training samples: {n_samples:,}\")\n",
        "        print(f\"  Subsampled training size: {subsample_size:,}\")\n",
        "\n",
        "        # Set random seed untuk reproducibility\n",
        "        np.random.seed(self.random_seed)\n",
        "\n",
        "        # Generate random indices\n",
        "        indices = np.random.choice(n_samples, subsample_size, replace=False)\n",
        "        indices.sort()  # Sort untuk efisiensi akses\n",
        "\n",
        "        # Subsample setiap komponen data training\n",
        "        for key, value in train_data.items():\n",
        "            if isinstance(value, np.ndarray):\n",
        "                subsampled_data['splits']['train'][key] = value[indices]\n",
        "            elif isinstance(value, list):\n",
        "                subsampled_data['splits']['train'][key] = [value[i] for i in indices]\n",
        "            else:\n",
        "                # Copy langsung jika bukan array atau list\n",
        "                subsampled_data['splits']['train'][key] = value\n",
        "\n",
        "        # Verifikasi hasil subsample\n",
        "        orig_pos_rate = np.mean(train_data['labels'])\n",
        "        new_pos_rate = np.mean(subsampled_data['splits']['train']['labels'])\n",
        "\n",
        "        print(f\"  Original positive rate: {orig_pos_rate:.4f}\")\n",
        "        print(f\"  Subsampled positive rate: {new_pos_rate:.4f}\")\n",
        "        print(f\"âœ… Subsample created successfully\")\n",
        "\n",
        "        return subsampled_data\n",
        "\n",
        "    def _init_search_space(self):\n",
        "        \"\"\"Inisialisasi search space berdasarkan tipe model\"\"\"\n",
        "        if self.model_type == 'DIN-DICE':\n",
        "            self.search_space = {\n",
        "                'learning_rate': [1e-4, 5e-5, 1e-5],\n",
        "                'batch_size': [2048, 4096, 8192],\n",
        "                'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
        "                'l2_reg': [1e-4, 5e-5, 1e-5],\n",
        "                'l2_dense': [1e-4, 5e-5, 1e-5],\n",
        "                'dice_alpha_init': [0.3, 0.4, 0.5],\n",
        "                'dice_beta_init': [1.0, 1.5, 2.0],\n",
        "                'dice_epsilon': [1e-8, 1e-9, 1e-10],\n",
        "                'attention_hidden': [8, 16, 32],\n",
        "                'label_smoothing': [0.0, 0.1, 0.2]\n",
        "            }\n",
        "        elif self.model_type == 'DIN-PReLU':\n",
        "            self.search_space = {\n",
        "                'learning_rate': [1e-4, 5e-5, 1e-5],\n",
        "                'batch_size': [2048, 4096, 8192],\n",
        "                'dropout_rate': [0.3, 0.4, 0.5, 0.6],\n",
        "                'l2_reg': [1e-4, 5e-5, 1e-5],\n",
        "                'l2_dense': [1e-4, 5e-5, 1e-5],\n",
        "                'prelu_alpha_init': [0.2, 0.3, 0.4],\n",
        "                'attention_hidden': [8, 16, 32],\n",
        "                'label_smoothing': [0.0, 0.1, 0.2]\n",
        "            }\n",
        "        elif self.model_type == 'DeepFM':\n",
        "            self.search_space = {\n",
        "                'learning_rate': [1e-3, 1e-4, 5e-5],\n",
        "                'batch_size': [2048, 4096, 8192],\n",
        "                'dropout_rate': [0.3, 0.5, 0.7],\n",
        "                'l2_reg': [1e-3, 1e-4, 1e-5],\n",
        "                'l2_dense': [1e-3, 1e-4, 1e-5],\n",
        "                'hidden_units': [[128, 64, 32], [256, 128, 64], [64, 32, 16]],\n",
        "                'label_smoothing': [0.0, 0.1, 0.2]\n",
        "            }\n",
        "        elif self.model_type == 'Baseline':\n",
        "            self.search_space = {\n",
        "                'learning_rate': [1e-3, 1e-4, 5e-5],\n",
        "                'batch_size': [2048, 4096, 8192],\n",
        "                'dropout_rate': [0.3, 0.5, 0.7],\n",
        "                'l2_reg': [1e-3, 1e-4, 1e-5],\n",
        "                'l2_dense': [1e-3, 1e-4, 1e-5],\n",
        "                'hidden_units': [[128, 64], [64, 32], [256, 128]],\n",
        "                'label_smoothing': [0.0, 0.1, 0.2]\n",
        "            }\n",
        "        else:\n",
        "            raise ValueError(f\"Model type {self.model_type} not supported\")\n",
        "\n",
        "    # Optuna objective function\n",
        "    def _optuna_objective(self, trial):\n",
        "        \"\"\"Objective function for Optuna optimization using only categorical parameters\"\"\"\n",
        "        # Sample hyperparameters using Optuna's categorical API\n",
        "        if self.model_type == 'DIN-DICE':\n",
        "        # Sample hyperparameters using Optuna's categorical API\n",
        "            hidden_units_options = [\n",
        "                [64, 32],        # Dangkal, Sempit\n",
        "                [128, 64],       # Dangkal, Sedang\n",
        "                [256, 128],      # Dangkal, Lebar\n",
        "                [128, 64, 32]    # Dalam, Sedang\n",
        "            ]\n",
        "            hidden_units_idx = trial.suggest_categorical('hidden_units_idx', list(range(len(hidden_units_options))))\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [2048, 4096, 8192]),\n",
        "                'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.4, 0.5, 0.6]),\n",
        "                'l2_reg': trial.suggest_categorical('l2_reg', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'l2_dense': trial.suggest_categorical('l2_dense', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'dice_alpha_init': trial.suggest_categorical('dice_alpha_init', [0.3, 0.35, 0.4, 0.45, 0.5]),\n",
        "                'dice_beta_init': trial.suggest_categorical('dice_beta_init', [1.0, 1.2, 1.5, 1.8, 2.0]),\n",
        "                'dice_epsilon': trial.suggest_categorical('dice_epsilon', [1e-8, 1e-9, 1e-10]),\n",
        "                'attention_hidden': trial.suggest_categorical('attention_hidden', [8, 16, 32]),\n",
        "                'label_smoothing': trial.suggest_categorical('label_smoothing', [0.0, 0.05, 0.1, 0.15, 0.2]),\n",
        "                'hidden_units': hidden_units_options[hidden_units_idx]\n",
        "            }\n",
        "        elif self.model_type == 'DIN-PReLU':\n",
        "            hidden_units_options = [\n",
        "                [64, 32],        # Dangkal, Sempit\n",
        "                [128, 64],       # Dangkal, Sedang\n",
        "                [256, 128],      # Dangkal, Lebar\n",
        "                [128, 64, 32]    # Dalam, Sedang\n",
        "            ]\n",
        "            hidden_units_idx = trial.suggest_categorical('hidden_units_idx', list(range(len(hidden_units_options))))\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [2048, 4096, 8192]),\n",
        "                'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.4, 0.5, 0.6]),\n",
        "                'l2_reg': trial.suggest_categorical('l2_reg', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'l2_dense': trial.suggest_categorical('l2_dense', [1e-5, 2e-5, 5e-5, 1e-4]),\n",
        "                'prelu_alpha_init': trial.suggest_categorical('prelu_alpha_init', [0.2, 0.25, 0.3, 0.35, 0.4]),\n",
        "                'attention_hidden': trial.suggest_categorical('attention_hidden', [8, 16, 32]),\n",
        "                'label_smoothing': trial.suggest_categorical('label_smoothing', [0.0, 0.05, 0.1, 0.15, 0.2]),\n",
        "                'hidden_units': hidden_units_options[hidden_units_idx]\n",
        "            }\n",
        "        elif self.model_type == 'DeepFM':\n",
        "            hidden_units_options = [[128, 64, 32], [256, 128, 64], [64, 32, 16]]\n",
        "            hidden_units_idx = trial.suggest_categorical('hidden_units_idx', list(range(len(hidden_units_options))))\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [2048, 4096, 8192]),\n",
        "                'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.4, 0.5, 0.6, 0.7]),\n",
        "                'l2_reg': trial.suggest_categorical('l2_reg', [1e-5, 1e-4, 1e-3]),\n",
        "                'l2_dense': trial.suggest_categorical('l2_dense', [1e-5, 1e-4, 1e-3]),\n",
        "                'hidden_units': hidden_units_options[hidden_units_idx],\n",
        "                'label_smoothing': trial.suggest_categorical('label_smoothing', [0.0, 0.05, 0.1, 0.15, 0.2]),\n",
        "            }\n",
        "        elif self.model_type == 'Baseline':\n",
        "            hidden_units_options = [[128, 64], [64, 32], [256, 128]]\n",
        "            hidden_units_idx = trial.suggest_categorical('hidden_units_idx', list(range(len(hidden_units_options))))\n",
        "            params = {\n",
        "                'learning_rate': trial.suggest_categorical('learning_rate', [1e-5, 5e-5, 1e-4, 5e-4, 1e-3]),\n",
        "                'batch_size': trial.suggest_categorical('batch_size', [2048, 4096, 8192]),\n",
        "                'dropout_rate': trial.suggest_categorical('dropout_rate', [0.3, 0.4, 0.5, 0.6, 0.7]),\n",
        "                'l2_reg': trial.suggest_categorical('l2_reg', [1e-5, 1e-4, 1e-3]),\n",
        "                'l2_dense': trial.suggest_categorical('l2_dense', [1e-5, 1e-4, 1e-3]),\n",
        "                'hidden_units': hidden_units_options[hidden_units_idx],\n",
        "                'label_smoothing': trial.suggest_categorical('label_smoothing', [0.0, 0.05, 0.1, 0.15, 0.2])\n",
        "            }\n",
        "\n",
        "        # Run trial with these parameters\n",
        "        trial_results = self.run_trial(params)\n",
        "\n",
        "        # Return validation AUC for Optuna to maximize\n",
        "        if 'val_auc' not in trial_results:\n",
        "            return 0.0  # In case of error\n",
        "\n",
        "        return trial_results['val_auc']\n",
        "\n",
        "    def _sample_hyperparameters(self):\n",
        "        \"\"\"Sample hyperparameters dari search space\"\"\"\n",
        "        params = {}\n",
        "        for param_name, param_values in self.search_space.items():\n",
        "            params[param_name] = random.choice(param_values)\n",
        "        return params\n",
        "\n",
        "    def run_trial(self, params=None):\n",
        "        \"\"\"Run single tuning trial dengan parameter tertentu\"\"\"\n",
        "        if params is None:\n",
        "            params = self._sample_hyperparameters()\n",
        "\n",
        "        # Add subsample info to output if applicable\n",
        "        subsample_info = \"\"\n",
        "        if self.subsample_fraction is not None and self.subsample_fraction < 1.0:\n",
        "            subsample_info = f\" (USING {self.subsample_fraction*100:.1f}% DATA)\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"RUNNING TRIAL FOR {self.model_type}{subsample_info}\")\n",
        "        print(f\"Parameters: {params}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Create model\n",
        "        try:\n",
        "            # Setup data\n",
        "            splits = self.model_data['splits']\n",
        "\n",
        "            # Prepare data berdasarkan tipe model\n",
        "            if self.model_type in ['DIN-DICE', 'DIN-PReLU']:\n",
        "                # DIN membutuhkan sequence\n",
        "                train_x = {\n",
        "                    'user_id': splits['train']['user_ids'],\n",
        "                    'item_id': splits['train']['item_ids'],\n",
        "                    'sequence': splits['train']['sequences'],\n",
        "                    'seq_length': splits['train']['seq_lengths'],\n",
        "                    'dense_features': splits['train']['dense_features']\n",
        "                }\n",
        "                val_x = {\n",
        "                    'user_id': splits['val']['user_ids'],\n",
        "                    'item_id': splits['val']['item_ids'],\n",
        "                    'sequence': splits['val']['sequences'],\n",
        "                    'seq_length': splits['val']['seq_lengths'],\n",
        "                    'dense_features': splits['val']['dense_features']\n",
        "                }\n",
        "                test_x = {\n",
        "                    'user_id': splits['test']['user_ids'],\n",
        "                    'item_id': splits['test']['item_ids'],\n",
        "                    'sequence': splits['test']['sequences'],\n",
        "                    'seq_length': splits['test']['seq_lengths'],\n",
        "                    'dense_features': splits['test']['dense_features']\n",
        "                }\n",
        "            else:\n",
        "                # DeepFM dan Baseline tidak membutuhkan sequence\n",
        "                train_x = {\n",
        "                    'user_id': splits['train']['user_ids'],\n",
        "                    'item_id': splits['train']['item_ids'],\n",
        "                    'dense_features': splits['train']['dense_features']\n",
        "                }\n",
        "                val_x = {\n",
        "                    'user_id': splits['val']['user_ids'],\n",
        "                    'item_id': splits['val']['item_ids'],\n",
        "                    'dense_features': splits['val']['dense_features']\n",
        "                }\n",
        "                test_x = {\n",
        "                    'user_id': splits['test']['user_ids'],\n",
        "                    'item_id': splits['test']['item_ids'],\n",
        "                    'dense_features': splits['test']['dense_features']\n",
        "                }\n",
        "\n",
        "            train_y = splits['train']['labels'].flatten()\n",
        "            val_y = splits['val']['labels'].flatten()\n",
        "            test_y = splits['test']['labels'].flatten()\n",
        "\n",
        "            # Create and compile model\n",
        "            if self.model_type == 'DIN-DICE':\n",
        "                model = self._create_din_dice_model(params)\n",
        "            elif self.model_type == 'DIN-PReLU':\n",
        "                model = self._create_din_prelu_model(params)\n",
        "            elif self.model_type == 'DeepFM':\n",
        "                model = self._create_deepfm_model(params)\n",
        "            elif self.model_type == 'Baseline':\n",
        "                model = self._create_baseline_model(params)\n",
        "            else:\n",
        "                raise ValueError(f\"Model type {self.model_type} not supported\")\n",
        "\n",
        "            # Compile model\n",
        "            label_smoothing = params['label_smoothing']\n",
        "            learning_rate = params['learning_rate']\n",
        "\n",
        "            optimizer = tf.keras.optimizers.Adam(\n",
        "                learning_rate=learning_rate,\n",
        "                clipnorm=0.5\n",
        "            )\n",
        "            loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "            metrics = [tf.keras.metrics.AUC(name='auc')]\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            # Callbacks\n",
        "            early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_auc',\n",
        "                patience=3,\n",
        "                mode='max',\n",
        "                restore_best_weights=True\n",
        "            )\n",
        "\n",
        "            # Train model\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Custom training loop atau keras fit\n",
        "            if self.model_type in ['DIN-DICE', 'DIN-PReLU']:\n",
        "                # Truncated custom training loop for tuning\n",
        "                val_auc, test_auc, test_logloss, history = self._train_din_custom(\n",
        "                    model, train_x, train_y, val_x, val_y, test_x, test_y, params\n",
        "                )\n",
        "            else:\n",
        "                # Standard Keras training untuk DeepFM dan Baseline\n",
        "                batch_size = params['batch_size']\n",
        "\n",
        "                history = model.fit(\n",
        "                    x=train_x,\n",
        "                    y=train_y,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=8,  # Kurangi epochs untuk tuning\n",
        "                    validation_data=(val_x, val_y),\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=1\n",
        "                )\n",
        "\n",
        "                # Evaluasi pada validation set\n",
        "                val_result = model.evaluate(val_x, val_y, verbose=0)\n",
        "                val_auc = val_result[1]  # Indeks 1 adalah AUC\n",
        "\n",
        "                # Evaluasi pada test set (PENTING: ini hanya untuk tracking)\n",
        "                test_result = model.evaluate(test_x, test_y, verbose=0)\n",
        "                test_auc = test_result[1]  # Indeks 1 adalah AUC\n",
        "\n",
        "                # Calculate log loss on test set\n",
        "                test_pred = model.predict(test_x, batch_size=batch_size, verbose=0)\n",
        "                test_pred = test_pred.flatten()\n",
        "                test_logloss = log_loss(test_y, test_pred)\n",
        "\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            # Capture results\n",
        "            trial_results = {\n",
        "                'model_type': self.model_type,\n",
        "                'trial_time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                'val_auc': val_auc,\n",
        "                'test_auc': test_auc,\n",
        "                'test_logloss': test_logloss,\n",
        "                'training_time': training_time,\n",
        "                'subsample_fraction': self.subsample_fraction,\n",
        "                **params  # Include all hyperparameters\n",
        "            }\n",
        "\n",
        "            # Add to results list\n",
        "            self.results.append(trial_results)\n",
        "\n",
        "            # Check if this is the best model (based on validation AUC)\n",
        "            if val_auc > self.best_val_auc:\n",
        "                self.best_val_auc = val_auc\n",
        "                self.best_test_auc = test_auc\n",
        "                self.best_test_logloss = test_logloss\n",
        "                self.best_params = params.copy()\n",
        "\n",
        "                print(f\"\\nâœ… NEW BEST MODEL!\")\n",
        "                print(f\"Validation AUC: {self.best_val_auc:.4f}\")\n",
        "                print(f\"Test AUC: {self.best_test_auc:.4f}\")\n",
        "                print(f\"Test Log Loss: {self.best_test_logloss:.4f}\")\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.DataFrame(self.results)\n",
        "            results_df.to_csv(self.csv_path, index=False)\n",
        "\n",
        "            print(f\"\\nTRIAL RESULTS:\")\n",
        "            print(f\"Validation AUC: {val_auc:.4f}\")\n",
        "            print(f\"Test AUC: {test_auc:.4f}\")\n",
        "            print(f\"Test Log Loss: {test_logloss:.4f}\")\n",
        "            print(f\"Training Time: {training_time:.1f}s\")\n",
        "            print(f\"Results saved to {self.csv_path}\")\n",
        "\n",
        "            return trial_results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error in trial: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Log failed trial\n",
        "            trial_results = {\n",
        "                'model_type': self.model_type,\n",
        "                'trial_time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                'error': str(e),\n",
        "                'status': 'failed',\n",
        "                'subsample_fraction': self.subsample_fraction,\n",
        "                **params  # Include all hyperparameters\n",
        "            }\n",
        "\n",
        "            self.results.append(trial_results)\n",
        "\n",
        "            # Save results to CSV\n",
        "            results_df = pd.DataFrame(self.results)\n",
        "            results_df.to_csv(self.csv_path, index=False)\n",
        "\n",
        "            return trial_results\n",
        "\n",
        "    def _train_din_custom(self, model, train_x, train_y, val_x, val_y, test_x, test_y, params):\n",
        "        \"\"\"Simplified custom training loop for DIN models during tuning\"\"\"\n",
        "        # TRUNCATED VERSION FOR TUNING - fewer epochs and simplified\n",
        "        batch_size = params['batch_size']\n",
        "        epochs = 8  # Reduced for tuning\n",
        "\n",
        "        # Set up optimizer and loss\n",
        "        learning_rate = params['learning_rate']\n",
        "        label_smoothing = params['label_smoothing']\n",
        "\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=0.5)\n",
        "        loss_fn = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "\n",
        "        # Metrics\n",
        "        train_loss_metric = tf.keras.metrics.Mean()\n",
        "        train_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "        val_loss_metric = tf.keras.metrics.Mean()\n",
        "        val_auc_metric = tf.keras.metrics.AUC()\n",
        "\n",
        "        # History tracking\n",
        "        history = {\n",
        "            'loss': [],\n",
        "            'auc': [],\n",
        "            'val_loss': [],\n",
        "            'val_auc': []\n",
        "        }\n",
        "\n",
        "        # Early stopping tracking\n",
        "        best_val_auc = 0.0\n",
        "        patience_counter = 0\n",
        "        best_weights = None\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "            # Reset metrics\n",
        "            train_loss_metric.reset_state()\n",
        "            train_auc_metric.reset_state()\n",
        "            val_loss_metric.reset_state()\n",
        "            val_auc_metric.reset_state()\n",
        "\n",
        "            # TRAINING PHASE\n",
        "            n_train_batches = (len(train_y) + batch_size - 1) // batch_size\n",
        "            indices = np.random.permutation(len(train_y))\n",
        "\n",
        "            for batch_idx in range(n_train_batches):\n",
        "                start_idx = batch_idx * batch_size\n",
        "                end_idx = min(start_idx + batch_size, len(train_y))\n",
        "                batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "                batch_x = {k: tf.convert_to_tensor(v[batch_indices]) for k, v in train_x.items()}\n",
        "                batch_y = tf.convert_to_tensor(train_y[batch_indices])\n",
        "\n",
        "                with tf.GradientTape() as tape:\n",
        "                    predictions = model(batch_x, training=True)\n",
        "                    predictions = tf.squeeze(predictions)\n",
        "                    loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "                gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "                # Update metrics\n",
        "                train_loss_metric.update_state(loss)\n",
        "                train_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # VALIDATION PHASE\n",
        "            n_val_batches = (len(val_y) + batch_size - 1) // batch_size\n",
        "\n",
        "            for batch_idx in range(n_val_batches):\n",
        "                start_idx = batch_idx * batch_size\n",
        "                end_idx = min(start_idx + batch_size, len(val_y))\n",
        "\n",
        "                batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in val_x.items()}\n",
        "                batch_y = tf.convert_to_tensor(val_y[start_idx:end_idx])\n",
        "\n",
        "                predictions = model(batch_x, training=False)\n",
        "                predictions = tf.squeeze(predictions)\n",
        "                loss = loss_fn(batch_y, predictions)\n",
        "\n",
        "                val_loss_metric.update_state(loss)\n",
        "                val_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # Get epoch results\n",
        "            epoch_train_loss = train_loss_metric.result().numpy()\n",
        "            epoch_train_auc = train_auc_metric.result().numpy()\n",
        "            epoch_val_loss = val_loss_metric.result().numpy()\n",
        "            epoch_val_auc = val_auc_metric.result().numpy()\n",
        "\n",
        "            # Store history\n",
        "            history['loss'].append(epoch_train_loss)\n",
        "            history['auc'].append(epoch_train_auc)\n",
        "            history['val_loss'].append(epoch_val_loss)\n",
        "            history['val_auc'].append(epoch_val_auc)\n",
        "\n",
        "            # Print results (only train and validation metrics)\n",
        "            print(f\"  Train - Loss: {epoch_train_loss:.4f}, AUC: {epoch_train_auc:.4f}\")\n",
        "            print(f\"  Val   - Loss: {epoch_val_loss:.4f}, AUC: {epoch_val_auc:.4f}\")\n",
        "\n",
        "            # Check early stopping\n",
        "            if epoch_val_auc > best_val_auc:\n",
        "                best_val_auc = epoch_val_auc\n",
        "                patience_counter = 0\n",
        "                best_weights = model.get_weights()\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= 3:  # Lower patience for tuning\n",
        "                print(f\"  Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "        # Restore best weights\n",
        "        if best_weights is not None:\n",
        "            model.set_weights(best_weights)\n",
        "\n",
        "        # Final evaluation\n",
        "        # Get final validation AUC\n",
        "        final_val_auc = best_val_auc\n",
        "\n",
        "        # ONLY NOW evaluate on test set (after training is complete)\n",
        "        print(f\"  Evaluating on test set...\")\n",
        "        test_auc_metric = tf.keras.metrics.AUC()\n",
        "        test_predictions = []\n",
        "        test_labels = []\n",
        "\n",
        "        n_test_batches = (len(test_y) + batch_size - 1) // batch_size\n",
        "\n",
        "        for batch_idx in range(n_test_batches):\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = min(start_idx + batch_size, len(test_y))\n",
        "\n",
        "            batch_x = {k: tf.convert_to_tensor(v[start_idx:end_idx]) for k, v in test_x.items()}\n",
        "            batch_y = tf.convert_to_tensor(test_y[start_idx:end_idx])\n",
        "\n",
        "            predictions = model(batch_x, training=False)\n",
        "            predictions = tf.squeeze(predictions)\n",
        "\n",
        "            test_auc_metric.update_state(batch_y, predictions)\n",
        "\n",
        "            # Collect predictions and labels for log loss calculation\n",
        "            test_predictions.append(predictions.numpy())\n",
        "            test_labels.append(batch_y.numpy())\n",
        "\n",
        "        final_test_auc = test_auc_metric.result().numpy()\n",
        "\n",
        "        # Calculate log loss on test set\n",
        "        test_predictions = np.concatenate(test_predictions)\n",
        "        test_labels = np.concatenate(test_labels)\n",
        "        test_logloss = log_loss(test_labels, test_predictions)\n",
        "\n",
        "        return final_val_auc, final_test_auc, test_logloss, history\n",
        "\n",
        "    # The rest of the methods remain unchanged\n",
        "    def _create_din_dice_model(self, params):\n",
        "        \"\"\"Create DIN-DICE model dengan parameter dari tuning\"\"\"\n",
        "        # Kode ini menyesuaikan dengan create_din_dice_model() yang ada\n",
        "\n",
        "        # Model parameters\n",
        "        n_users = self.model_data['model_params']['n_users']\n",
        "        n_items = self.model_data['model_params']['n_items']\n",
        "        embedding_dim = 32\n",
        "        hidden_units = params['hidden_units']\n",
        "        attention_hidden = params['attention_hidden']\n",
        "        max_seq_len = 8\n",
        "        dense_feature_dim = self.model_data['model_params']['dense_feature_dim']\n",
        "        dropout_rate = params['dropout_rate']\n",
        "        l2_reg = params['l2_reg']\n",
        "        l2_dense = params['l2_dense']\n",
        "        dice_alpha_init = params['dice_alpha_init']\n",
        "        dice_beta_init = params['dice_beta_init']\n",
        "        dice_epsilon = params['dice_epsilon']\n",
        "\n",
        "        # Input layers\n",
        "        user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "        item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "        sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "        seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "        dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        user_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_users, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='user_embedding'\n",
        "        )\n",
        "        item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_items, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='item_embedding'\n",
        "        )\n",
        "\n",
        "        # Apply embeddings\n",
        "        user_emb = user_embedding_layer(user_input)\n",
        "        target_item_emb = item_embedding_layer(item_input)\n",
        "        sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "        # DIN Attention mechanism\n",
        "        attention_scores, attended_emb = DINAttention(\n",
        "            hidden_units=attention_hidden,\n",
        "            max_seq_len=max_seq_len,\n",
        "            activation_type='dice',\n",
        "            dice_alpha_init=params['dice_alpha_init'],\n",
        "            dice_beta_init=params['dice_beta_init'],\n",
        "            dice_epsilon=params['dice_epsilon'],\n",
        "            name='din_attention'\n",
        "        )([sequence_emb, target_item_emb])\n",
        "\n",
        "        # Sequence pooling\n",
        "        pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "            [attention_scores, attended_emb, seq_length_input]\n",
        "        )\n",
        "\n",
        "        # Feature concatenation\n",
        "        all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "            user_emb,\n",
        "            target_item_emb,\n",
        "            pooled_sequence,\n",
        "            dense_input\n",
        "        ])\n",
        "\n",
        "        # DEEP NETWORK dengan DICE activation\n",
        "        x = all_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            x = tf.keras.layers.Dense(\n",
        "                units,\n",
        "                name=f'dense_{i+1}',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "            )(x)\n",
        "\n",
        "            # DICE activation dari tuning\n",
        "            x = DiceActivation(\n",
        "                name=f'dice_{i+1}',\n",
        "                alpha_init=dice_alpha_init,\n",
        "                beta_init=dice_beta_init,\n",
        "                epsilon=dice_epsilon\n",
        "            )(x)\n",
        "\n",
        "            x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "            x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "        # OUTPUT LAYER\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "        # Create model\n",
        "        model = tf.keras.Model(\n",
        "            inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "            outputs=output,\n",
        "            name='din_dice_tuning'\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    # Methods _create_din_prelu_model, _create_deepfm_model, _create_baseline_model unchanged\n",
        "    def _create_din_prelu_model(self, params):\n",
        "        \"\"\"Create DIN-PReLU model dengan parameter dari tuning\"\"\"\n",
        "        # Model parameters\n",
        "        n_users = self.model_data['model_params']['n_users']\n",
        "        n_items = self.model_data['model_params']['n_items']\n",
        "        embedding_dim = 32\n",
        "        hidden_units = params['hidden_units']\n",
        "        attention_hidden = params['attention_hidden']\n",
        "        max_seq_len = 8\n",
        "        dense_feature_dim = self.model_data['model_params']['dense_feature_dim']\n",
        "        dropout_rate = params['dropout_rate']\n",
        "        l2_reg = params['l2_reg']\n",
        "        l2_dense = params['l2_dense']\n",
        "        prelu_alpha_init = params['prelu_alpha_init']\n",
        "\n",
        "        # Input layers\n",
        "        user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "        item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "        sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "        seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "        dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        user_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_users, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='user_embedding'\n",
        "        )\n",
        "        item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_items, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='item_embedding'\n",
        "        )\n",
        "\n",
        "        # Apply embeddings\n",
        "        user_emb = user_embedding_layer(user_input)\n",
        "        target_item_emb = item_embedding_layer(item_input)\n",
        "        sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "        # DIN Attention mechanism\n",
        "        attention_scores, attended_emb = DINAttention(\n",
        "            hidden_units=attention_hidden,\n",
        "            max_seq_len=max_seq_len,\n",
        "            activation_type='prelu',  # Gunakan PReLU\n",
        "            prelu_alpha_init=params['prelu_alpha_init'],\n",
        "            name='din_attention'\n",
        "        )([sequence_emb, target_item_emb])\n",
        "\n",
        "        # Sequence pooling\n",
        "        pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "            [attention_scores, attended_emb, seq_length_input]\n",
        "        )\n",
        "\n",
        "        # Feature concatenation\n",
        "        all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "            user_emb,\n",
        "            target_item_emb,\n",
        "            pooled_sequence,\n",
        "            dense_input\n",
        "        ])\n",
        "\n",
        "        # DEEP NETWORK dengan PReLU activation\n",
        "        x = all_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            x = tf.keras.layers.Dense(\n",
        "                units,\n",
        "                name=f'dense_{i+1}',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "            )(x)\n",
        "\n",
        "            # PReLU activation dari tuning\n",
        "            x = tf.keras.layers.PReLU(\n",
        "                alpha_initializer=tf.keras.initializers.Constant(prelu_alpha_init),\n",
        "                name=f'prelu_{i+1}'\n",
        "            )(x)\n",
        "\n",
        "            x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "            x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "        # OUTPUT LAYER\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "        # Create model\n",
        "        model = tf.keras.Model(\n",
        "            inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "            outputs=output,\n",
        "            name='din_prelu_tuning'\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _create_deepfm_model(self, params):\n",
        "        \"\"\"Create DeepFM model dengan parameter dari tuning\"\"\"\n",
        "        # Model parameters\n",
        "        n_users = self.model_data['model_params']['n_users']\n",
        "        n_items = self.model_data['model_params']['n_items']\n",
        "        embedding_dim = 32\n",
        "        hidden_units = params['hidden_units']\n",
        "        dense_feature_dim = self.model_data['model_params']['dense_feature_dim']\n",
        "        dropout_rate = params['dropout_rate']\n",
        "        l2_reg = params['l2_reg']\n",
        "        l2_dense = params['l2_dense']\n",
        "\n",
        "        # Input layers\n",
        "        user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "        item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "        dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        user_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_users, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='user_embedding'\n",
        "        )\n",
        "        item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_items, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='item_embedding'\n",
        "        )\n",
        "\n",
        "        # Apply embeddings\n",
        "        user_emb = user_embedding_layer(user_input)\n",
        "        item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "        # FM PART: Factorization Machine component\n",
        "\n",
        "        # LINEAR PART\n",
        "        user_linear = tf.keras.layers.Dense(1, use_bias=False, name='user_linear',\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(user_emb)\n",
        "        item_linear = tf.keras.layers.Dense(1, use_bias=False, name='item_linear',\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(item_emb)\n",
        "        dense_linear = tf.keras.layers.Dense(1, use_bias=False, name='dense_linear',\n",
        "                                          kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "\n",
        "        # INTERACTION PART\n",
        "        # User-Item interaction\n",
        "        user_item_interaction = tf.keras.layers.Multiply(name='user_item_mult')([user_emb, item_emb])\n",
        "\n",
        "        # User-Dense interaction\n",
        "        user_dense_proj = tf.keras.layers.Dense(embedding_dim, name='user_dense_proj',\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "        user_dense_interaction = tf.keras.layers.Multiply(name='user_dense_mult')([user_emb, user_dense_proj])\n",
        "\n",
        "        # Item-Dense interaction\n",
        "        item_dense_proj = tf.keras.layers.Dense(embedding_dim, name='item_dense_proj',\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "        item_dense_interaction = tf.keras.layers.Multiply(name='item_dense_mult')([item_emb, item_dense_proj])\n",
        "\n",
        "        # Sum all interactions\n",
        "        fm_interactions = tf.keras.layers.Add(name='fm_interactions')([\n",
        "            user_item_interaction,\n",
        "            user_dense_interaction,\n",
        "            item_dense_interaction\n",
        "        ])\n",
        "        fm_interaction_sum = tf.keras.layers.Dense(1, name='fm_interaction_sum',\n",
        "                                                kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(fm_interactions)\n",
        "\n",
        "        # FM output\n",
        "        fm_output = tf.keras.layers.Add(name='fm_output')([\n",
        "            user_linear,\n",
        "            item_linear,\n",
        "            dense_linear,\n",
        "            fm_interaction_sum\n",
        "        ])\n",
        "\n",
        "        # DEEP PART: Deep Neural Network component\n",
        "\n",
        "        # Concatenate all features untuk deep part\n",
        "        deep_features = tf.keras.layers.Concatenate(name='deep_features')([\n",
        "            user_emb,\n",
        "            item_emb,\n",
        "            dense_input\n",
        "        ])\n",
        "\n",
        "        # DEEP NETWORK\n",
        "        x = deep_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            x = tf.keras.layers.Dense(\n",
        "                units,\n",
        "                activation='relu',\n",
        "                name=f'deep_dense_{i+1}',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "            )(x)\n",
        "            x = tf.keras.layers.Dropout(dropout_rate, name=f'deep_dropout_{i+1}')(x)\n",
        "            x = tf.keras.layers.BatchNormalization(name=f'deep_bn_{i+1}')(x)\n",
        "\n",
        "        # DEEP OUTPUT\n",
        "        deep_output = tf.keras.layers.Dense(1, name='deep_output',\n",
        "                                         kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "        # COMBINE FM + DEEP\n",
        "        combined_output = tf.keras.layers.Add(name='fm_deep_combine')([fm_output, deep_output])\n",
        "\n",
        "        # Final activation\n",
        "        final_output = tf.keras.layers.Activation('sigmoid', name='final_output')(combined_output)\n",
        "\n",
        "        # Create model\n",
        "        model = tf.keras.Model(\n",
        "            inputs=[user_input, item_input, dense_input],\n",
        "            outputs=final_output,\n",
        "            name='deepfm_tuning'\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _create_baseline_model(self, params):\n",
        "        \"\"\"Create Baseline model dengan parameter dari tuning\"\"\"\n",
        "        # Model parameters\n",
        "        n_users = self.model_data['model_params']['n_users']\n",
        "        n_items = self.model_data['model_params']['n_items']\n",
        "        embedding_dim = 32\n",
        "        hidden_units = params['hidden_units']\n",
        "        dense_feature_dim = self.model_data['model_params']['dense_feature_dim']\n",
        "        dropout_rate = params['dropout_rate']\n",
        "        l2_reg = params['l2_reg']\n",
        "        l2_dense = params['l2_dense']\n",
        "\n",
        "        # Input layers\n",
        "        user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "        item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "        dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        user_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_users, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='user_embedding'\n",
        "        )\n",
        "        item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            n_items, embedding_dim,\n",
        "            embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "            name='item_embedding'\n",
        "        )\n",
        "\n",
        "        # Apply embeddings\n",
        "        user_emb = user_embedding_layer(user_input)\n",
        "        item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "        # Simple feature concatenation\n",
        "        all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "            user_emb,\n",
        "            item_emb,\n",
        "            dense_input\n",
        "        ])\n",
        "\n",
        "        # FEEDFORWARD NETWORK\n",
        "        x = all_features\n",
        "        for i, units in enumerate(hidden_units):\n",
        "            x = tf.keras.layers.Dense(\n",
        "                units,\n",
        "                activation='relu',\n",
        "                name=f'dense_{i+1}',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "            )(x)\n",
        "            x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "            x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "        # OUTPUT LAYER\n",
        "        output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                     kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "        # Create model\n",
        "        model = tf.keras.Model(\n",
        "            inputs=[user_input, item_input, dense_input],\n",
        "            outputs=output,\n",
        "            name='baseline_tuning'\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def run_tuning(self, n_trials=10):\n",
        "        \"\"\"Run hyperparameter tuning dengan n trials menggunakan Optuna\"\"\"\n",
        "        # Add subsample info to output if applicable\n",
        "        subsample_info = \"\"\n",
        "        if self.subsample_fraction is not None and self.subsample_fraction < 1.0:\n",
        "            subsample_info = f\" (USING {self.subsample_fraction*100:.1f}% DATA)\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"STARTING HYPERPARAMETER TUNING FOR {self.model_type}{subsample_info} USING OPTUNA\")\n",
        "        print(f\"Number of trials: {n_trials}\")\n",
        "        print(f\"User: {self.current_user}\")\n",
        "        print(f\"Time: {self.current_time}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Create Optuna study\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "\n",
        "        # Run optimization\n",
        "        study.optimize(self._optuna_objective, n_trials=n_trials)\n",
        "\n",
        "        # Store the study for later analysis\n",
        "        self.optuna_study = study\n",
        "\n",
        "        # Get best parameters from Optuna\n",
        "        self.best_params = study.best_params\n",
        "\n",
        "        # For DeepFM and Baseline, convert hidden_units_idx to actual hidden_units\n",
        "        if self.model_type == 'DIN-DICE' and 'hidden_units_idx' in self.best_params:\n",
        "            # Pastikan list ini SAMA PERSIS dengan yang ada di _optuna_objective\n",
        "            hidden_units_options = [\n",
        "                [64, 32],\n",
        "                [128, 64],\n",
        "                [256, 128],\n",
        "                [128, 64, 32]\n",
        "            ]\n",
        "            idx = self.best_params.pop('hidden_units_idx') # Ambil dan hapus idx\n",
        "            self.best_params['hidden_units'] = hidden_units_options[idx] # Tambahkan list-nya\n",
        "\n",
        "        elif self.model_type == 'DIN-PReLU' and 'hidden_units_idx' in self.best_params:\n",
        "            # Pastikan list ini SAMA PERSIS dengan yang ada di _optuna_objective\n",
        "            hidden_units_options = [\n",
        "                [64, 32],\n",
        "                [128, 64],\n",
        "                [256, 128],\n",
        "                [128, 64, 32]\n",
        "            ]\n",
        "            idx = self.best_params.pop('hidden_units_idx') # Ambil dan hapus idx\n",
        "            self.best_params['hidden_units'] = hidden_units_options[idx] # Tambahkan list-nya\n",
        "\n",
        "        elif self.model_type == 'DeepFM' and 'hidden_units_idx' in self.best_params:\n",
        "            hidden_units_options = [[128, 64, 32], [256, 128, 64], [64, 32, 16]]\n",
        "            idx = self.best_params.pop('hidden_units_idx')\n",
        "            self.best_params['hidden_units'] = hidden_units_options[idx]\n",
        "\n",
        "        elif self.model_type == 'Baseline' and 'hidden_units_idx' in self.best_params:\n",
        "            hidden_units_options = [[128, 64], [64, 32], [256, 128]]\n",
        "            idx = self.best_params.pop('hidden_units_idx')\n",
        "            self.best_params['hidden_units'] = hidden_units_options[idx]\n",
        "\n",
        "        # Get best metrics from results list\n",
        "        best_trial_results = None\n",
        "        for result in self.results:\n",
        "            if 'error' in result:  # Skip failed trials\n",
        "                continue\n",
        "\n",
        "            # Find the trial with the best validation AUC\n",
        "            if result.get('val_auc', 0) > self.best_val_auc:\n",
        "                self.best_val_auc = result.get('val_auc', 0)\n",
        "                self.best_test_auc = result.get('test_auc', 0)\n",
        "                self.best_test_logloss = result.get('test_logloss', float('inf'))\n",
        "                best_trial_results = result\n",
        "\n",
        "        tuning_time = time.time() - start_time\n",
        "\n",
        "        # Print optimization plot info\n",
        "        print(f\"\\nOptuna Study Statistics:\")\n",
        "        print(f\"  Best Value: {study.best_value:.4f}\")\n",
        "        print(f\"  Best Trial: {study.best_trial.number}\")\n",
        "\n",
        "        # Get top parameter importances\n",
        "        try:\n",
        "            importances = optuna.importance.get_param_importances(study)\n",
        "            print(f\"\\nParameter Importances:\")\n",
        "            for param, importance in sorted(importances.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
        "                print(f\"  {param}: {importance:.4f}\")\n",
        "        except:\n",
        "            print(\"Could not calculate parameter importances.\")\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"TUNING COMPLETED FOR {self.model_type}\")\n",
        "        print(f\"Total trials: {n_trials}\")\n",
        "        print(f\"Best validation AUC: {self.best_val_auc:.4f}\")\n",
        "        print(f\"Best test AUC: {self.best_test_auc:.4f}\")\n",
        "        print(f\"Best test log loss: {self.best_test_logloss:.4f}\")\n",
        "        print(f\"Best parameters: {self.best_params}\")\n",
        "        print(f\"Total tuning time: {tuning_time:.1f}s\")\n",
        "        print(f\"Results saved to {self.csv_path}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Save best parameters to JSON\n",
        "        best_params_file = os.path.join(self.save_dir, f'{self.model_type}_best_params.json')\n",
        "        with open(best_params_file, 'w') as f:\n",
        "            json.dump(self.best_params, f, indent=4)\n",
        "\n",
        "        print(f\"Best parameters saved to {best_params_file}\")\n",
        "\n",
        "        # Add reminder if subsampling was used\n",
        "        if self.subsample_fraction is not None and self.subsample_fraction < 1.0:\n",
        "            print(f\"\\nâš ï¸ REMINDER: Tuning used {self.subsample_fraction*100:.1f}% of training data\")\n",
        "            print(f\"   For final model training, use these parameters with the FULL dataset!\")\n",
        "\n",
        "        return {\n",
        "            'best_params': self.best_params,\n",
        "            'best_val_auc': self.best_val_auc,\n",
        "            'best_test_auc': self.best_test_auc,\n",
        "            'best_test_logloss': self.best_test_logloss,\n",
        "            'trials': len(self.results),\n",
        "            'csv_path': self.csv_path,\n",
        "            'params_file': best_params_file,\n",
        "            'subsample_fraction': self.subsample_fraction,\n",
        "            'optuna_study': self.optuna_study\n",
        "        }\n",
        "\n",
        "    def get_best_params(self):\n",
        "        \"\"\"Return best parameters dari tuning\"\"\"\n",
        "        return self.best_params\n",
        "\n",
        "print(f\"HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA LOADED!\")"
      ],
      "metadata": {
        "id": "xrOdRWwblxnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e175cde-b788-4b47-8ab8-842546a073a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA\n",
            "============================================================\n",
            "HYPERPARAMETER TUNING FRAMEWORK WITH OPTUNA LOADED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 6G: RUN HYPERPARAMETER TUNING WITH OPTUNA\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RUN HYPERPARAMETER TUNING WITH OPTUNA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup environment\n",
        "os.makedirs('tuning_results', exist_ok=True)\n",
        "os.makedirs('tuning_results/din_dice', exist_ok=True)\n",
        "os.makedirs('tuning_results/din_prelu', exist_ok=True)\n",
        "os.makedirs('tuning_results/deepfm', exist_ok=True)\n",
        "os.makedirs('tuning_results/baseline', exist_ok=True)\n",
        "\n",
        "# Current settings\n",
        "CURRENT_USER = \"Muhammad Sultan Nurrochman\"\n",
        "CURRENT_TIME = \"-\"\n",
        "N_TRIALS = 8  # Number of trials per model\n",
        "SUBSAMPLE_FRACTION = 0.1  # Use 20% data for tuning\n",
        "\n",
        "print(f\"Environment setup completed!\")\n",
        "print(f\"Using {SUBSAMPLE_FRACTION*100:.1f}% of training data for tuning\")\n",
        "print(f\"Running {N_TRIALS} trials for each model\")\n"
      ],
      "metadata": {
        "id": "_PMEhUdomc1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d780904-119f-4843-c939-05a2fcd6f2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RUN HYPERPARAMETER TUNING WITH OPTUNA\n",
            "============================================================\n",
            "Environment setup completed!\n",
            "Using 10.0% of training data for tuning\n",
            "Running 8 trials for each model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DIN-DICE HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup DIN-DICE tuner with Optuna\n",
        "din_tuner = ModelTuner(\n",
        "    model_type='DIN-DICE',\n",
        "    model_data=model_data,\n",
        "    subsample_fraction=SUBSAMPLE_FRACTION,\n",
        "    save_dir='tuning_results/din_dice',\n",
        "    current_user=CURRENT_USER,\n",
        "    current_time=CURRENT_TIME\n",
        ")\n",
        "\n",
        "# Run tuning\n",
        "din_tuning_results = din_tuner.run_tuning(n_trials=N_TRIALS)\n",
        "\n",
        "# Get best parameters\n",
        "din_best_params = din_tuning_results['best_params']\n",
        "\n",
        "print(\"\\nDIN-DICE Best Parameters:\")\n",
        "for param, value in din_best_params.items():\n",
        "    print(f\"    {param}: {value}\")"
      ],
      "metadata": {
        "id": "J1d7glDcs7UL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e8279c-c173-4749-eb86-44f0fcbdb007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIN-DICE HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "Creating 10.0% subsample of training data...\n",
            "  Original training samples: 21,246,368\n",
            "  Subsampled training size: 2,124,636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 16:25:30,368] A new study created in memory with name: no-name-ec547f37-13e0-43c5-8e62-7f8066614ffd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original positive rate: 0.0515\n",
            "  Subsampled positive rate: 0.0514\n",
            "âœ… Subsample created successfully\n",
            "\n",
            "================================================================================\n",
            "STARTING HYPERPARAMETER TUNING FOR DIN-DICE (USING 10.0% DATA) USING OPTUNA\n",
            "Number of trials: 8\n",
            "User: Muhammad Sultan Nurrochman\n",
            "Time: -\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 1e-05, 'l2_dense': 2e-05, 'dice_alpha_init': 0.4, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8927, AUC: 0.4365\n",
            "  Val   - Loss: 0.7565, AUC: 0.3990\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8469, AUC: 0.4534\n",
            "  Val   - Loss: 0.7329, AUC: 0.4186\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.8144, AUC: 0.4703\n",
            "  Val   - Loss: 0.7076, AUC: 0.4412\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7900, AUC: 0.4854\n",
            "  Val   - Loss: 0.6893, AUC: 0.4697\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7718, AUC: 0.4972\n",
            "  Val   - Loss: 0.6765, AUC: 0.5041\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7565, AUC: 0.5044\n",
            "  Val   - Loss: 0.6657, AUC: 0.5362\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7428, AUC: 0.5124\n",
            "  Val   - Loss: 0.6567, AUC: 0.5586\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.7310, AUC: 0.5161\n",
            "  Val   - Loss: 0.6479, AUC: 0.5762\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 16:37:44,592] Trial 0 finished with value: 0.5762196779251099 and parameters: {'hidden_units_idx': 0, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 1e-05, 'l2_dense': 2e-05, 'dice_alpha_init': 0.4, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2}. Best is trial 0 with value: 0.5762196779251099.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.5762\n",
            "Test AUC: 0.5757\n",
            "Test Log Loss: 0.6345\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.5762\n",
            "Test AUC: 0.5757\n",
            "Test Log Loss: 0.6345\n",
            "Training Time: 733.9s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.6113, AUC: 0.5387\n",
            "  Val   - Loss: 0.4183, AUC: 0.6562\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.4216, AUC: 0.5486\n",
            "  Val   - Loss: 0.3630, AUC: 0.6568\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.3868, AUC: 0.5723\n",
            "  Val   - Loss: 0.3618, AUC: 0.6710\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.3764, AUC: 0.5930\n",
            "  Val   - Loss: 0.3611, AUC: 0.6777\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.3706, AUC: 0.6153\n",
            "  Val   - Loss: 0.3606, AUC: 0.6848\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.3659, AUC: 0.6602\n",
            "  Val   - Loss: 0.3599, AUC: 0.6935\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.3579, AUC: 0.7789\n",
            "  Val   - Loss: 0.3632, AUC: 0.6610\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.3439, AUC: 0.8794\n",
            "  Val   - Loss: 0.3701, AUC: 0.6366\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 17:25:56,496] Trial 1 finished with value: 0.6934754848480225 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.15}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6935\n",
            "Test AUC: 0.6936\n",
            "Test Log Loss: 0.2209\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6935\n",
            "Test AUC: 0.6936\n",
            "Test Log Loss: 0.2209\n",
            "Training Time: 2891.6s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 2e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 2e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.8, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.1, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8726, AUC: 0.4916\n",
            "  Val   - Loss: 0.6508, AUC: 0.4875\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8335, AUC: 0.5007\n",
            "  Val   - Loss: 0.6340, AUC: 0.5265\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.8029, AUC: 0.5072\n",
            "  Val   - Loss: 0.6176, AUC: 0.5607\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7767, AUC: 0.5148\n",
            "  Val   - Loss: 0.6050, AUC: 0.5879\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7537, AUC: 0.5186\n",
            "  Val   - Loss: 0.5924, AUC: 0.6076\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7329, AUC: 0.5224\n",
            "  Val   - Loss: 0.5803, AUC: 0.6209\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7137, AUC: 0.5240\n",
            "  Val   - Loss: 0.5697, AUC: 0.6296\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6956, AUC: 0.5253\n",
            "  Val   - Loss: 0.5588, AUC: 0.6356\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 17:38:20,750] Trial 2 finished with value: 0.6356160640716553 and parameters: {'hidden_units_idx': 0, 'learning_rate': 2e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 2e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.8, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.1}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6356\n",
            "Test AUC: 0.6345\n",
            "Test Log Loss: 0.5416\n",
            "Training Time: 743.9s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 2e-05, 'batch_size': 2048, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.45, 'dice_beta_init': 1.2, 'dice_epsilon': 1e-08, 'attention_hidden': 16, 'label_smoothing': 0.15, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8256, AUC: 0.5064\n",
            "  Val   - Loss: 0.6176, AUC: 0.5915\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.7293, AUC: 0.5204\n",
            "  Val   - Loss: 0.5733, AUC: 0.6351\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.6659, AUC: 0.5239\n",
            "  Val   - Loss: 0.5363, AUC: 0.6480\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.6158, AUC: 0.5253\n",
            "  Val   - Loss: 0.5017, AUC: 0.6511\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.5726, AUC: 0.5280\n",
            "  Val   - Loss: 0.4698, AUC: 0.6537\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.5345, AUC: 0.5280\n",
            "  Val   - Loss: 0.4391, AUC: 0.6514\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.5002, AUC: 0.5295\n",
            "  Val   - Loss: 0.4130, AUC: 0.6476\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.4712, AUC: 0.5309\n",
            "  Val   - Loss: 0.3923, AUC: 0.6452\n",
            "  Early stopping triggered!\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 18:26:55,916] Trial 3 finished with value: 0.653675377368927 and parameters: {'hidden_units_idx': 0, 'learning_rate': 2e-05, 'batch_size': 2048, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.45, 'dice_beta_init': 1.2, 'dice_epsilon': 1e-08, 'attention_hidden': 16, 'label_smoothing': 0.15}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6537\n",
            "Test AUC: 0.6546\n",
            "Test Log Loss: 0.4174\n",
            "Training Time: 2914.9s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.5, 'l2_reg': 1e-05, 'l2_dense': 5e-05, 'dice_alpha_init': 0.5, 'dice_beta_init': 2.0, 'dice_epsilon': 1e-10, 'attention_hidden': 8, 'label_smoothing': 0.1, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8469, AUC: 0.5151\n",
            "  Val   - Loss: 0.6468, AUC: 0.5930\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8243, AUC: 0.5219\n",
            "  Val   - Loss: 0.6442, AUC: 0.6226\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.8061, AUC: 0.5247\n",
            "  Val   - Loss: 0.6403, AUC: 0.6402\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7901, AUC: 0.5252\n",
            "  Val   - Loss: 0.6357, AUC: 0.6505\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7757, AUC: 0.5285\n",
            "  Val   - Loss: 0.6304, AUC: 0.6566\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7631, AUC: 0.5274\n",
            "  Val   - Loss: 0.6247, AUC: 0.6608\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7502, AUC: 0.5313\n",
            "  Val   - Loss: 0.6207, AUC: 0.6631\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.7392, AUC: 0.5296\n",
            "  Val   - Loss: 0.6150, AUC: 0.6647\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 18:41:30,405] Trial 4 finished with value: 0.6647292375564575 and parameters: {'hidden_units_idx': 3, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.5, 'l2_reg': 1e-05, 'l2_dense': 5e-05, 'dice_alpha_init': 0.5, 'dice_beta_init': 2.0, 'dice_epsilon': 1e-10, 'attention_hidden': 8, 'label_smoothing': 0.1}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6647\n",
            "Test AUC: 0.6644\n",
            "Test Log Loss: 0.6055\n",
            "Training Time: 874.1s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'dice_alpha_init': 0.4, 'dice_beta_init': 2.0, 'dice_epsilon': 1e-09, 'attention_hidden': 8, 'label_smoothing': 0.15, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8752, AUC: 0.5109\n",
            "  Val   - Loss: 0.7038, AUC: 0.6011\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8377, AUC: 0.5145\n",
            "  Val   - Loss: 0.6842, AUC: 0.6232\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.8067, AUC: 0.5188\n",
            "  Val   - Loss: 0.6655, AUC: 0.6349\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7802, AUC: 0.5185\n",
            "  Val   - Loss: 0.6492, AUC: 0.6412\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7563, AUC: 0.5199\n",
            "  Val   - Loss: 0.6339, AUC: 0.6439\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7350, AUC: 0.5187\n",
            "  Val   - Loss: 0.6199, AUC: 0.6454\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7160, AUC: 0.5181\n",
            "  Val   - Loss: 0.6065, AUC: 0.6459\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6980, AUC: 0.5179\n",
            "  Val   - Loss: 0.5938, AUC: 0.6446\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 19:10:15,756] Trial 5 finished with value: 0.6458544135093689 and parameters: {'hidden_units_idx': 3, 'learning_rate': 1e-05, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'dice_alpha_init': 0.4, 'dice_beta_init': 2.0, 'dice_epsilon': 1e-09, 'attention_hidden': 8, 'label_smoothing': 0.15}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6459\n",
            "Test AUC: 0.6455\n",
            "Test Log Loss: 0.5897\n",
            "Training Time: 1725.0s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 0.0001, 'dice_alpha_init': 0.5, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8787, AUC: 0.5077\n",
            "  Val   - Loss: 0.7243, AUC: 0.5268\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8011, AUC: 0.5187\n",
            "  Val   - Loss: 0.6886, AUC: 0.5653\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.7712, AUC: 0.5279\n",
            "  Val   - Loss: 0.6723, AUC: 0.5975\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7529, AUC: 0.5324\n",
            "  Val   - Loss: 0.6601, AUC: 0.6144\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7373, AUC: 0.5335\n",
            "  Val   - Loss: 0.6512, AUC: 0.6225\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7235, AUC: 0.5348\n",
            "  Val   - Loss: 0.6427, AUC: 0.6288\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.7105, AUC: 0.5350\n",
            "  Val   - Loss: 0.6337, AUC: 0.6347\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6983, AUC: 0.5379\n",
            "  Val   - Loss: 0.6252, AUC: 0.6391\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 19:22:35,018] Trial 6 finished with value: 0.6391257643699646 and parameters: {'hidden_units_idx': 1, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 0.0001, 'dice_alpha_init': 0.5, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6391\n",
            "Test AUC: 0.6383\n",
            "Test Log Loss: 0.6059\n",
            "Training Time: 739.0s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-DICE (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 2e-05, 'dice_alpha_init': 0.3, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.7405, AUC: 0.5109\n",
            "  Val   - Loss: 0.6183, AUC: 0.6400\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.6142, AUC: 0.5174\n",
            "  Val   - Loss: 0.5194, AUC: 0.6426\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.5264, AUC: 0.5220\n",
            "  Val   - Loss: 0.4486, AUC: 0.6549\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.4708, AUC: 0.5334\n",
            "  Val   - Loss: 0.4200, AUC: 0.6580\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.4461, AUC: 0.5482\n",
            "  Val   - Loss: 0.4132, AUC: 0.6625\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.4355, AUC: 0.5629\n",
            "  Val   - Loss: 0.4110, AUC: 0.6652\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.4289, AUC: 0.5789\n",
            "  Val   - Loss: 0.4091, AUC: 0.6669\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.4241, AUC: 0.5901\n",
            "  Val   - Loss: 0.4077, AUC: 0.6684\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 19:51:28,067] Trial 7 finished with value: 0.6684398651123047 and parameters: {'hidden_units_idx': 3, 'learning_rate': 0.0001, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 2e-05, 'dice_alpha_init': 0.3, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.2}. Best is trial 1 with value: 0.6934754848480225.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6684\n",
            "Test AUC: 0.6675\n",
            "Test Log Loss: 0.2457\n",
            "Training Time: 1732.7s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "\n",
            "Optuna Study Statistics:\n",
            "  Best Value: 0.6935\n",
            "  Best Trial: 1\n",
            "\n",
            "Parameter Importances:\n",
            "  dropout_rate: 0.2951\n",
            "  dice_alpha_init: 0.1281\n",
            "  learning_rate: 0.1141\n",
            "  hidden_units_idx: 0.1123\n",
            "  l2_dense: 0.1070\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETED FOR DIN-DICE\n",
            "Total trials: 8\n",
            "Best validation AUC: 0.6935\n",
            "Best test AUC: 0.6936\n",
            "Best test log loss: 0.2209\n",
            "Best parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'dice_alpha_init': 0.35, 'dice_beta_init': 1.0, 'dice_epsilon': 1e-09, 'attention_hidden': 16, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "Total tuning time: 12357.7s\n",
            "Results saved to tuning_results/din_dice/DIN-DICE_tuning_results_20250628_162529.csv\n",
            "================================================================================\n",
            "Best parameters saved to tuning_results/din_dice/DIN-DICE_best_params.json\n",
            "\n",
            "âš ï¸ REMINDER: Tuning used 10.0% of training data\n",
            "   For final model training, use these parameters with the FULL dataset!\n",
            "\n",
            "DIN-DICE Best Parameters:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.4\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    dice_alpha_init: 0.35\n",
            "    dice_beta_init: 1.0\n",
            "    dice_epsilon: 1e-09\n",
            "    attention_hidden: 16\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# DIN-PReLU Hyperparameter Tuning\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DIN-PRELU HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup DIN-PReLU tuner with Optuna\n",
        "din_prelu_tuner = ModelTuner(\n",
        "    model_type='DIN-PReLU',\n",
        "    model_data=model_data,\n",
        "    subsample_fraction=SUBSAMPLE_FRACTION,\n",
        "    save_dir='tuning_results/din_prelu',\n",
        "    current_user=CURRENT_USER,\n",
        "    current_time=CURRENT_TIME\n",
        ")\n",
        "\n",
        "# Run tuning\n",
        "din_prelu_tuning_results = din_prelu_tuner.run_tuning(n_trials=N_TRIALS)\n",
        "\n",
        "# Get best parameters\n",
        "din_prelu_best_params = din_prelu_tuning_results['best_params']\n",
        "\n",
        "print(\"\\nDIN-PReLU Best Parameters:\")\n",
        "for param, value in din_prelu_best_params.items():\n",
        "    print(f\"    {param}: {value}\")"
      ],
      "metadata": {
        "id": "9ls5XDUZtF9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e935486-4f22-45e1-eb2d-cf054221a370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIN-PRELU HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "Creating 10.0% subsample of training data...\n",
            "  Original training samples: 21,246,368\n",
            "  Subsampled training size: 2,124,636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 19:51:30,015] A new study created in memory with name: no-name-7427c5e5-d8cb-41c9-97e2-273d9a87ae6f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original positive rate: 0.0515\n",
            "  Subsampled positive rate: 0.0514\n",
            "âœ… Subsample created successfully\n",
            "\n",
            "================================================================================\n",
            "STARTING HYPERPARAMETER TUNING FOR DIN-PReLU (USING 10.0% DATA) USING OPTUNA\n",
            "Number of trials: 8\n",
            "User: Muhammad Sultan Nurrochman\n",
            "Time: -\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 2e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'prelu_alpha_init': 0.4, 'attention_hidden': 8, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8608, AUC: 0.4992\n",
            "  Val   - Loss: 0.7335, AUC: 0.5325\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8126, AUC: 0.5135\n",
            "  Val   - Loss: 0.7042, AUC: 0.6085\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.7769, AUC: 0.5207\n",
            "  Val   - Loss: 0.6806, AUC: 0.6316\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7483, AUC: 0.5223\n",
            "  Val   - Loss: 0.6592, AUC: 0.6426\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7227, AUC: 0.5262\n",
            "  Val   - Loss: 0.6399, AUC: 0.6495\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.7011, AUC: 0.5284\n",
            "  Val   - Loss: 0.6218, AUC: 0.6528\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.6812, AUC: 0.5298\n",
            "  Val   - Loss: 0.6050, AUC: 0.6569\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6624, AUC: 0.5317\n",
            "  Val   - Loss: 0.5889, AUC: 0.6596\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 20:02:28,333] Trial 0 finished with value: 0.6595548391342163 and parameters: {'hidden_units_idx': 1, 'learning_rate': 2e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'prelu_alpha_init': 0.4, 'attention_hidden': 8, 'label_smoothing': 0.15}. Best is trial 0 with value: 0.6595548391342163.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6596\n",
            "Test AUC: 0.6591\n",
            "Test Log Loss: 0.5680\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6596\n",
            "Test AUC: 0.6591\n",
            "Test Log Loss: 0.5680\n",
            "Training Time: 658.0s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 2e-05, 'l2_dense': 1e-05, 'prelu_alpha_init': 0.2, 'attention_hidden': 16, 'label_smoothing': 0.05, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.7475, AUC: 0.5319\n",
            "  Val   - Loss: 0.6230, AUC: 0.6077\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.6360, AUC: 0.5450\n",
            "  Val   - Loss: 0.5409, AUC: 0.6242\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.5559, AUC: 0.5522\n",
            "  Val   - Loss: 0.4726, AUC: 0.6283\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.4813, AUC: 0.5568\n",
            "  Val   - Loss: 0.4070, AUC: 0.6377\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.4147, AUC: 0.5632\n",
            "  Val   - Loss: 0.3532, AUC: 0.6486\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.3619, AUC: 0.5740\n",
            "  Val   - Loss: 0.3148, AUC: 0.6595\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.3258, AUC: 0.5950\n",
            "  Val   - Loss: 0.2917, AUC: 0.6667\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.3026, AUC: 0.6117\n",
            "  Val   - Loss: 0.2780, AUC: 0.6708\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 20:15:12,053] Trial 1 finished with value: 0.6708238124847412 and parameters: {'hidden_units_idx': 3, 'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 2e-05, 'l2_dense': 1e-05, 'prelu_alpha_init': 0.2, 'attention_hidden': 16, 'label_smoothing': 0.05}. Best is trial 1 with value: 0.6708238124847412.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6708\n",
            "Test AUC: 0.6708\n",
            "Test Log Loss: 0.2321\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6708\n",
            "Test AUC: 0.6708\n",
            "Test Log Loss: 0.2321\n",
            "Training Time: 763.4s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 5e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.3, 'attention_hidden': 16, 'label_smoothing': 0.0, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.7771, AUC: 0.5246\n",
            "  Val   - Loss: 0.6389, AUC: 0.6097\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.6825, AUC: 0.5403\n",
            "  Val   - Loss: 0.5747, AUC: 0.6297\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.6159, AUC: 0.5452\n",
            "  Val   - Loss: 0.5202, AUC: 0.6376\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.5571, AUC: 0.5452\n",
            "  Val   - Loss: 0.4676, AUC: 0.6419\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.5016, AUC: 0.5479\n",
            "  Val   - Loss: 0.4154, AUC: 0.6451\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.4496, AUC: 0.5470\n",
            "  Val   - Loss: 0.3673, AUC: 0.6447\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.4014, AUC: 0.5505\n",
            "  Val   - Loss: 0.3245, AUC: 0.6448\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.3599, AUC: 0.5486\n",
            "  Val   - Loss: 0.2893, AUC: 0.6426\n",
            "  Early stopping triggered!\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 20:26:07,910] Trial 2 finished with value: 0.645082414150238 and parameters: {'hidden_units_idx': 1, 'learning_rate': 5e-05, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.3, 'attention_hidden': 16, 'label_smoothing': 0.0}. Best is trial 1 with value: 0.6708238124847412.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6451\n",
            "Test AUC: 0.6451\n",
            "Test Log Loss: 0.4158\n",
            "Training Time: 655.6s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 5e-05, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.3, 'attention_hidden': 16, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8098, AUC: 0.5157\n",
            "  Val   - Loss: 0.6171, AUC: 0.6263\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.6743, AUC: 0.5257\n",
            "  Val   - Loss: 0.5353, AUC: 0.6347\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.5879, AUC: 0.5307\n",
            "  Val   - Loss: 0.4740, AUC: 0.6318\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.5229, AUC: 0.5327\n",
            "  Val   - Loss: 0.4273, AUC: 0.6285\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.4737, AUC: 0.5351\n",
            "  Val   - Loss: 0.3958, AUC: 0.6309\n",
            "  Early stopping triggered!\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 20:39:54,072] Trial 3 finished with value: 0.6347348690032959 and parameters: {'hidden_units_idx': 1, 'learning_rate': 5e-05, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.3, 'attention_hidden': 16, 'label_smoothing': 0.15}. Best is trial 1 with value: 0.6708238124847412.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6347\n",
            "Test AUC: 0.6339\n",
            "Test Log Loss: 0.5014\n",
            "Training Time: 825.9s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.6040, AUC: 0.5342\n",
            "  Val   - Loss: 0.4119, AUC: 0.6463\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.4171, AUC: 0.5495\n",
            "  Val   - Loss: 0.3624, AUC: 0.6506\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.3865, AUC: 0.5739\n",
            "  Val   - Loss: 0.3612, AUC: 0.6638\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.3767, AUC: 0.5947\n",
            "  Val   - Loss: 0.3604, AUC: 0.6747\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.3707, AUC: 0.6146\n",
            "  Val   - Loss: 0.3599, AUC: 0.6817\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.3663, AUC: 0.6479\n",
            "  Val   - Loss: 0.3594, AUC: 0.6912\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.3595, AUC: 0.7484\n",
            "  Val   - Loss: 0.3620, AUC: 0.6631\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.3455, AUC: 0.8685\n",
            "  Val   - Loss: 0.3692, AUC: 0.6377\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 21:22:19,299] Trial 4 finished with value: 0.6912413239479065 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.15}. Best is trial 4 with value: 0.6912413239479065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6912\n",
            "Test AUC: 0.6913\n",
            "Test Log Loss: 0.2214\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6912\n",
            "Test AUC: 0.6913\n",
            "Test Log Loss: 0.2214\n",
            "Training Time: 2544.9s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.1, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8390, AUC: 0.4891\n",
            "  Val   - Loss: 0.6559, AUC: 0.5174\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.7625, AUC: 0.5158\n",
            "  Val   - Loss: 0.6184, AUC: 0.5803\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.7152, AUC: 0.5255\n",
            "  Val   - Loss: 0.5911, AUC: 0.6096\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.6760, AUC: 0.5331\n",
            "  Val   - Loss: 0.5657, AUC: 0.6223\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.6432, AUC: 0.5330\n",
            "  Val   - Loss: 0.5416, AUC: 0.6294\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.6126, AUC: 0.5384\n",
            "  Val   - Loss: 0.5177, AUC: 0.6344\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.5855, AUC: 0.5372\n",
            "  Val   - Loss: 0.4943, AUC: 0.6380\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.5587, AUC: 0.5387\n",
            "  Val   - Loss: 0.4711, AUC: 0.6392\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 22:04:44,453] Trial 5 finished with value: 0.6392340064048767 and parameters: {'hidden_units_idx': 0, 'learning_rate': 1e-05, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.1}. Best is trial 4 with value: 0.6912413239479065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6392\n",
            "Test AUC: 0.6400\n",
            "Test Log Loss: 0.4396\n",
            "Training Time: 2544.9s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 2e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 16, 'label_smoothing': 0.05, 'hidden_units': [128, 64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.6232, AUC: 0.5327\n",
            "  Val   - Loss: 0.4086, AUC: 0.6213\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.3745, AUC: 0.5419\n",
            "  Val   - Loss: 0.2782, AUC: 0.6390\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.2884, AUC: 0.5832\n",
            "  Val   - Loss: 0.2610, AUC: 0.6608\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.2716, AUC: 0.6219\n",
            "  Val   - Loss: 0.2592, AUC: 0.6789\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.2651, AUC: 0.6526\n",
            "  Val   - Loss: 0.2578, AUC: 0.6891\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.2580, AUC: 0.7220\n",
            "  Val   - Loss: 0.2585, AUC: 0.6811\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.2390, AUC: 0.8490\n",
            "  Val   - Loss: 0.2668, AUC: 0.6487\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.2170, AUC: 0.9164\n",
            "  Val   - Loss: 0.2798, AUC: 0.6301\n",
            "  Early stopping triggered!\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 22:54:34,351] Trial 6 finished with value: 0.6891223192214966 and parameters: {'hidden_units_idx': 3, 'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 2e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 16, 'label_smoothing': 0.05}. Best is trial 4 with value: 0.6912413239479065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6891\n",
            "Test AUC: 0.6883\n",
            "Test Log Loss: 0.1973\n",
            "Training Time: 2989.6s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DIN-PReLU (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 4096, 'dropout_rate': 0.4, 'l2_reg': 0.0001, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.0, 'hidden_units': [64, 32]}\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/8\n",
            "  Train - Loss: 0.8531, AUC: 0.4958\n",
            "  Val   - Loss: 0.6664, AUC: 0.5177\n",
            "\n",
            "Epoch 2/8\n",
            "  Train - Loss: 0.8047, AUC: 0.5138\n",
            "  Val   - Loss: 0.6425, AUC: 0.5711\n",
            "\n",
            "Epoch 3/8\n",
            "  Train - Loss: 0.7707, AUC: 0.5266\n",
            "  Val   - Loss: 0.6247, AUC: 0.6021\n",
            "\n",
            "Epoch 4/8\n",
            "  Train - Loss: 0.7426, AUC: 0.5303\n",
            "  Val   - Loss: 0.6092, AUC: 0.6186\n",
            "\n",
            "Epoch 5/8\n",
            "  Train - Loss: 0.7176, AUC: 0.5342\n",
            "  Val   - Loss: 0.5950, AUC: 0.6280\n",
            "\n",
            "Epoch 6/8\n",
            "  Train - Loss: 0.6943, AUC: 0.5380\n",
            "  Val   - Loss: 0.5808, AUC: 0.6344\n",
            "\n",
            "Epoch 7/8\n",
            "  Train - Loss: 0.6728, AUC: 0.5399\n",
            "  Val   - Loss: 0.5671, AUC: 0.6388\n",
            "\n",
            "Epoch 8/8\n",
            "  Train - Loss: 0.6527, AUC: 0.5395\n",
            "  Val   - Loss: 0.5541, AUC: 0.6418\n",
            "  Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:15:53,127] Trial 7 finished with value: 0.6418236494064331 and parameters: {'hidden_units_idx': 0, 'learning_rate': 1e-05, 'batch_size': 4096, 'dropout_rate': 0.4, 'l2_reg': 0.0001, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.0}. Best is trial 4 with value: 0.6912413239479065.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6418\n",
            "Test AUC: 0.6411\n",
            "Test Log Loss: 0.5543\n",
            "Training Time: 1278.5s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "\n",
            "Optuna Study Statistics:\n",
            "  Best Value: 0.6912\n",
            "  Best Trial: 4\n",
            "\n",
            "Parameter Importances:\n",
            "  learning_rate: 0.4850\n",
            "  l2_reg: 0.1246\n",
            "  l2_dense: 0.1136\n",
            "  dropout_rate: 0.0852\n",
            "  batch_size: 0.0584\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETED FOR DIN-PReLU\n",
            "Total trials: 8\n",
            "Best validation AUC: 0.6912\n",
            "Best test AUC: 0.6913\n",
            "Best test log loss: 0.2214\n",
            "Best parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 5e-05, 'l2_dense': 5e-05, 'prelu_alpha_init': 0.35, 'attention_hidden': 8, 'label_smoothing': 0.15, 'hidden_units': [128, 64]}\n",
            "Total tuning time: 12263.1s\n",
            "Results saved to tuning_results/din_prelu/DIN-PReLU_tuning_results_20250628_195128.csv\n",
            "================================================================================\n",
            "Best parameters saved to tuning_results/din_prelu/DIN-PReLU_best_params.json\n",
            "\n",
            "âš ï¸ REMINDER: Tuning used 10.0% of training data\n",
            "   For final model training, use these parameters with the FULL dataset!\n",
            "\n",
            "DIN-PReLU Best Parameters:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 5e-05\n",
            "    l2_dense: 5e-05\n",
            "    prelu_alpha_init: 0.35\n",
            "    attention_hidden: 8\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# DeepFM Hyperparameter Tuning\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DEEPFM HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup DeepFM tuner with Optuna\n",
        "deepfm_tuner = ModelTuner(\n",
        "    model_type='DeepFM',\n",
        "    model_data=model_data,\n",
        "    subsample_fraction=SUBSAMPLE_FRACTION,\n",
        "    save_dir='tuning_results/deepfm',\n",
        "    current_user=CURRENT_USER,\n",
        "    current_time=CURRENT_TIME\n",
        ")\n",
        "\n",
        "# Run tuning\n",
        "deepfm_tuning_results = deepfm_tuner.run_tuning(n_trials=N_TRIALS)\n",
        "\n",
        "# Get best parameters\n",
        "deepfm_best_params = deepfm_tuning_results['best_params']\n",
        "\n",
        "print(\"\\nDeepFM Best Parameters:\")\n",
        "for param, value in deepfm_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n"
      ],
      "metadata": {
        "id": "fSyzxslHtPJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb969b6-044b-4bc7-9b35-0c4e49a6f2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DEEPFM HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "Creating 10.0% subsample of training data...\n",
            "  Original training samples: 21,246,368\n",
            "  Subsampled training size: 2,124,636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:15:54,484] A new study created in memory with name: no-name-0b64cd82-485c-4e9f-8d59-20e217cad112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original positive rate: 0.0515\n",
            "  Subsampled positive rate: 0.0514\n",
            "âœ… Subsample created successfully\n",
            "\n",
            "================================================================================\n",
            "STARTING HYPERPARAMETER TUNING FOR DeepFM (USING 10.0% DATA) USING OPTUNA\n",
            "Number of trials: 8\n",
            "User: Muhammad Sultan Nurrochman\n",
            "Time: -\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.001, 'batch_size': 2048, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 0.001, 'hidden_units': [256, 128, 64], 'label_smoothing': 0.0}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 26ms/step - auc: 0.5646 - loss: 0.6211 - val_auc: 0.6797 - val_loss: 0.1951\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6774 - loss: 0.1958 - val_auc: 0.6886 - val_loss: 0.1916\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6844 - loss: 0.1935 - val_auc: 0.6896 - val_loss: 0.1911\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6843 - loss: 0.1932 - val_auc: 0.6898 - val_loss: 0.1904\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6850 - loss: 0.1927 - val_auc: 0.6895 - val_loss: 0.1906\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6847 - loss: 0.1926 - val_auc: 0.6898 - val_loss: 0.1903\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6853 - loss: 0.1923 - val_auc: 0.6903 - val_loss: 0.1897\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6854 - loss: 0.1918 - val_auc: 0.6898 - val_loss: 0.1897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:26:11,231] Trial 0 finished with value: 0.6903295516967773 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.001, 'batch_size': 2048, 'dropout_rate': 0.6, 'l2_reg': 1e-05, 'l2_dense': 0.001, 'label_smoothing': 0.0}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6903\n",
            "Test AUC: 0.6895\n",
            "Test Log Loss: 0.1888\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6903\n",
            "Test AUC: 0.6895\n",
            "Test Log Loss: 0.1888\n",
            "Training Time: 616.6s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'hidden_units': [128, 64, 32], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - auc: 0.4672 - loss: 4.7975 - val_auc: 0.4886 - val_loss: 1.7899\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5189 - loss: 1.4786 - val_auc: 0.5683 - val_loss: 0.7377\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5355 - loss: 0.7108 - val_auc: 0.5901 - val_loss: 0.5122\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5458 - loss: 0.5267 - val_auc: 0.5953 - val_loss: 0.4353\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5581 - loss: 0.4533 - val_auc: 0.5958 - val_loss: 0.3904\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - auc: 0.5725 - loss: 0.4091 - val_auc: 0.5952 - val_loss: 0.3622\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5809 - loss: 0.3822 - val_auc: 0.5974 - val_loss: 0.3464\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5938 - loss: 0.3636 - val_auc: 0.6012 - val_loss: 0.3372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:34:41,608] Trial 1 finished with value: 0.6011937260627747 and parameters: {'hidden_units_idx': 0, 'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'label_smoothing': 0.1}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6012\n",
            "Test AUC: 0.6014\n",
            "Test Log Loss: 0.2375\n",
            "Training Time: 510.3s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'hidden_units': [256, 128, 64], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - auc: 0.5143 - loss: 6.1584 - val_auc: 0.5332 - val_loss: 5.6777\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5204 - loss: 5.4161 - val_auc: 0.5457 - val_loss: 4.9653\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5252 - loss: 4.7623 - val_auc: 0.5545 - val_loss: 4.3572\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5279 - loss: 4.1906 - val_auc: 0.5618 - val_loss: 3.8277\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5329 - loss: 3.6882 - val_auc: 0.5683 - val_loss: 3.3642\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5341 - loss: 3.2471 - val_auc: 0.5734 - val_loss: 2.9575\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5330 - loss: 2.8615 - val_auc: 0.5773 - val_loss: 2.6009\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5367 - loss: 2.5221 - val_auc: 0.5798 - val_loss: 2.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:43:15,265] Trial 2 finished with value: 0.5798419713973999 and parameters: {'hidden_units_idx': 1, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.6, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'label_smoothing': 0.1}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.5798\n",
            "Test AUC: 0.5791\n",
            "Test Log Loss: 0.7592\n",
            "Training Time: 513.6s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 5e-05, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'hidden_units': [64, 32, 16], 'label_smoothing': 0.05}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - auc: 0.5625 - loss: 1.2270 - val_auc: 0.6196 - val_loss: 0.6489\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5693 - loss: 0.6894 - val_auc: 0.6272 - val_loss: 0.4758\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5859 - loss: 0.4974 - val_auc: 0.6331 - val_loss: 0.3727\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6156 - loss: 0.3883 - val_auc: 0.6391 - val_loss: 0.3200\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6557 - loss: 0.3301 - val_auc: 0.6479 - val_loss: 0.2976\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.7015 - loss: 0.3013 - val_auc: 0.6571 - val_loss: 0.2885\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.7408 - loss: 0.2866 - val_auc: 0.6646 - val_loss: 0.2840\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.7779 - loss: 0.2766 - val_auc: 0.6684 - val_loss: 0.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-28 23:53:31,029] Trial 3 finished with value: 0.6684173941612244 and parameters: {'hidden_units_idx': 2, 'learning_rate': 5e-05, 'batch_size': 2048, 'dropout_rate': 0.4, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'label_smoothing': 0.05}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6684\n",
            "Test AUC: 0.6702\n",
            "Test Log Loss: 0.2002\n",
            "Training Time: 615.7s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.5, 'l2_reg': 0.001, 'l2_dense': 1e-05, 'hidden_units': [64, 32, 16], 'label_smoothing': 0.2}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - auc: 0.4945 - loss: 20.6317 - val_auc: 0.5424 - val_loss: 0.5651\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5241 - loss: 0.5868 - val_auc: 0.5588 - val_loss: 0.4477\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5396 - loss: 0.4783 - val_auc: 0.5743 - val_loss: 0.4193\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5597 - loss: 0.4420 - val_auc: 0.6027 - val_loss: 0.4128\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.5857 - loss: 0.4274 - val_auc: 0.6321 - val_loss: 0.4092\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6086 - loss: 0.4189 - val_auc: 0.6572 - val_loss: 0.4071\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6295 - loss: 0.4134 - val_auc: 0.6726 - val_loss: 0.4060\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6453 - loss: 0.4101 - val_auc: 0.6804 - val_loss: 0.4052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:03:49,972] Trial 4 finished with value: 0.6803634762763977 and parameters: {'hidden_units_idx': 2, 'learning_rate': 0.0001, 'batch_size': 2048, 'dropout_rate': 0.5, 'l2_reg': 0.001, 'l2_dense': 1e-05, 'label_smoothing': 0.2}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6804\n",
            "Test AUC: 0.6795\n",
            "Test Log Loss: 0.2401\n",
            "Training Time: 618.8s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'hidden_units': [128, 64, 32], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - auc: 0.4956 - loss: 1.4355 - val_auc: 0.4993 - val_loss: 0.8658\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5046 - loss: 0.9645 - val_auc: 0.5127 - val_loss: 0.6356\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5184 - loss: 0.7176 - val_auc: 0.5317 - val_loss: 0.5142\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5395 - loss: 0.5788 - val_auc: 0.5466 - val_loss: 0.4428\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5648 - loss: 0.4931 - val_auc: 0.5580 - val_loss: 0.4019\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.5915 - loss: 0.4405 - val_auc: 0.5653 - val_loss: 0.3791\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.6227 - loss: 0.4059 - val_auc: 0.5740 - val_loss: 0.3661\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - auc: 0.6543 - loss: 0.3838 - val_auc: 0.5825 - val_loss: 0.3590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:12:23,139] Trial 5 finished with value: 0.5824745297431946 and parameters: {'hidden_units_idx': 0, 'learning_rate': 0.0001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 1e-05, 'label_smoothing': 0.1}. Best is trial 0 with value: 0.6903295516967773.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.5825\n",
            "Test AUC: 0.5833\n",
            "Test Log Loss: 0.2357\n",
            "Training Time: 513.1s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.5, 'l2_reg': 0.0001, 'l2_dense': 0.001, 'hidden_units': [256, 128, 64], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step - auc: 0.5341 - loss: 2.0654 - val_auc: 0.5674 - val_loss: 0.3886\n",
            "Epoch 2/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6180 - loss: 0.3691 - val_auc: 0.6188 - val_loss: 0.3322\n",
            "Epoch 3/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6506 - loss: 0.3302 - val_auc: 0.6663 - val_loss: 0.3199\n",
            "Epoch 4/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6625 - loss: 0.3224 - val_auc: 0.6689 - val_loss: 0.3172\n",
            "Epoch 5/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6708 - loss: 0.3176 - val_auc: 0.6870 - val_loss: 0.3128\n",
            "Epoch 6/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6826 - loss: 0.3136 - val_auc: 0.6897 - val_loss: 0.3114\n",
            "Epoch 7/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6866 - loss: 0.3124 - val_auc: 0.6905 - val_loss: 0.3109\n",
            "Epoch 8/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6876 - loss: 0.3120 - val_auc: 0.6911 - val_loss: 0.3107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:21:35,311] Trial 6 finished with value: 0.6910551190376282 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.5, 'l2_reg': 0.0001, 'l2_dense': 0.001, 'label_smoothing': 0.1}. Best is trial 6 with value: 0.6910551190376282.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6911\n",
            "Test AUC: 0.6903\n",
            "Test Log Loss: 0.2074\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6911\n",
            "Test AUC: 0.6903\n",
            "Test Log Loss: 0.2074\n",
            "Training Time: 552.1s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR DeepFM (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'hidden_units': [64, 32, 16], 'label_smoothing': 0.05}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 25ms/step - auc: 0.5420 - loss: 6.8381 - val_auc: 0.6411 - val_loss: 0.2732\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6306 - loss: 0.2793 - val_auc: 0.6702 - val_loss: 0.2654\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6615 - loss: 0.2680 - val_auc: 0.6829 - val_loss: 0.2614\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6780 - loss: 0.2629 - val_auc: 0.6881 - val_loss: 0.2588\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6846 - loss: 0.2601 - val_auc: 0.6902 - val_loss: 0.2570\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6870 - loss: 0.2583 - val_auc: 0.6912 - val_loss: 0.2559\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6883 - loss: 0.2572 - val_auc: 0.6914 - val_loss: 0.2553\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - auc: 0.6889 - loss: 0.2566 - val_auc: 0.6914 - val_loss: 0.2550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:31:57,888] Trial 7 finished with value: 0.6914399266242981 and parameters: {'hidden_units_idx': 2, 'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'label_smoothing': 0.05}. Best is trial 7 with value: 0.6914399266242981.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6914\n",
            "Test AUC: 0.6907\n",
            "Test Log Loss: 0.1957\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6914\n",
            "Test AUC: 0.6907\n",
            "Test Log Loss: 0.1957\n",
            "Training Time: 622.5s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "\n",
            "Optuna Study Statistics:\n",
            "  Best Value: 0.6914\n",
            "  Best Trial: 7\n",
            "\n",
            "Parameter Importances:\n",
            "  batch_size: 0.5990\n",
            "  hidden_units_idx: 0.1240\n",
            "  label_smoothing: 0.1075\n",
            "  dropout_rate: 0.0522\n",
            "  learning_rate: 0.0504\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETED FOR DeepFM\n",
            "Total trials: 8\n",
            "Best validation AUC: 0.6914\n",
            "Best test AUC: 0.6907\n",
            "Best test log loss: 0.1957\n",
            "Best parameters: {'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'label_smoothing': 0.05, 'hidden_units': [64, 32, 16]}\n",
            "Total tuning time: 4563.4s\n",
            "Results saved to tuning_results/deepfm/DeepFM_tuning_results_20250628_231553.csv\n",
            "================================================================================\n",
            "Best parameters saved to tuning_results/deepfm/DeepFM_best_params.json\n",
            "\n",
            "âš ï¸ REMINDER: Tuning used 10.0% of training data\n",
            "   For final model training, use these parameters with the FULL dataset!\n",
            "\n",
            "DeepFM Best Parameters:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 0.001\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.05\n",
            "    hidden_units: [64, 32, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# Baseline Hyperparameter Tuning\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BASELINE HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Setup Baseline tuner with Optuna\n",
        "baseline_tuner = ModelTuner(\n",
        "    model_type='Baseline',\n",
        "    model_data=model_data,\n",
        "    subsample_fraction=SUBSAMPLE_FRACTION,\n",
        "    save_dir='tuning_results/baseline',\n",
        "    current_user=CURRENT_USER,\n",
        "    current_time=CURRENT_TIME\n",
        ")\n",
        "\n",
        "# Run tuning\n",
        "baseline_tuning_results = baseline_tuner.run_tuning(n_trials=N_TRIALS)\n",
        "\n",
        "# Get best parameters\n",
        "baseline_best_params = baseline_tuning_results['best_params']\n",
        "\n",
        "print(\"\\nBaseline Best Parameters:\")\n",
        "for param, value in baseline_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n"
      ],
      "metadata": {
        "id": "jxvsNeO9tXrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d3ae15-365d-4dda-e256-ee77ecfa29b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BASELINE HYPERPARAMETER TUNING\n",
            "============================================================\n",
            "Creating 10.0% subsample of training data...\n",
            "  Original training samples: 21,246,368\n",
            "  Subsampled training size: 2,124,636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:31:59,263] A new study created in memory with name: no-name-654c4d57-1475-4713-8bb7-fe5b800a81da\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original positive rate: 0.0515\n",
            "  Subsampled positive rate: 0.0514\n",
            "âœ… Subsample created successfully\n",
            "\n",
            "================================================================================\n",
            "STARTING HYPERPARAMETER TUNING FOR Baseline (USING 10.0% DATA) USING OPTUNA\n",
            "Number of trials: 8\n",
            "User: Muhammad Sultan Nurrochman\n",
            "Time: -\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'hidden_units': [128, 64], 'label_smoothing': 0.2}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - auc: 0.5005 - loss: 1.4148 - val_auc: 0.5307 - val_loss: 1.2355\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5051 - loss: 1.3484 - val_auc: 0.5549 - val_loss: 1.1765\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5088 - loss: 1.2843 - val_auc: 0.5730 - val_loss: 1.1213\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5111 - loss: 1.2256 - val_auc: 0.5855 - val_loss: 1.0712\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5127 - loss: 1.1707 - val_auc: 0.5947 - val_loss: 1.0252\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5129 - loss: 1.1215 - val_auc: 0.6012 - val_loss: 0.9833\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5121 - loss: 1.0755 - val_auc: 0.6068 - val_loss: 0.9441\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5158 - loss: 1.0327 - val_auc: 0.6110 - val_loss: 0.9088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:40:00,089] Trial 0 finished with value: 0.6109569668769836 and parameters: {'hidden_units_idx': 0, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'label_smoothing': 0.2}. Best is trial 0 with value: 0.6109569668769836.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6110\n",
            "Test AUC: 0.6110\n",
            "Test Log Loss: 0.6576\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6110\n",
            "Test AUC: 0.6110\n",
            "Test Log Loss: 0.6576\n",
            "Training Time: 480.8s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 0.0001, 'l2_dense': 0.001, 'hidden_units': [256, 128], 'label_smoothing': 0.1}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - auc: 0.5294 - loss: 1.9081 - val_auc: 0.6529 - val_loss: 0.3440\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6435 - loss: 0.3498 - val_auc: 0.6831 - val_loss: 0.3196\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6623 - loss: 0.3217 - val_auc: 0.6896 - val_loss: 0.3131\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6711 - loss: 0.3141 - val_auc: 0.6904 - val_loss: 0.3114\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6717 - loss: 0.3133 - val_auc: 0.6907 - val_loss: 0.3111\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6715 - loss: 0.3132 - val_auc: 0.6907 - val_loss: 0.3110\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6707 - loss: 0.3131 - val_auc: 0.6908 - val_loss: 0.3110\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6714 - loss: 0.3131 - val_auc: 0.6902 - val_loss: 0.3111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:48:00,852] Trial 1 finished with value: 0.6907510757446289 and parameters: {'hidden_units_idx': 2, 'learning_rate': 0.001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 0.0001, 'l2_dense': 0.001, 'label_smoothing': 0.1}. Best is trial 1 with value: 0.6907510757446289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6908\n",
            "Test AUC: 0.6900\n",
            "Test Log Loss: 0.2087\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6908\n",
            "Test AUC: 0.6900\n",
            "Test Log Loss: 0.2087\n",
            "Training Time: 480.7s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.5, 'l2_reg': 0.001, 'l2_dense': 0.001, 'hidden_units': [256, 128], 'label_smoothing': 0.2}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - auc: 0.5229 - loss: 52.2190 - val_auc: 0.5721 - val_loss: 46.2997\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5248 - loss: 44.7743 - val_auc: 0.5881 - val_loss: 39.6613\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5255 - loss: 38.3270 - val_auc: 0.5953 - val_loss: 33.8798\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5267 - loss: 32.7282 - val_auc: 0.5998 - val_loss: 28.8516\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5283 - loss: 27.8619 - val_auc: 0.6027 - val_loss: 24.4808\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5292 - loss: 23.6318 - val_auc: 0.6055 - val_loss: 20.6844\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5287 - loss: 19.9599 - val_auc: 0.6071 - val_loss: 17.3945\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.5280 - loss: 16.7789 - val_auc: 0.6094 - val_loss: 14.5504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 00:56:01,879] Trial 2 finished with value: 0.6093747615814209 and parameters: {'hidden_units_idx': 2, 'learning_rate': 1e-05, 'batch_size': 8192, 'dropout_rate': 0.5, 'l2_reg': 0.001, 'l2_dense': 0.001, 'label_smoothing': 0.2}. Best is trial 1 with value: 0.6907510757446289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6094\n",
            "Test AUC: 0.6093\n",
            "Test Log Loss: 0.5560\n",
            "Training Time: 481.0s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 0.001, 'l2_dense': 0.001, 'hidden_units': [128, 64], 'label_smoothing': 0.05}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - auc: 0.5223 - loss: 11.0280 - val_auc: 0.5405 - val_loss: 0.2960\n",
            "Epoch 2/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6158 - loss: 0.3006 - val_auc: 0.6798 - val_loss: 0.2692\n",
            "Epoch 3/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6542 - loss: 0.2708 - val_auc: 0.6869 - val_loss: 0.2622\n",
            "Epoch 4/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6584 - loss: 0.2632 - val_auc: 0.6904 - val_loss: 0.2582\n",
            "Epoch 5/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - auc: 0.6628 - loss: 0.2612 - val_auc: 0.6902 - val_loss: 0.2578\n",
            "Epoch 6/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - auc: 0.6643 - loss: 0.2606 - val_auc: 0.6906 - val_loss: 0.2573\n",
            "Epoch 7/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - auc: 0.6656 - loss: 0.2603 - val_auc: 0.6902 - val_loss: 0.2571\n",
            "Epoch 8/8\n",
            "\u001b[1m260/260\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - auc: 0.6663 - loss: 0.2601 - val_auc: 0.6903 - val_loss: 0.2568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:04:03,199] Trial 3 finished with value: 0.6905850172042847 and parameters: {'hidden_units_idx': 0, 'learning_rate': 0.001, 'batch_size': 8192, 'dropout_rate': 0.7, 'l2_reg': 0.001, 'l2_dense': 0.001, 'label_smoothing': 0.05}. Best is trial 1 with value: 0.6907510757446289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6906\n",
            "Test AUC: 0.6898\n",
            "Test Log Loss: 0.1972\n",
            "Training Time: 481.3s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'hidden_units': [64, 32], 'label_smoothing': 0.15}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - auc: 0.5189 - loss: 11.0976 - val_auc: 0.5885 - val_loss: 0.3835\n",
            "Epoch 2/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.5549 - loss: 0.3966 - val_auc: 0.6201 - val_loss: 0.3743\n",
            "Epoch 3/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.5974 - loss: 0.3817 - val_auc: 0.6429 - val_loss: 0.3684\n",
            "Epoch 4/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6237 - loss: 0.3734 - val_auc: 0.6763 - val_loss: 0.3652\n",
            "Epoch 5/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6457 - loss: 0.3680 - val_auc: 0.6870 - val_loss: 0.3633\n",
            "Epoch 6/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6632 - loss: 0.3652 - val_auc: 0.6899 - val_loss: 0.3622\n",
            "Epoch 7/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6730 - loss: 0.3636 - val_auc: 0.6909 - val_loss: 0.3615\n",
            "Epoch 8/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - auc: 0.6777 - loss: 0.3628 - val_auc: 0.6909 - val_loss: 0.3610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:13:02,285] Trial 4 finished with value: 0.690935492515564 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.6, 'l2_reg': 0.001, 'l2_dense': 0.0001, 'label_smoothing': 0.15}. Best is trial 4 with value: 0.690935492515564.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6909\n",
            "Test AUC: 0.6901\n",
            "Test Log Loss: 0.2233\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6909\n",
            "Test AUC: 0.6901\n",
            "Test Log Loss: 0.2233\n",
            "Training Time: 539.0s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 5e-05, 'batch_size': 4096, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.001, 'hidden_units': [64, 32], 'label_smoothing': 0.15}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - auc: 0.5186 - loss: 38.5748 - val_auc: 0.5722 - val_loss: 10.5664\n",
            "Epoch 2/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5339 - loss: 7.3812 - val_auc: 0.5867 - val_loss: 1.8640\n",
            "Epoch 3/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5375 - loss: 1.4504 - val_auc: 0.5959 - val_loss: 0.6561\n",
            "Epoch 4/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5376 - loss: 0.6726 - val_auc: 0.6022 - val_loss: 0.5170\n",
            "Epoch 5/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5413 - loss: 0.5649 - val_auc: 0.6056 - val_loss: 0.4661\n",
            "Epoch 6/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5415 - loss: 0.5114 - val_auc: 0.6113 - val_loss: 0.4313\n",
            "Epoch 7/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5473 - loss: 0.4714 - val_auc: 0.6194 - val_loss: 0.4094\n",
            "Epoch 8/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.5550 - loss: 0.4437 - val_auc: 0.6282 - val_loss: 0.3975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:22:08,626] Trial 5 finished with value: 0.6281977891921997 and parameters: {'hidden_units_idx': 1, 'learning_rate': 5e-05, 'batch_size': 4096, 'dropout_rate': 0.3, 'l2_reg': 0.001, 'l2_dense': 0.001, 'label_smoothing': 0.15}. Best is trial 4 with value: 0.690935492515564.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6282\n",
            "Test AUC: 0.6285\n",
            "Test Log Loss: 0.2501\n",
            "Training Time: 546.3s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'hidden_units': [256, 128], 'label_smoothing': 0.0}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 31ms/step - auc: 0.5398 - loss: 1.6497 - val_auc: 0.6628 - val_loss: 0.1969\n",
            "Epoch 2/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6435 - loss: 0.2059 - val_auc: 0.6863 - val_loss: 0.1913\n",
            "Epoch 3/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - auc: 0.6705 - loss: 0.1951 - val_auc: 0.6889 - val_loss: 0.1900\n",
            "Epoch 4/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6801 - loss: 0.1926 - val_auc: 0.6900 - val_loss: 0.1896\n",
            "Epoch 5/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - auc: 0.6829 - loss: 0.1918 - val_auc: 0.6905 - val_loss: 0.1894\n",
            "Epoch 6/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - auc: 0.6858 - loss: 0.1914 - val_auc: 0.6907 - val_loss: 0.1892\n",
            "Epoch 7/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - auc: 0.6867 - loss: 0.1911 - val_auc: 0.6908 - val_loss: 0.1890\n",
            "Epoch 8/8\n",
            "\u001b[1m519/519\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - auc: 0.6874 - loss: 0.1908 - val_auc: 0.6909 - val_loss: 0.1889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:31:15,375] Trial 6 finished with value: 0.6908634901046753 and parameters: {'hidden_units_idx': 2, 'learning_rate': 0.0005, 'batch_size': 4096, 'dropout_rate': 0.3, 'l2_reg': 0.0001, 'l2_dense': 1e-05, 'label_smoothing': 0.0}. Best is trial 4 with value: 0.690935492515564.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6909\n",
            "Test AUC: 0.6902\n",
            "Test Log Loss: 0.1885\n",
            "Training Time: 546.7s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "================================================================================\n",
            "RUNNING TRIAL FOR Baseline (USING 10.0% DATA)\n",
            "Parameters: {'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'hidden_units': [64, 32], 'label_smoothing': 0.0}\n",
            "================================================================================\n",
            "Epoch 1/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 24ms/step - auc: 0.5193 - loss: 0.6399 - val_auc: 0.6615 - val_loss: 0.2038\n",
            "Epoch 2/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6105 - loss: 0.2095 - val_auc: 0.6815 - val_loss: 0.1939\n",
            "Epoch 3/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6431 - loss: 0.1984 - val_auc: 0.6869 - val_loss: 0.1920\n",
            "Epoch 4/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6645 - loss: 0.1951 - val_auc: 0.6900 - val_loss: 0.1903\n",
            "Epoch 5/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6741 - loss: 0.1933 - val_auc: 0.6907 - val_loss: 0.1891\n",
            "Epoch 6/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6779 - loss: 0.1922 - val_auc: 0.6908 - val_loss: 0.1886\n",
            "Epoch 7/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - auc: 0.6787 - loss: 0.1917 - val_auc: 0.6913 - val_loss: 0.1881\n",
            "Epoch 8/8\n",
            "\u001b[1m1038/1038\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - auc: 0.6793 - loss: 0.1914 - val_auc: 0.6911 - val_loss: 0.1880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-29 01:41:36,038] Trial 7 finished with value: 0.6912732720375061 and parameters: {'hidden_units_idx': 1, 'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'label_smoothing': 0.0}. Best is trial 7 with value: 0.6912732720375061.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… NEW BEST MODEL!\n",
            "Validation AUC: 0.6913\n",
            "Test AUC: 0.6905\n",
            "Test Log Loss: 0.1887\n",
            "\n",
            "TRIAL RESULTS:\n",
            "Validation AUC: 0.6913\n",
            "Test AUC: 0.6905\n",
            "Test Log Loss: 0.1887\n",
            "Training Time: 620.6s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "\n",
            "Optuna Study Statistics:\n",
            "  Best Value: 0.6913\n",
            "  Best Trial: 7\n",
            "\n",
            "Parameter Importances:\n",
            "  learning_rate: 0.4536\n",
            "  label_smoothing: 0.1969\n",
            "  l2_reg: 0.1285\n",
            "  dropout_rate: 0.0942\n",
            "  l2_dense: 0.0505\n",
            "\n",
            "================================================================================\n",
            "TUNING COMPLETED FOR Baseline\n",
            "Total trials: 8\n",
            "Best validation AUC: 0.6913\n",
            "Best test AUC: 0.6905\n",
            "Best test log loss: 0.1887\n",
            "Best parameters: {'learning_rate': 0.0005, 'batch_size': 2048, 'dropout_rate': 0.7, 'l2_reg': 1e-05, 'l2_dense': 0.0001, 'label_smoothing': 0.0, 'hidden_units': [64, 32]}\n",
            "Total tuning time: 4176.8s\n",
            "Results saved to tuning_results/baseline/Baseline_tuning_results_20250629_003158.csv\n",
            "================================================================================\n",
            "Best parameters saved to tuning_results/baseline/Baseline_best_params.json\n",
            "\n",
            "âš ï¸ REMINDER: Tuning used 10.0% of training data\n",
            "   For final model training, use these parameters with the FULL dataset!\n",
            "\n",
            "Baseline Best Parameters:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.7\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.0\n",
            "    hidden_units: [64, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# Save All Best Parameters to One File\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING ALL BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Collect all best parameters\n",
        "all_best_params = {\n",
        "    'DIN-DICE': din_best_params,\n",
        "    'DIN-PReLU': din_prelu_best_params,\n",
        "    'DeepFM': deepfm_best_params,\n",
        "    'Baseline': baseline_best_params\n",
        "}\n",
        "\n",
        "# Save to JSON file\n",
        "with open('tuning_results/all_best_params.json', 'w') as f:\n",
        "    json.dump(all_best_params, f, indent=4)\n",
        "\n",
        "print(f\"All best parameters saved to: tuning_results/all_best_params.json\")\n",
        "\n",
        "# =====================================================================\n",
        "# Plot Comparison of Best Models\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARING MODEL PERFORMANCE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Collect test metrics\n",
        "models = ['DIN-DICE', 'DIN-PReLU', 'DeepFM', 'Baseline']\n",
        "test_aucs = [\n",
        "    din_tuning_results['best_test_auc'],\n",
        "    din_prelu_tuning_results['best_test_auc'],\n",
        "    deepfm_tuning_results['best_test_auc'],\n",
        "    baseline_tuning_results['best_test_auc']\n",
        "]\n",
        "test_loglosses = [\n",
        "    din_tuning_results['best_test_logloss'],\n",
        "    din_prelu_tuning_results['best_test_logloss'],\n",
        "    deepfm_tuning_results['best_test_logloss'],\n",
        "    baseline_tuning_results['best_test_logloss']\n",
        "]\n",
        "\n",
        "# Plot AUC comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(models, test_aucs, color=['lightblue', 'lightgreen', 'coral', 'lightgray'])\n",
        "plt.ylabel('Test AUC')\n",
        "plt.title('Comparison of Model Performance (AUC)')\n",
        "plt.ylim(0.5, 1.0)  # AUC range\n",
        "\n",
        "# Add values above bars\n",
        "for i, v in enumerate(test_aucs):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('tuning_results/model_auc_comparison.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Plot Log Loss comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(models, test_loglosses, color=['lightblue', 'lightgreen', 'coral', 'lightgray'])\n",
        "plt.ylabel('Test Log Loss')\n",
        "plt.title('Comparison of Model Performance (Log Loss)')\n",
        "\n",
        "# Add values above bars\n",
        "for i, v in enumerate(test_loglosses):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('tuning_results/model_logloss_comparison.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Performance comparison plots saved!\")\n",
        "print(f\"Hyperparameter tuning complete for all models!\")"
      ],
      "metadata": {
        "id": "mg0WWU7etegB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "outputId": "398a085c-e164-4891-e3e2-1b8c2d4dba30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SAVING ALL BEST PARAMETERS\n",
            "============================================================\n",
            "All best parameters saved to: tuning_results/all_best_params.json\n",
            "\n",
            "============================================================\n",
            "COMPARING MODEL PERFORMANCE\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance comparison plots saved!\n",
            "Hyperparameter tuning complete for all models!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 7: TRAIN ALL MODELS WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN ALL MODELS WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create best_hyperparameters.json from tuning results\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Option 1: If all_best_params.json exists from previous cell\n",
        "if os.path.exists('tuning_results/all_best_params.json'):\n",
        "    print(\"Loading parameters from combined results file...\")\n",
        "    with open('tuning_results/all_best_params.json', 'r') as f:\n",
        "        best_params = json.load(f)\n",
        "\n",
        "# Option 2: Load individual parameter files\n",
        "else:\n",
        "    print(\"Loading parameters from individual model files...\")\n",
        "    best_params = {}\n",
        "\n",
        "    # DIN-DICE best parameters\n",
        "    din_files = [f for f in os.listdir('tuning_results/din_dice') if f.endswith('_best_params.json')]\n",
        "    if din_files:\n",
        "        with open(f'tuning_results/din_dice/{din_files[0]}', 'r') as f:\n",
        "            best_params['DIN-DICE'] = json.load(f)\n",
        "\n",
        "    # DIN-PReLU best parameters\n",
        "    prelu_files = [f for f in os.listdir('tuning_results/din_prelu') if f.endswith('_best_params.json')]\n",
        "    if prelu_files:\n",
        "        with open(f'tuning_results/din_prelu/{prelu_files[0]}', 'r') as f:\n",
        "            best_params['DIN-PReLU'] = json.load(f)\n",
        "\n",
        "    # DeepFM best parameters\n",
        "    deepfm_files = [f for f in os.listdir('tuning_results/deepfm') if f.endswith('_best_params.json')]\n",
        "    if deepfm_files:\n",
        "        with open(f'tuning_results/deepfm/{deepfm_files[0]}', 'r') as f:\n",
        "            best_params['DeepFM'] = json.load(f)\n",
        "\n",
        "    # Baseline best parameters\n",
        "    baseline_files = [f for f in os.listdir('tuning_results/baseline') if f.endswith('_best_params.json')]\n",
        "    if baseline_files:\n",
        "        with open(f'tuning_results/baseline/{baseline_files[0]}', 'r') as f:\n",
        "            best_params['Baseline'] = json.load(f)\n",
        "\n",
        "    # Save all parameters to a single file for future use\n",
        "    with open('best_hyperparameters.json', 'w') as f:\n",
        "        json.dump(best_params, f, indent=4)\n",
        "\n",
        "    print(\"Combined parameters saved to 'best_hyperparameters.json'\")\n",
        "\n",
        "# Display the loaded parameters\n",
        "print(\"\\nLoaded best parameters:\")\n",
        "for model, params in best_params.items():\n",
        "    print(f\"\\n{model} best parameters:\")\n",
        "    for param, value in params.items():\n",
        "        print(f\"    {param}: {value}\")\n"
      ],
      "metadata": {
        "id": "gEHrIPB9gD3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c0b24a7-ff37-4231-e25a-4ab317dd59bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN ALL MODELS WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Loading parameters from combined results file...\n",
            "\n",
            "Loaded best parameters:\n",
            "\n",
            "DIN-DICE best parameters:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.4\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    dice_alpha_init: 0.35\n",
            "    dice_beta_init: 1.0\n",
            "    dice_epsilon: 1e-09\n",
            "    attention_hidden: 16\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n",
            "\n",
            "DIN-PReLU best parameters:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 5e-05\n",
            "    l2_dense: 5e-05\n",
            "    prelu_alpha_init: 0.35\n",
            "    attention_hidden: 8\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n",
            "\n",
            "DeepFM best parameters:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 0.001\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.05\n",
            "    hidden_units: [64, 32, 16]\n",
            "\n",
            "Baseline best parameters:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.7\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.0\n",
            "    hidden_units: [64, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# =====================================================================\n",
        "# 1. TRAIN DIN-DICE WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN DIN-DICE WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get best parameters\n",
        "din_best_params = best_params['DIN-DICE']\n",
        "\n",
        "print(\"Best Parameters for DIN-DICE:\")\n",
        "for param, value in din_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n",
        "\n",
        "# Create new DIN-DICE model with best parameters\n",
        "def create_optimized_din_dice_model():\n",
        "    \"\"\"Create DIN-DICE model dengan best parameters dari tuning\"\"\"\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = din_best_params['hidden_units']\n",
        "    attention_hidden = din_best_params['attention_hidden']\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = din_best_params['dropout_rate']\n",
        "    l2_reg = din_best_params['l2_reg']\n",
        "    l2_dense = din_best_params['l2_dense']\n",
        "\n",
        "    print(f\"Building DIN-DICE with optimal parameters:\")\n",
        "    print(f\"    Attention hidden: {attention_hidden}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 reg: {l2_reg}\")\n",
        "    print(f\"    L2 dense: {l2_dense}\")\n",
        "    print(f\"    DICE Î±_init: {din_best_params['dice_alpha_init']}\")\n",
        "    print(f\"    DICE Î²_init: {din_best_params['dice_beta_init']}\")\n",
        "    print(f\"    DICE Îµ: {din_best_params['dice_epsilon']}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "    seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    target_item_emb = item_embedding_layer(item_input)\n",
        "    sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "    # DIN Attention mechanism\n",
        "    attention_scores, attended_emb = DINAttention(\n",
        "        hidden_units=attention_hidden,\n",
        "        max_seq_len=max_seq_len,\n",
        "        activation_type='dice',  # Tambahkan parameter ini\n",
        "        dice_alpha_init=din_best_params['dice_alpha_init'],  # Tambahkan parameter ini\n",
        "        dice_beta_init=din_best_params['dice_beta_init'],    # Tambahkan parameter ini\n",
        "        dice_epsilon=din_best_params['dice_epsilon'],        # Tambahkan parameter ini\n",
        "        name='din_attention'\n",
        "    )([sequence_emb, target_item_emb])\n",
        "\n",
        "    # Sequence pooling\n",
        "    pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "        [attention_scores, attended_emb, seq_length_input]\n",
        "    )\n",
        "\n",
        "    # Feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        target_item_emb,\n",
        "        pooled_sequence,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK dengan DICE activation\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "\n",
        "        # DICE activation dengan parameter optimal\n",
        "        dice = DiceActivation(\n",
        "            name=f'dice_{i+1}',\n",
        "            alpha_init=din_best_params['dice_alpha_init'],\n",
        "            beta_init=din_best_params['dice_beta_init'],\n",
        "            epsilon=din_best_params['dice_epsilon']\n",
        "        )\n",
        "        x = dice(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='din_dice_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DIN-DICE model with best parameters\n",
        "print(f\"Creating DIN-DICE model with best parameters...\")\n",
        "din_dice_model = create_optimized_din_dice_model()\n",
        "\n",
        "# Compile DIN-DICE model with best parameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=din_best_params['learning_rate'],\n",
        "    beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
        "    clipnorm=0.5\n",
        ")\n",
        "metrics = [\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "# LOSS dengan label smoothing optimal\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=din_best_params['label_smoothing'])\n",
        "\n",
        "din_dice_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(f\"DIN-DICE model created successfully with optimal parameters!\")\n",
        "print(f\"Model summary:\")\n",
        "print(f\"    Total parameters: {din_dice_model.count_params():,}\")\n",
        "print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in din_dice_model.trainable_weights]):,}\")\n",
        "\n",
        "# Run manual training with best parameters\n",
        "print(f\"\\nStarting DIN-DICE training with best parameters...\")\n",
        "din_dice_results = manual_training_loop_din_dice(\n",
        "    model=din_dice_model,\n",
        "    batch_size=4096,\n",
        "    save_csv=True\n",
        ")"
      ],
      "metadata": {
        "id": "tRn3IiqOm5PX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aedf1634-1231-417d-b419-b06d6bdb0804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN DIN-DICE WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Best Parameters for DIN-DICE:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.4\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    dice_alpha_init: 0.35\n",
            "    dice_beta_init: 1.0\n",
            "    dice_epsilon: 1e-09\n",
            "    attention_hidden: 16\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n",
            "Creating DIN-DICE model with best parameters...\n",
            "Building DIN-DICE with optimal parameters:\n",
            "    Attention hidden: 16\n",
            "    Dropout rate: 0.4\n",
            "    L2 reg: 1e-05\n",
            "    L2 dense: 0.0001\n",
            "    DICE Î±_init: 0.35\n",
            "    DICE Î²_init: 1.0\n",
            "    DICE Îµ: 1e-09\n",
            "DIN-DICE model created successfully with optimal parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,660,002\n",
            "    Trainable parameters: 63,659,618\n",
            "\n",
            "Starting DIN-DICE training with best parameters...\n",
            "STARTING DIN-DICE TRAINING:\n",
            "  Batch size: 4096\n",
            "  Epochs: 15\n",
            "  Early stopping patience: 4\n",
            "Epoch 1/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1974, AUC: 0.6944\n",
            "  Val   Loss: 0.1823, AUC: 0.7321\n",
            "Epoch 2/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1735, AUC: 0.7863\n",
            "  Val   Loss: 0.1845, AUC: 0.7253\n",
            "Epoch 3/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1620, AUC: 0.8305\n",
            "  Val   Loss: 0.1929, AUC: 0.7072\n",
            "Epoch 4/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1471, AUC: 0.8737\n",
            "  Val   Loss: 0.2100, AUC: 0.6883\n",
            "Epoch 5/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1278, AUC: 0.9139\n",
            "  Val   Loss: 0.2445, AUC: 0.6644\n",
            "Early stopping triggered after 5 epochs!\n",
            "\n",
            "Training completed. Evaluating final model on test set...\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Best epoch: 1\n",
            "  Best validation AUC: 0.7321\n",
            "  Test AUC: 0.7325\n",
            "  Test log loss: 0.1834\n",
            "  Training time: 6738.3s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results saved to din_dice_training_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# 2. TRAIN DIN-PRELU WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN DIN-PRELU WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get best parameters\n",
        "din_prelu_best_params = best_params['DIN-PReLU']\n",
        "\n",
        "print(\"Best Parameters for DIN-PReLU:\")\n",
        "for param, value in din_prelu_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n",
        "\n",
        "# Create new DIN-PReLU model with best parameters\n",
        "def create_optimized_din_prelu_model():\n",
        "    \"\"\"Create DIN-PReLU model dengan best parameters dari tuning\"\"\"\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = din_prelu_best_params['hidden_units']\n",
        "    attention_hidden = din_prelu_best_params['attention_hidden']\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = din_prelu_best_params['dropout_rate']\n",
        "    l2_reg = din_prelu_best_params['l2_reg']\n",
        "    l2_dense = din_prelu_best_params['l2_dense']\n",
        "\n",
        "    print(f\"Building DIN-PReLU with optimal parameters:\")\n",
        "    print(f\"    Attention hidden: {attention_hidden}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 reg: {l2_reg}\")\n",
        "    print(f\"    L2 dense: {l2_dense}\")\n",
        "    print(f\"    PReLU Î±_init: {din_prelu_best_params['prelu_alpha_init']}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    sequence_input = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "    seq_length_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    target_item_emb = item_embedding_layer(item_input)\n",
        "    sequence_emb = item_embedding_layer(sequence_input)\n",
        "\n",
        "    # DIN Attention mechanism\n",
        "    attention_scores, attended_emb = DINAttention(\n",
        "        hidden_units=attention_hidden,\n",
        "        max_seq_len=max_seq_len,\n",
        "        activation_type='prelu',  # Tambahkan parameter ini\n",
        "        prelu_alpha_init=din_prelu_best_params['prelu_alpha_init'],  # Tambahkan parameter ini\n",
        "        name='din_attention'\n",
        "    )([sequence_emb, target_item_emb])\n",
        "\n",
        "    # Sequence pooling\n",
        "    pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "        [attention_scores, attended_emb, seq_length_input]\n",
        "    )\n",
        "\n",
        "    # Feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        target_item_emb,\n",
        "        pooled_sequence,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK dengan PReLU activation\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "\n",
        "        # PReLU activation dengan parameter optimal\n",
        "        x = tf.keras.layers.PReLU(\n",
        "            alpha_initializer=tf.keras.initializers.Constant(din_prelu_best_params['prelu_alpha_init']),\n",
        "            name=f'prelu_{i+1}'\n",
        "        )(x)\n",
        "\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, sequence_input, seq_length_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='din_prelu_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DIN-PReLU model with best parameters\n",
        "print(f\"Creating DIN-PReLU model with best parameters...\")\n",
        "din_prelu_model = create_optimized_din_prelu_model()\n",
        "\n",
        "# Compile DIN-PReLU model with best parameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=din_prelu_best_params['learning_rate'],\n",
        "    beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
        "    clipnorm=0.5\n",
        ")\n",
        "metrics = [\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "# LOSS dengan label smoothing optimal\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=din_prelu_best_params['label_smoothing'])\n",
        "\n",
        "din_prelu_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(f\"DIN-PReLU model created successfully with optimal parameters!\")\n",
        "print(f\"Model summary:\")\n",
        "print(f\"    Total parameters: {din_prelu_model.count_params():,}\")\n",
        "print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in din_prelu_model.trainable_weights]):,}\")\n",
        "\n",
        "# Run manual training with best parameters\n",
        "print(f\"\\nStarting DIN-PReLU training with best parameters...\")\n",
        "din_prelu_results = manual_training_loop_din_prelu(\n",
        "    model=din_prelu_model,\n",
        "    batch_size=4096,\n",
        "    save_csv=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "pIlBjx7cm49_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17ddda92-bfb6-49c8-da4e-fb9f5d822505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN DIN-PRELU WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Best Parameters for DIN-PReLU:\n",
            "    learning_rate: 0.0001\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 5e-05\n",
            "    l2_dense: 5e-05\n",
            "    prelu_alpha_init: 0.35\n",
            "    attention_hidden: 8\n",
            "    label_smoothing: 0.15\n",
            "    hidden_units: [128, 64]\n",
            "Creating DIN-PReLU model with best parameters...\n",
            "Building DIN-PReLU with optimal parameters:\n",
            "    Attention hidden: 8\n",
            "    Dropout rate: 0.3\n",
            "    L2 reg: 5e-05\n",
            "    L2 dense: 5e-05\n",
            "    PReLU Î±_init: 0.35\n",
            "DIN-PReLU model created successfully with optimal parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,658,578\n",
            "    Trainable parameters: 63,658,194\n",
            "\n",
            "Starting DIN-PReLU training with best parameters...\n",
            "STARTING DIN-PReLU TRAINING:\n",
            "  Batch size: 4096\n",
            "  Epochs: 15\n",
            "  Early stopping patience: 4\n",
            "  Test set evaluation: Only at end of training\n",
            "Epoch 1/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1959, AUC: 0.6978\n",
            "  Val   Loss: 0.1821, AUC: 0.7324\n",
            "Epoch 2/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1732, AUC: 0.7870\n",
            "  Val   Loss: 0.1844, AUC: 0.7248\n",
            "Epoch 3/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1616, AUC: 0.8306\n",
            "  Val   Loss: 0.1915, AUC: 0.7080\n",
            "Epoch 4/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1469, AUC: 0.8719\n",
            "  Val   Loss: 0.2081, AUC: 0.6860\n",
            "Epoch 5/15\n",
            "  Batch 100/5188\n",
            "  Batch 200/5188\n",
            "  Batch 300/5188\n",
            "  Batch 400/5188\n",
            "  Batch 500/5188\n",
            "  Batch 600/5188\n",
            "  Batch 700/5188\n",
            "  Batch 800/5188\n",
            "  Batch 900/5188\n",
            "  Batch 1000/5188\n",
            "  Batch 1100/5188\n",
            "  Batch 1200/5188\n",
            "  Batch 1300/5188\n",
            "  Batch 1400/5188\n",
            "  Batch 1500/5188\n",
            "  Batch 1600/5188\n",
            "  Batch 1700/5188\n",
            "  Batch 1800/5188\n",
            "  Batch 1900/5188\n",
            "  Batch 2000/5188\n",
            "  Batch 2100/5188\n",
            "  Batch 2200/5188\n",
            "  Batch 2300/5188\n",
            "  Batch 2400/5188\n",
            "  Batch 2500/5188\n",
            "  Batch 2600/5188\n",
            "  Batch 2700/5188\n",
            "  Batch 2800/5188\n",
            "  Batch 2900/5188\n",
            "  Batch 3000/5188\n",
            "  Batch 3100/5188\n",
            "  Batch 3200/5188\n",
            "  Batch 3300/5188\n",
            "  Batch 3400/5188\n",
            "  Batch 3500/5188\n",
            "  Batch 3600/5188\n",
            "  Batch 3700/5188\n",
            "  Batch 3800/5188\n",
            "  Batch 3900/5188\n",
            "  Batch 4000/5188\n",
            "  Batch 4100/5188\n",
            "  Batch 4200/5188\n",
            "  Batch 4300/5188\n",
            "  Batch 4400/5188\n",
            "  Batch 4500/5188\n",
            "  Batch 4600/5188\n",
            "  Batch 4700/5188\n",
            "  Batch 4800/5188\n",
            "  Batch 4900/5188\n",
            "  Batch 5000/5188\n",
            "  Batch 5100/5188\n",
            "  Train Loss: 0.1290, AUC: 0.9096\n",
            "  Val   Loss: 0.2406, AUC: 0.6678\n",
            "Early stopping triggered after 5 epochs!\n",
            "\n",
            "Training completed. Evaluating final model on test set...\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Best epoch: 1\n",
            "  Best validation AUC: 0.7324\n",
            "  Test AUC: 0.7328\n",
            "  Test log loss: 0.1831\n",
            "  Training time: 5890.4s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results saved to din_prelu_training_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# 3. TRAIN DEEPFM WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN DEEPFM WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get best parameters\n",
        "deepfm_best_params = best_params['DeepFM']\n",
        "\n",
        "print(\"Best Parameters for DeepFM:\")\n",
        "for param, value in deepfm_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n",
        "\n",
        "# Create new DeepFM model with best parameters\n",
        "def create_optimized_deepfm_model():\n",
        "    \"\"\"Create DeepFM model with best parameters\"\"\"\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = deepfm_best_params['hidden_units']\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = deepfm_best_params['dropout_rate']\n",
        "    l2_reg = deepfm_best_params['l2_reg']\n",
        "    l2_dense = deepfm_best_params['l2_dense']\n",
        "\n",
        "    print(f\"Building DeepFM with optimal parameters:\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 reg: {l2_reg}\")\n",
        "    print(f\"    L2 dense: {l2_dense}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "    # FM PART: Factorization Machine component\n",
        "\n",
        "    # LINEAR PART\n",
        "    user_linear = tf.keras.layers.Dense(1, use_bias=False, name='user_linear',\n",
        "                                      kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(user_emb)\n",
        "    item_linear = tf.keras.layers.Dense(1, use_bias=False, name='item_linear',\n",
        "                                      kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(item_emb)\n",
        "    dense_linear = tf.keras.layers.Dense(1, use_bias=False, name='dense_linear',\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "\n",
        "    # INTERACTION PART\n",
        "    # User-Item interaction\n",
        "    user_item_interaction = tf.keras.layers.Multiply(name='user_item_mult')([user_emb, item_emb])\n",
        "\n",
        "    # User-Dense interaction\n",
        "    user_dense_proj = tf.keras.layers.Dense(embedding_dim, name='user_dense_proj',\n",
        "                                          kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "    user_dense_interaction = tf.keras.layers.Multiply(name='user_dense_mult')([user_emb, user_dense_proj])\n",
        "\n",
        "    # Item-Dense interaction\n",
        "    item_dense_proj = tf.keras.layers.Dense(embedding_dim, name='item_dense_proj',\n",
        "                                          kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(dense_input)\n",
        "    item_dense_interaction = tf.keras.layers.Multiply(name='item_dense_mult')([item_emb, item_dense_proj])\n",
        "\n",
        "    # Sum all interactions\n",
        "    fm_interactions = tf.keras.layers.Add(name='fm_interactions')([\n",
        "        user_item_interaction,\n",
        "        user_dense_interaction,\n",
        "        item_dense_interaction\n",
        "    ])\n",
        "    fm_interaction_sum = tf.keras.layers.Dense(1, name='fm_interaction_sum',\n",
        "                                             kernel_regularizer=tf.keras.regularizers.l2(l2_dense))(fm_interactions)\n",
        "\n",
        "    # FM output\n",
        "    fm_output = tf.keras.layers.Add(name='fm_output')([\n",
        "        user_linear,\n",
        "        item_linear,\n",
        "        dense_linear,\n",
        "        fm_interaction_sum\n",
        "    ])\n",
        "\n",
        "    # DEEP PART: Deep Neural Network component\n",
        "\n",
        "    # Concatenate all features untuk deep part\n",
        "    deep_features = tf.keras.layers.Concatenate(name='deep_features')([\n",
        "        user_emb,\n",
        "        item_emb,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # DEEP NETWORK\n",
        "    x = deep_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation='relu',\n",
        "            name=f'deep_dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'deep_dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'deep_bn_{i+1}')(x)\n",
        "\n",
        "    # DEEP OUTPUT\n",
        "    deep_output = tf.keras.layers.Dense(1, name='deep_output',\n",
        "                                      kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # COMBINE FM + DEEP\n",
        "    combined_output = tf.keras.layers.Add(name='fm_deep_combine')([fm_output, deep_output])\n",
        "\n",
        "    # Final activation\n",
        "    final_output = tf.keras.layers.Activation('sigmoid', name='final_output')(combined_output)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, dense_input],\n",
        "        outputs=final_output,\n",
        "        name='deepfm_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create DeepFM model with best parameters\n",
        "print(f\"Creating DeepFM model with best parameters...\")\n",
        "deepfm_model = create_optimized_deepfm_model()\n",
        "\n",
        "# Create DeepFM dataset\n",
        "deepfm_data = create_deepfm_dataset()\n",
        "\n",
        "# Compile DeepFM model with best parameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=deepfm_best_params['learning_rate'],\n",
        "    beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
        "    clipnorm=0.5\n",
        ")\n",
        "metrics = [\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "# LOSS dengan label smoothing optimal\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=deepfm_best_params['label_smoothing'])\n",
        "\n",
        "deepfm_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(f\"DeepFM model created successfully with optimal parameters!\")\n",
        "print(f\"Model summary:\")\n",
        "print(f\"    Total parameters: {deepfm_model.count_params():,}\")\n",
        "print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in deepfm_model.trainable_weights]):,}\")\n",
        "\n",
        "# Train DeepFM with best parameters\n",
        "print(f\"\\nStarting DeepFM training with best parameters...\")\n",
        "deepfm_results = train_deepfm_model(\n",
        "    model=deepfm_model,\n",
        "    batch_size=deepfm_best_params['batch_size'],\n",
        "    save_csv=True\n",
        ")"
      ],
      "metadata": {
        "id": "nty8aYzAm47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c7aa75c-b2d1-4f42-b059-ec0ad231316e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN DEEPFM WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Best Parameters for DeepFM:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.3\n",
            "    l2_reg: 0.001\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.05\n",
            "    hidden_units: [64, 32, 16]\n",
            "Creating DeepFM model with best parameters...\n",
            "Building DeepFM with optimal parameters:\n",
            "    Hidden units: [64, 32, 16]\n",
            "    Dropout rate: 0.3\n",
            "    L2 reg: 0.001\n",
            "    L2 dense: 0.0001\n",
            "Creating DeepFM dataset...\n",
            "DeepFM model created successfully with optimal parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,643,189\n",
            "    Trainable parameters: 63,642,965\n",
            "\n",
            "Starting DeepFM training with best parameters...\n",
            "STARTING DEEPFM TRAINING:\n",
            "  Batch size: 2048\n",
            "  Epochs: 15\n",
            "  Early stopping patience: 4\n",
            "  Test set evaluation: Only at end of training\n",
            "Creating DeepFM dataset...\n",
            "Epoch 1/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 17ms/step - auc: 0.6061 - loss: 1.2937 - precision: 0.0762 - recall: 0.0566 - val_auc: 0.6911 - val_loss: 0.2547 - val_precision: 0.6633 - val_recall: 0.0121\n",
            "Epoch 2/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6895 - loss: 0.2554 - precision: 0.6721 - recall: 0.0116 - val_auc: 0.6913 - val_loss: 0.2544 - val_precision: 0.6683 - val_recall: 0.0119\n",
            "Epoch 3/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6898 - loss: 0.2551 - precision: 0.6818 - recall: 0.0111 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6676 - val_recall: 0.0119\n",
            "Epoch 4/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 16ms/step - auc: 0.6898 - loss: 0.2551 - precision: 0.6859 - recall: 0.0111 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6727 - val_recall: 0.0117\n",
            "Epoch 5/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6899 - loss: 0.2551 - precision: 0.6832 - recall: 0.0110 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6672 - val_recall: 0.0119\n",
            "Epoch 6/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6899 - loss: 0.2550 - precision: 0.6833 - recall: 0.0112 - val_auc: 0.6912 - val_loss: 0.2543 - val_precision: 0.6689 - val_recall: 0.0119\n",
            "Epoch 7/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6835 - recall: 0.0110 - val_auc: 0.6911 - val_loss: 0.2543 - val_precision: 0.6669 - val_recall: 0.0119\n",
            "Epoch 8/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6830 - recall: 0.0110 - val_auc: 0.6911 - val_loss: 0.2543 - val_precision: 0.6692 - val_recall: 0.0119\n",
            "Epoch 9/15\n",
            "\u001b[1m10373/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6850 - recall: 0.0110Early stopping triggered after 9 epochs!\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 16ms/step - auc: 0.6900 - loss: 0.2550 - precision: 0.6850 - recall: 0.0110 - val_auc: 0.6913 - val_loss: 0.2543 - val_precision: 0.6680 - val_recall: 0.0119\n",
            "Restored best weights from epoch 5\n",
            "\n",
            "Training completed. Evaluating final model on test set...\n",
            "\u001b[1m1297/1297\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - auc: 0.6913 - loss: 0.2553 - precision: 0.6771 - recall: 0.0128\n",
            "\u001b[1m1297/1297\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Best epoch: 5\n",
            "  Best validation AUC: 0.6913\n",
            "  Test AUC: 0.6907\n",
            "  Test Log Loss: 0.1949\n",
            "  Training time: 1527.5s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results saved to deepfm_training_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# 4. TRAIN BASELINE WITH BEST PARAMETERS\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAIN BASELINE WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get best parameters\n",
        "baseline_best_params = best_params['Baseline']\n",
        "\n",
        "print(\"Best Parameters for Baseline:\")\n",
        "for param, value in baseline_best_params.items():\n",
        "    print(f\"    {param}: {value}\")\n",
        "\n",
        "# Create new Baseline model with best parameters\n",
        "def create_optimized_baseline_model():\n",
        "    \"\"\"Create Baseline model with best parameters\"\"\"\n",
        "    # Model parameters\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = baseline_best_params['hidden_units']\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = baseline_best_params['dropout_rate']\n",
        "    l2_reg = baseline_best_params['l2_reg']\n",
        "    l2_dense = baseline_best_params['l2_dense']\n",
        "\n",
        "    print(f\"Building Baseline with optimal parameters:\")\n",
        "    print(f\"    Hidden units: {hidden_units}\")\n",
        "    print(f\"    Dropout rate: {dropout_rate}\")\n",
        "    print(f\"    L2 reg: {l2_reg}\")\n",
        "    print(f\"    L2 dense: {l2_dense}\")\n",
        "\n",
        "    # Input layers\n",
        "    user_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    item_input = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "    dense_input = tf.keras.layers.Input(shape=(dense_feature_dim,), dtype=tf.float32, name='dense_features')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    # Apply embeddings\n",
        "    user_emb = user_embedding_layer(user_input)\n",
        "    item_emb = item_embedding_layer(item_input)\n",
        "\n",
        "    # Simple feature concatenation\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')([\n",
        "        user_emb,\n",
        "        item_emb,\n",
        "        dense_input\n",
        "    ])\n",
        "\n",
        "    # FEEDFORWARD NETWORK\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units,\n",
        "            activation='relu',\n",
        "            name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    # OUTPUT LAYER\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                 kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "\n",
        "    # Create model\n",
        "    model = tf.keras.Model(\n",
        "        inputs=[user_input, item_input, dense_input],\n",
        "        outputs=output,\n",
        "        name='baseline_optimized'\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create Baseline model with best parameters\n",
        "print(f\"Creating Baseline model with best parameters...\")\n",
        "baseline_model = create_optimized_baseline_model()\n",
        "\n",
        "# Create Baseline dataset\n",
        "baseline_data = create_baseline_dataset()\n",
        "\n",
        "# Compile Baseline model with best parameters\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=baseline_best_params['learning_rate'],\n",
        "    beta_1=0.9, beta_2=0.999, epsilon=1e-8,\n",
        "    clipnorm=0.5\n",
        ")\n",
        "metrics = [\n",
        "    tf.keras.metrics.AUC(name='auc'),\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "# LOSS dengan label smoothing optimal\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=baseline_best_params['label_smoothing'])\n",
        "\n",
        "baseline_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(f\"Baseline model created successfully with optimal parameters!\")\n",
        "print(f\"Model summary:\")\n",
        "print(f\"    Total parameters: {baseline_model.count_params():,}\")\n",
        "print(f\"    Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in baseline_model.trainable_weights]):,}\")\n",
        "\n",
        "# Train Baseline with best parameters\n",
        "print(f\"\\nStarting Baseline training with best parameters...\")\n",
        "baseline_results = train_baseline_model(\n",
        "    model=baseline_model,\n",
        "    batch_size=baseline_best_params['batch_size'],\n",
        "    save_csv=True\n",
        ")"
      ],
      "metadata": {
        "id": "IHeiAjk1m44x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36ae03c5-05ce-4f30-8d99-bc8a0ef16eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAIN BASELINE WITH BEST PARAMETERS\n",
            "============================================================\n",
            "Best Parameters for Baseline:\n",
            "    learning_rate: 0.0005\n",
            "    batch_size: 2048\n",
            "    dropout_rate: 0.7\n",
            "    l2_reg: 1e-05\n",
            "    l2_dense: 0.0001\n",
            "    label_smoothing: 0.0\n",
            "    hidden_units: [64, 32]\n",
            "Creating Baseline model with best parameters...\n",
            "Building Baseline with optimal parameters:\n",
            "    Hidden units: [64, 32]\n",
            "    Dropout rate: 0.7\n",
            "    L2 reg: 1e-05\n",
            "    L2 dense: 0.0001\n",
            "Creating Baseline dataset...\n",
            "Baseline model created successfully with optimal parameters!\n",
            "Model summary:\n",
            "    Total parameters: 63,641,217\n",
            "    Trainable parameters: 63,641,025\n",
            "\n",
            "Starting Baseline training with best parameters...\n",
            "STARTING BASELINE TRAINING:\n",
            "  Batch size: 2048\n",
            "  Epochs: 15\n",
            "  Early stopping patience: 4\n",
            "  Test set evaluation: Only at end of training\n",
            "Creating Baseline dataset...\n",
            "Epoch 1/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 16ms/step - auc: 0.6044 - loss: 0.2757 - precision: 0.0756 - recall: 0.0483 - val_auc: 0.6913 - val_loss: 0.1879 - val_precision: 0.9474 - val_recall: 0.0061\n",
            "Epoch 2/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 15ms/step - auc: 0.6810 - loss: 0.1903 - precision: 0.5527 - recall: 0.0075 - val_auc: 0.6912 - val_loss: 0.1879 - val_precision: 0.8833 - val_recall: 0.0067\n",
            "Epoch 3/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 15ms/step - auc: 0.6810 - loss: 0.1903 - precision: 0.5498 - recall: 0.0075 - val_auc: 0.6913 - val_loss: 0.1879 - val_precision: 0.6744 - val_recall: 0.0118\n",
            "Epoch 4/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 15ms/step - auc: 0.6810 - loss: 0.1903 - precision: 0.5455 - recall: 0.0074 - val_auc: 0.6912 - val_loss: 0.1878 - val_precision: 0.6768 - val_recall: 0.0116\n",
            "Epoch 5/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 15ms/step - auc: 0.6811 - loss: 0.1902 - precision: 0.5454 - recall: 0.0074 - val_auc: 0.6913 - val_loss: 0.1878 - val_precision: 0.6707 - val_recall: 0.0118\n",
            "Epoch 6/15\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 15ms/step - auc: 0.6811 - loss: 0.1902 - precision: 0.5452 - recall: 0.0075 - val_auc: 0.6913 - val_loss: 0.1879 - val_precision: 0.9037 - val_recall: 0.0064\n",
            "Epoch 7/15\n",
            "\u001b[1m10373/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - auc: 0.6810 - loss: 0.1902 - precision: 0.5435 - recall: 0.0073Early stopping triggered after 7 epochs!\n",
            "\u001b[1m10375/10375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 15ms/step - auc: 0.6810 - loss: 0.1902 - precision: 0.5435 - recall: 0.0073 - val_auc: 0.6912 - val_loss: 0.1879 - val_precision: 0.9484 - val_recall: 0.0061\n",
            "Restored best weights from epoch 3\n",
            "\n",
            "Training completed. Evaluating final model on test set...\n",
            "\u001b[1m1297/1297\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - auc: 0.6914 - loss: 0.1892 - precision: 0.6809 - recall: 0.0125\n",
            "\u001b[1m1297/1297\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Best epoch: 3\n",
            "  Best validation AUC: 0.6913\n",
            "  Test AUC: 0.6908\n",
            "  Test Log Loss: 0.1887\n",
            "  Training time: 1141.2s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training results saved to baseline_training_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# OVERALL TRAINING SUMMARY\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"OVERALL TRAINING SUMMARY WITH BEST PARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create a comparison table of results\n",
        "training_summary = {\n",
        "    'Model': [],\n",
        "    'Val AUC': [],\n",
        "    'Test AUC': [],\n",
        "    'Test LogLoss': [],\n",
        "    'Training Time': [],\n",
        "    'Parameters': []\n",
        "}\n",
        "\n",
        "if 'din_dice_results' in locals() and din_dice_results.get('success'):\n",
        "    training_summary['Model'].append('DIN-DICE')\n",
        "    training_summary['Val AUC'].append(f\"{din_dice_results['best_val_auc']:.4f}\")\n",
        "    training_summary['Test AUC'].append(f\"{din_dice_results['best_test_auc']:.4f}\")\n",
        "    training_summary['Test LogLoss'].append(f\"{din_dice_results['best_test_logloss']:.4f}\")\n",
        "    training_summary['Training Time'].append(f\"{din_dice_results['training_time']:.1f}s\")\n",
        "    training_summary['Parameters'].append(f\"{din_dice_model.count_params():,}\")\n",
        "\n",
        "if 'din_prelu_results' in locals() and din_prelu_results.get('success'):\n",
        "    training_summary['Model'].append('DIN-PReLU')\n",
        "    training_summary['Val AUC'].append(f\"{din_prelu_results['best_val_auc']:.4f}\")\n",
        "    training_summary['Test AUC'].append(f\"{din_prelu_results['best_test_auc']:.4f}\")\n",
        "    training_summary['Test LogLoss'].append(f\"{din_prelu_results['best_test_logloss']:.4f}\")\n",
        "    training_summary['Training Time'].append(f\"{din_prelu_results['training_time']:.1f}s\")\n",
        "    training_summary['Parameters'].append(f\"{din_prelu_model.count_params():,}\")\n",
        "\n",
        "if 'deepfm_results' in locals() and deepfm_results.get('success'):\n",
        "    training_summary['Model'].append('DeepFM')\n",
        "    training_summary['Val AUC'].append(f\"{deepfm_results['best_val_auc']:.4f}\")\n",
        "    training_summary['Test AUC'].append(f\"{deepfm_results['best_test_auc']:.4f}\")\n",
        "    training_summary['Test LogLoss'].append(f\"{deepfm_results['best_test_logloss']:.4f}\")\n",
        "    training_summary['Training Time'].append(f\"{deepfm_results['training_time']:.1f}s\")\n",
        "    training_summary['Parameters'].append(f\"{deepfm_model.count_params():,}\")\n",
        "\n",
        "if 'baseline_results' in locals() and baseline_results.get('success'):\n",
        "    training_summary['Model'].append('Baseline')\n",
        "    training_summary['Val AUC'].append(f\"{baseline_results['best_val_auc']:.4f}\")\n",
        "    training_summary['Test AUC'].append(f\"{baseline_results['best_test_auc']:.4f}\")\n",
        "    training_summary['Test LogLoss'].append(f\"{baseline_results['best_test_logloss']:.4f}\")\n",
        "    training_summary['Training Time'].append(f\"{baseline_results['training_time']:.1f}s\")\n",
        "    training_summary['Parameters'].append(f\"{baseline_model.count_params():,}\")\n",
        "\n",
        "# Display summary table\n",
        "training_df = pd.DataFrame(training_summary)\n",
        "print(\"\\nOPTIMIZED MODELS PERFORMANCE SUMMARY:\")\n",
        "print(training_df)\n",
        "\n",
        "# Save summary to CSV\n",
        "summary_path = \"training_summary_optimized.csv\"\n",
        "training_df.to_csv(summary_path, index=False)\n",
        "print(f\"\\nSummary saved to {summary_path}\")\n",
        "\n",
        "# Create a comparison plot for Test AUC\n",
        "plt.figure(figsize=(12, 6))\n",
        "models = training_summary['Model']\n",
        "test_aucs = [float(auc) for auc in training_summary['Test AUC']]\n",
        "plt.bar(models, test_aucs, color='lightcoral')\n",
        "plt.title('Test AUC Comparison (Optimized Models)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Test AUC')\n",
        "plt.ylim(0.5, 1.0)\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(test_aucs):\n",
        "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_auc_comparison_optimized.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Create a comparison plot for Test LogLoss\n",
        "plt.figure(figsize=(12, 6))\n",
        "test_logloss = [float(loss) for loss in training_summary['Test LogLoss']]\n",
        "plt.bar(models, test_logloss, color='lightgreen')\n",
        "plt.title('Test Log Loss Comparison (Optimized Models)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Test Log Loss')\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(test_logloss):\n",
        "    plt.text(i, v - 0.02, f'{v:.4f}', ha='center', color='black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('test_logloss_comparison_optimized.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Final Output\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETED FOR ALL OPTIMIZED MODELS!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nThe hyperparameter tuning and optimized training process has been completed.\")\n",
        "print(\"All models have been trained with their best parameters from hyperparameter tuning.\")\n",
        "print(\"The results show both validation and test performance metrics.\")\n",
        "print(\"The best model based on test AUC is:\", training_summary['Model'][np.argmax(test_aucs)])\n",
        "print(\"The best model based on test LogLoss is:\", training_summary['Model'][np.argmin(test_logloss)])"
      ],
      "metadata": {
        "id": "YSKP1G-6m42I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "462be4bc-2409-4299-8e75-7ff70a098876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "OVERALL TRAINING SUMMARY WITH BEST PARAMETERS\n",
            "============================================================\n",
            "\n",
            "OPTIMIZED MODELS PERFORMANCE SUMMARY:\n",
            "       Model Val AUC Test AUC Test LogLoss Training Time  Parameters\n",
            "0   DIN-DICE  0.7321   0.7325       0.1834       6738.3s  63,660,002\n",
            "1  DIN-PReLU  0.7324   0.7328       0.1831       5890.4s  63,658,578\n",
            "2     DeepFM  0.6913   0.6907       0.1949       1527.5s  63,643,189\n",
            "3   Baseline  0.6913   0.6908       0.1887       1141.2s  63,641,217\n",
            "\n",
            "Summary saved to training_summary_optimized.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING COMPLETED FOR ALL OPTIMIZED MODELS!\n",
            "============================================================\n",
            "\n",
            "The hyperparameter tuning and optimized training process has been completed.\n",
            "All models have been trained with their best parameters from hyperparameter tuning.\n",
            "The results show both validation and test performance metrics.\n",
            "The best model based on test AUC is: DIN-PReLU\n",
            "The best model based on test LogLoss is: DIN-PReLU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 8: MODEL EVALUATION & TESTING (SIMPLIFIED METRICS)\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CELL 8: MODEL EVALUATION & TESTING (SIMPLIFIED METRICS)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Add required sklearn imports\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "\n",
        "def comprehensive_model_evaluation():\n",
        "    \"\"\"Comprehensive evaluation of all trained models focusing on AUC, Log Loss, and AUC-based RelaImpr\"\"\"\n",
        "\n",
        "    # Current timestamp and user information\n",
        "    current_timestamp = \"-\"\n",
        "    current_user = \"Muhammad Sultan Nurrochman\"\n",
        "\n",
        "    print(\"ðŸ“Š Starting simplified model evaluation...\")\n",
        "\n",
        "    # Collect all trained models\n",
        "    trained_models = {}\n",
        "\n",
        "    # Check DIN-DICE\n",
        "    if 'din_dice_model' in globals() and 'din_dice_results' in globals():\n",
        "        trained_models['DIN-DICE (Optimized)'] = {\n",
        "            'model': din_dice_model,\n",
        "            'results': din_dice_results,\n",
        "            'data_format': 'sequences'\n",
        "        }\n",
        "        print(\"DIN-DICE model found\")\n",
        "\n",
        "    # Check DIN-PReLU\n",
        "    if 'din_prelu_model' in globals() and 'din_prelu_results' in globals():\n",
        "        trained_models['DIN-PReLU (Optimized)'] = {\n",
        "            'model': din_prelu_model,\n",
        "            'results': din_prelu_results,\n",
        "            'data_format': 'sequences'\n",
        "        }\n",
        "        print(\"DIN-PReLU model found\")\n",
        "\n",
        "    # Check DeepFM\n",
        "    if 'deepfm_model' in globals() and 'deepfm_results' in globals():\n",
        "        trained_models['DeepFM'] = {\n",
        "            'model': deepfm_model,\n",
        "            'results': deepfm_results,\n",
        "            'data_format': 'simple'\n",
        "        }\n",
        "        print(\"DeepFM model found\")\n",
        "\n",
        "    # Check Baseline\n",
        "    if 'baseline_model' in globals() and 'baseline_results' in globals():\n",
        "        trained_models['Baseline'] = {\n",
        "            'model': baseline_model,\n",
        "            'results': baseline_results,\n",
        "            'data_format': 'simple'\n",
        "        }\n",
        "        print(\"Baseline model found\")\n",
        "\n",
        "    if not trained_models:\n",
        "        print(\"âŒ No trained models found! Please run training cells first.\")\n",
        "        return {'success': False, 'error': 'No trained models available'}\n",
        "\n",
        "    print(f\"Found {len(trained_models)} trained models: {list(trained_models.keys())}\")\n",
        "\n",
        "    # Prepare test data\n",
        "    test_data = model_data['splits']['test']\n",
        "\n",
        "    # Test data for sequence models (DIN variants)\n",
        "    test_data_sequences = {\n",
        "        'user_id': test_data['user_ids'],\n",
        "        'item_id': test_data['item_ids'],\n",
        "        'sequence': test_data['sequences'],\n",
        "        'seq_length': test_data['seq_lengths'],\n",
        "        'dense_features': test_data['dense_features']\n",
        "    }\n",
        "\n",
        "    # Test data for simple models (DeepFM, Baseline)\n",
        "    test_data_simple = {\n",
        "        'user_id': test_data['user_ids'],\n",
        "        'item_id': test_data['item_ids'],\n",
        "        'dense_features': test_data['dense_features']\n",
        "    }\n",
        "\n",
        "    test_labels = test_data['labels'].flatten()\n",
        "\n",
        "    print(f\"Test dataset info:\")\n",
        "    print(f\"    Test samples: {len(test_labels):,}\")\n",
        "    print(f\"    Test CTR: {test_labels.mean():.4f}\")\n",
        "    print(f\"    Positive samples: {test_labels.sum():,}\")\n",
        "    print(f\"    Negative samples: {len(test_labels) - test_labels.sum():,}\")\n",
        "\n",
        "    # Evaluation results storage\n",
        "    evaluation_results = {}\n",
        "\n",
        "    print(f\"\\nðŸ” Starting model evaluations...\")\n",
        "\n",
        "    # Evaluate each model\n",
        "    for model_name, model_info in trained_models.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ðŸ” Evaluating {model_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        model = model_info['model']\n",
        "        data_format = model_info['data_format']\n",
        "\n",
        "        try:\n",
        "            # Select appropriate test data format\n",
        "            if data_format == 'sequences':\n",
        "                test_x = test_data_sequences\n",
        "            else:\n",
        "                test_x = test_data_simple\n",
        "\n",
        "            print(f\"Model info:\")\n",
        "            print(f\"    Parameters: {model.count_params():,}\")\n",
        "            print(f\"    Data format: {data_format}\")\n",
        "\n",
        "            # Make predictions\n",
        "            print(f\"Making predictions...\")\n",
        "            start_time = time.time()\n",
        "\n",
        "            predictions = model.predict(test_x, batch_size=512, verbose=0)\n",
        "            predictions = predictions.flatten()\n",
        "\n",
        "            prediction_time = time.time() - start_time\n",
        "\n",
        "            # Calculate key metrics\n",
        "            print(f\"Calculating key metrics: AUC and Log Loss...\")\n",
        "\n",
        "            # AUC\n",
        "            auc_score = tf.keras.metrics.AUC()\n",
        "            auc_score.update_state(test_labels, predictions)\n",
        "            auc = auc_score.result().numpy()\n",
        "\n",
        "            # ROC AUC (using sklearn for validation)\n",
        "            roc_auc = roc_auc_score(test_labels, predictions)\n",
        "\n",
        "            # Log Loss\n",
        "            log_loss_val = tf.keras.losses.BinaryCrossentropy()(test_labels, predictions).numpy()\n",
        "\n",
        "            # Store results\n",
        "            evaluation_results[model_name] = {\n",
        "                'auc': auc,\n",
        "                'roc_auc': roc_auc,\n",
        "                'log_loss': log_loss_val,\n",
        "                'prediction_time': prediction_time,\n",
        "                'model_params': model.count_params(),\n",
        "                'validation_auc': model_info['results']['best_val_auc'],\n",
        "                'training_time': model_info['results']['training_time'],\n",
        "                'success': True\n",
        "            }\n",
        "\n",
        "            # Print results\n",
        "            print(f\"{model_name} Evaluation Results:\")\n",
        "            print(f\"    AUC: {auc:.4f}\")\n",
        "            print(f\"    ROC AUC (sklearn): {roc_auc:.4f}\")\n",
        "            print(f\"    Log Loss: {log_loss_val:.4f}\")\n",
        "            print(f\"    Prediction Time: {prediction_time:.2f}s\")\n",
        "            print(f\"    Model Parameters: {model.count_params():,}\")\n",
        "            print(f\"    Validation AUC: {model_info['results']['best_val_auc']:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error evaluating {model_name}: {e}\")\n",
        "            evaluation_results[model_name] = {'success': False, 'error': str(e)}\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Calculate the relative improvement over baseline based on AUC\n",
        "    if 'Baseline' in evaluation_results and evaluation_results['Baseline'].get('success'):\n",
        "        baseline_auc = evaluation_results['Baseline']['auc']\n",
        "\n",
        "        for model_name, results in evaluation_results.items():\n",
        "            if results.get('success'):\n",
        "                # Calculate RelaImpr as AUC improvement over baseline\n",
        "                if model_name != 'Baseline':\n",
        "                    model_auc = results['auc']\n",
        "                    # RelaImpr as percentage improvement over baseline AUC\n",
        "                    auc_relaimpr = ((model_auc / baseline_auc) - 1) * 100 if baseline_auc > 0 else 0\n",
        "                else:\n",
        "                    # Baseline has 0% improvement over itself\n",
        "                    auc_relaimpr = 0.0\n",
        "\n",
        "                evaluation_results[model_name]['relaimpr'] = auc_relaimpr\n",
        "\n",
        "    # Create results directory\n",
        "    os.makedirs('evaluation_results', exist_ok=True)\n",
        "\n",
        "    # Prepare data for CSV export\n",
        "    results_for_csv = []\n",
        "\n",
        "    # Create comprehensive comparison\n",
        "    print(f\"\\nSIMPLIFIED MODEL COMPARISON (Sorted by RelaImpr)\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Filter successful evaluations\n",
        "    successful_results = {k: v for k, v in evaluation_results.items() if v.get('success')}\n",
        "\n",
        "    if not successful_results:\n",
        "        print(\"âŒ No successful evaluations found!\")\n",
        "        return {'success': False, 'error': 'No successful evaluations'}\n",
        "\n",
        "    # MAIN COMPARISON TABLE WITH CORE METRICS - Diurutkan berdasarkan RelaImpr terendah\n",
        "    print(f\"{'Model':<20} {'AUC':<10} {'RelaImpr':<10} {'Log Loss':<10} {'Params':<12}\")\n",
        "    print(f\"{'-'*20} {'-'*10} {'-'*10} {'-'*10} {'-'*12}\")\n",
        "\n",
        "    # Sorting model names by RelaImpr (ascending - lowest first)\n",
        "    sorted_models = sorted(successful_results.keys(),\n",
        "                        key=lambda x: successful_results[x].get('relaimpr', 0.0))\n",
        "\n",
        "    for model_name in sorted_models:\n",
        "        results = successful_results[model_name]\n",
        "        # Add to CSV data\n",
        "        results_for_csv.append({\n",
        "            'model_name': model_name,\n",
        "            'auc': results['auc'],\n",
        "            'relaimpr': results.get('relaimpr', 0.0),\n",
        "            'log_loss': results['log_loss'],\n",
        "            'validation_auc': results['validation_auc'],\n",
        "            'prediction_time': results['prediction_time'],\n",
        "            'training_time': results['training_time'],\n",
        "            'parameters': results['model_params']\n",
        "        })\n",
        "\n",
        "        # Print table row with key metrics\n",
        "        print(f\"{model_name:<20} {results['auc']:<10.4f} {results.get('relaimpr', 0.0):<10.2f} \"\n",
        "            f\"{results['log_loss']:<10.4f} {results['model_params']:<12,}\")\n",
        "\n",
        "    # Find best model by different criteria\n",
        "    best_auc_model = max(successful_results.keys(), key=lambda x: successful_results[x]['auc'])\n",
        "    best_relaimpr_model = max(successful_results.keys(), key=lambda x: successful_results[x].get('relaimpr', 0.0))\n",
        "    best_logloss_model = min(successful_results.keys(), key=lambda x: successful_results[x]['log_loss'])\n",
        "\n",
        "    best_results = successful_results[best_auc_model]\n",
        "\n",
        "    print(f\"\\nBEST MODELS BY CRITERIA:\")\n",
        "    print(f\"    Best AUC: {best_auc_model} ({successful_results[best_auc_model]['auc']:.4f})\")\n",
        "    print(f\"    Best RelaImpr: {best_relaimpr_model} ({successful_results[best_relaimpr_model].get('relaimpr', 0.0):.2f}%)\")\n",
        "    print(f\"    Best Log Loss: {best_logloss_model} ({successful_results[best_logloss_model]['log_loss']:.4f})\")\n",
        "\n",
        "    # EXPORT RESULTS TO CSV\n",
        "    results_df = pd.DataFrame(results_for_csv)\n",
        "    csv_timestamp = current_timestamp.replace(' ', '_').replace(':', '-')\n",
        "    csv_path = f'evaluation_results/model_evaluation_simplified_{csv_timestamp}.csv'\n",
        "    results_df.to_csv(csv_path, index=False)\n",
        "    print(f\"\\nEvaluation results exported to CSV: {csv_path}\")\n",
        "\n",
        "    # PLOTS - using same model order as the table (sorted by RelaImpr)\n",
        "    models = sorted_models  # Using the same sorted order as the table\n",
        "\n",
        "    # 1. AUC Comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    test_aucs = [successful_results[m]['auc'] for m in models]\n",
        "    bars = plt.bar(models, test_aucs, color='skyblue', alpha=0.8)\n",
        "    plt.title('Test AUC Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('AUC Score')\n",
        "    plt.ylim(0, 1)\n",
        "    for bar, auc in zip(bars, test_aucs):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{auc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/auc_comparison.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 2. RelaImpr Comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    relaimpr_scores = [successful_results[m].get('relaimpr', 0.0) for m in models]\n",
        "    bars = plt.bar(models, relaimpr_scores, color='lightcoral', alpha=0.8)\n",
        "    plt.title('AUC-Based RelaImpr Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Relative Improvement (%)')\n",
        "    for bar, relaimpr in zip(bars, relaimpr_scores):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                f'{relaimpr:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/relaimpr_comparison.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 3. Log Loss Comparison\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    log_losses = [successful_results[m]['log_loss'] for m in models]\n",
        "    bars = plt.bar(models, log_losses, color='lightgreen', alpha=0.8)\n",
        "    plt.title('Log Loss Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Log Loss')\n",
        "    for bar, loss in zip(bars, log_losses):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{loss:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/logloss_comparison.png', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Final summary section\n",
        "    print(f\"\\nEVALUATION SUMMARY:\")\n",
        "    print(f\"    Models evaluated: {len(successful_results)}\")\n",
        "    print(f\"    Best overall model: {best_auc_model}\")\n",
        "    print(f\"    Best test AUC: {best_results['auc']:.4f}\")\n",
        "    print(f\"    Best RelaImpr: {successful_results[best_relaimpr_model].get('relaimpr', 0.0):.1f}%\")\n",
        "    print(f\"    CSV Export: Results saved to {csv_path}\")\n",
        "    print(f\"    Plots: Saved to evaluation_results/ directory\")\n",
        "\n",
        "    if 'Baseline' in successful_results:\n",
        "        baseline_auc = successful_results['Baseline']['auc']\n",
        "        improvement = best_results['auc'] - baseline_auc\n",
        "        print(f\"    ðŸ“ˆ AUC improvement over baseline: {improvement:.4f} points ({improvement/baseline_auc*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nðŸŽ‰ EVALUATION COMPLETED SUCCESSFULLY!\")\n",
        "    print(f\"ðŸ“… Evaluation completed on: {current_timestamp}\")\n",
        "    print(f\"ðŸ‘¤ Evaluated by: {current_user}\")\n",
        "\n",
        "    return {\n",
        "        'success': True,\n",
        "        'evaluation_results': evaluation_results,\n",
        "        'best_model': best_auc_model,\n",
        "        'best_results': best_results,\n",
        "        'best_relaimpr_model': best_relaimpr_model,\n",
        "        'best_logloss_model': best_logloss_model,\n",
        "        'models_evaluated': len(successful_results),\n",
        "        'timestamp': current_timestamp,\n",
        "        'evaluator': current_user,\n",
        "        'csv_path': csv_path\n",
        "    }\n",
        "\n",
        "# Execute comprehensive evaluation\n",
        "print(f\"Starting model evaluation with simplified metrics (AUC, Log Loss, RelaImpr)...\")\n",
        "try:\n",
        "    final_evaluation = comprehensive_model_evaluation()\n",
        "\n",
        "    if final_evaluation['success']:\n",
        "        print(f\"\\nEVALUATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"{final_evaluation['models_evaluated']} models evaluated with core metrics\")\n",
        "        print(f\"Best performing model: {final_evaluation['best_model']}\")\n",
        "        print(f\"Best test AUC: {final_evaluation['best_results']['auc']:.4f}\")\n",
        "        print(f\"Best RelaImpr model: {final_evaluation['best_relaimpr_model']}\")\n",
        "        print(f\"Results exported to: {final_evaluation['csv_path']}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"âŒ Evaluation failed: {final_evaluation.get('error', 'Unknown error')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Evaluation error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "FuoNnVeoufUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93c72ae-0f86-465b-a69e-d7f3a12f8055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CELL 8: MODEL EVALUATION & TESTING (SIMPLIFIED METRICS)\n",
            "============================================================\n",
            "Starting model evaluation with simplified metrics (AUC, Log Loss, RelaImpr)...\n",
            "ðŸ“Š Starting simplified model evaluation...\n",
            "DIN-DICE model found\n",
            "DIN-PReLU model found\n",
            "DeepFM model found\n",
            "Baseline model found\n",
            "Found 4 trained models: ['DIN-DICE (Optimized)', 'DIN-PReLU (Optimized)', 'DeepFM', 'Baseline']\n",
            "Test dataset info:\n",
            "    Test samples: 2,655,797\n",
            "    Test CTR: 0.0516\n",
            "    Positive samples: 136,973.0\n",
            "    Negative samples: 2,518,824.0\n",
            "\n",
            "ðŸ” Starting model evaluations...\n",
            "\n",
            "============================================================\n",
            "ðŸ” Evaluating DIN-DICE (Optimized)\n",
            "============================================================\n",
            "Model info:\n",
            "    Parameters: 63,660,002\n",
            "    Data format: sequences\n",
            "Making predictions...\n",
            "Calculating key metrics: AUC and Log Loss...\n",
            "DIN-DICE (Optimized) Evaluation Results:\n",
            "    AUC: 0.7324\n",
            "    ROC AUC (sklearn): 0.7328\n",
            "    Log Loss: 0.1834\n",
            "    Prediction Time: 14.42s\n",
            "    Model Parameters: 63,660,002\n",
            "    Validation AUC: 0.7321\n",
            "\n",
            "============================================================\n",
            "ðŸ” Evaluating DIN-PReLU (Optimized)\n",
            "============================================================\n",
            "Model info:\n",
            "    Parameters: 63,658,578\n",
            "    Data format: sequences\n",
            "Making predictions...\n",
            "Calculating key metrics: AUC and Log Loss...\n",
            "DIN-PReLU (Optimized) Evaluation Results:\n",
            "    AUC: 0.7328\n",
            "    ROC AUC (sklearn): 0.7332\n",
            "    Log Loss: 0.1831\n",
            "    Prediction Time: 12.33s\n",
            "    Model Parameters: 63,658,578\n",
            "    Validation AUC: 0.7324\n",
            "\n",
            "============================================================\n",
            "ðŸ” Evaluating DeepFM\n",
            "============================================================\n",
            "Model info:\n",
            "    Parameters: 63,643,189\n",
            "    Data format: simple\n",
            "Making predictions...\n",
            "Calculating key metrics: AUC and Log Loss...\n",
            "DeepFM Evaluation Results:\n",
            "    AUC: 0.6907\n",
            "    ROC AUC (sklearn): 0.6912\n",
            "    Log Loss: 0.1949\n",
            "    Prediction Time: 10.93s\n",
            "    Model Parameters: 63,643,189\n",
            "    Validation AUC: 0.6913\n",
            "\n",
            "============================================================\n",
            "ðŸ” Evaluating Baseline\n",
            "============================================================\n",
            "Model info:\n",
            "    Parameters: 63,641,217\n",
            "    Data format: simple\n",
            "Making predictions...\n",
            "Calculating key metrics: AUC and Log Loss...\n",
            "Baseline Evaluation Results:\n",
            "    AUC: 0.6908\n",
            "    ROC AUC (sklearn): 0.6914\n",
            "    Log Loss: 0.1887\n",
            "    Prediction Time: 9.72s\n",
            "    Model Parameters: 63,641,217\n",
            "    Validation AUC: 0.6913\n",
            "\n",
            "SIMPLIFIED MODEL COMPARISON (Sorted by RelaImpr)\n",
            "================================================================================\n",
            "Model                AUC        RelaImpr   Log Loss   Params      \n",
            "-------------------- ---------- ---------- ---------- ------------\n",
            "DeepFM               0.6907     -0.01      0.1949     63,643,189  \n",
            "Baseline             0.6908     0.00       0.1887     63,641,217  \n",
            "DIN-DICE (Optimized) 0.7324     6.03       0.1834     63,660,002  \n",
            "DIN-PReLU (Optimized) 0.7328     6.08       0.1831     63,658,578  \n",
            "\n",
            "BEST MODELS BY CRITERIA:\n",
            "    Best AUC: DIN-PReLU (Optimized) (0.7328)\n",
            "    Best RelaImpr: DIN-PReLU (Optimized) (6.08%)\n",
            "    Best Log Loss: DIN-PReLU (Optimized) (0.1831)\n",
            "\n",
            "Evaluation results exported to CSV: evaluation_results/model_evaluation_simplified_-.csv\n",
            "\n",
            "EVALUATION SUMMARY:\n",
            "    Models evaluated: 4\n",
            "    Best overall model: DIN-PReLU (Optimized)\n",
            "    Best test AUC: 0.7328\n",
            "    Best RelaImpr: 6.1%\n",
            "    CSV Export: Results saved to evaluation_results/model_evaluation_simplified_-.csv\n",
            "    Plots: Saved to evaluation_results/ directory\n",
            "    ðŸ“ˆ AUC improvement over baseline: 0.0420 points (6.1%)\n",
            "\n",
            "ðŸŽ‰ EVALUATION COMPLETED SUCCESSFULLY!\n",
            "ðŸ“… Evaluation completed on: -\n",
            "ðŸ‘¤ Evaluated by: Muhammad Sultan Nurrochman\n",
            "\n",
            "EVALUATION COMPLETED SUCCESSFULLY!\n",
            "4 models evaluated with core metrics\n",
            "Best performing model: DIN-PReLU (Optimized)\n",
            "Best test AUC: 0.7328\n",
            "Best RelaImpr model: DIN-PReLU (Optimized)\n",
            "Results exported to: evaluation_results/model_evaluation_simplified_-.csv\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# CELL 9: ENHANCED MODEL VISUALIZATIONS\n",
        "# =====================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CELL 9: ENHANCED MODEL VISUALIZATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from datetime import datetime\n",
        "\n",
        "# Current timestamp and user information\n",
        "current_timestamp = \"-\"\n",
        "current_user = \"Muhammad Sultan Nurrochman\"\n",
        "\n",
        "def create_enhanced_visualizations():\n",
        "    \"\"\"Create enhanced visualizations for model comparison with professional styling\"\"\"\n",
        "\n",
        "    print(\"ðŸ“Š Creating enhanced visualizations...\")\n",
        "\n",
        "    # Check if evaluation results exist\n",
        "    if 'final_evaluation' not in globals() or not final_evaluation.get('success', False):\n",
        "        print(\"âŒ No evaluation results found! Please run evaluation cell first.\")\n",
        "        return {'success': False, 'error': 'No evaluation results available'}\n",
        "\n",
        "    # Create directories for saving visualizations\n",
        "    os.makedirs('evaluation_results/visualizations', exist_ok=True)\n",
        "\n",
        "    # Get evaluation results\n",
        "    evaluation_results = final_evaluation['evaluation_results']\n",
        "    successful_results = {k: v for k, v in evaluation_results.items() if v.get('success')}\n",
        "\n",
        "    # Sort models by RelaImpr (ascending)\n",
        "    sorted_models = sorted(successful_results.keys(),\n",
        "                        key=lambda x: successful_results[x].get('relaimpr', 0.0))\n",
        "\n",
        "    # Extract metrics for visualization\n",
        "    metrics = {\n",
        "        'model_names': sorted_models,\n",
        "        'auc': [successful_results[m]['auc'] for m in sorted_models],\n",
        "        'relaimpr': [successful_results[m].get('relaimpr', 0.0) for m in sorted_models],\n",
        "        'log_loss': [successful_results[m]['log_loss'] for m in sorted_models],\n",
        "        'params': [successful_results[m]['model_params'] for m in sorted_models]\n",
        "    }\n",
        "\n",
        "    # Color palette\n",
        "    colors = {\n",
        "        'primary': '#4287f5',\n",
        "        'secondary': '#f54242',\n",
        "        'tertiary': '#42f59e',\n",
        "        'background': '#f7f9fc',\n",
        "        'grid': '#e0e0e0',\n",
        "        'text': '#333333'\n",
        "    }\n",
        "\n",
        "    # Set plotting style\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    sns.set_context(\"talk\")\n",
        "\n",
        "    # 1. ENHANCED AUC COMPARISON\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    ax = plt.gca()\n",
        "    bars = plt.bar(metrics['model_names'], metrics['auc'], color=colors['primary'], alpha=0.8, width=0.6)\n",
        "\n",
        "    # Add value labels on top of bars\n",
        "    for bar, auc in zip(bars, metrics['auc']):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
        "                f'{auc:.4f}', ha='center', va='bottom', fontweight='bold', color=colors['text'])\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('Model Performance: AUC Comparison', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.ylabel('AUC Score', fontsize=12, labelpad=10)\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.xticks(rotation=15, ha='right')\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/enhanced_auc_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 2. ENHANCED RELAIMPR COMPARISON\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    # Create gradient colors based on RelaImpr values\n",
        "    norm = plt.Normalize(min(metrics['relaimpr']), max(metrics['relaimpr']))\n",
        "    colors_gradient = plt.cm.RdYlGn(norm(metrics['relaimpr']))\n",
        "\n",
        "    bars = plt.bar(metrics['model_names'], metrics['relaimpr'], color=colors_gradient, alpha=0.9, width=0.6)\n",
        "\n",
        "    # Add value labels on top of bars\n",
        "    for bar, relaimpr in zip(bars, metrics['relaimpr']):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5 if relaimpr >= 0 else bar.get_height() - 1.5,\n",
        "                f'{relaimpr:.2f}%', ha='center', va='bottom' if relaimpr >= 0 else 'top',\n",
        "                fontweight='bold', color='black')\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('AUC-Based Relative Improvement (RelaImpr)', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.ylabel('Improvement Over Baseline (%)', fontsize=12, labelpad=10)\n",
        "    plt.axhline(y=0, color='gray', linestyle='--', alpha=0.6)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.xticks(rotation=15, ha='right')\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/enhanced_relaimpr_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 3. ENHANCED LOG LOSS COMPARISON - FIXED VERSION\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    # Lower log loss is better, so we use a different approach:\n",
        "    # 1. Use the correct order in Normalize\n",
        "    norm = plt.Normalize(min(metrics['log_loss']), max(metrics['log_loss']))\n",
        "    # 2. Use a reversed colormap instead\n",
        "    colors_gradient = plt.cm.RdYlGn_r(norm(metrics['log_loss']))\n",
        "\n",
        "    bars = plt.bar(metrics['model_names'], metrics['log_loss'], color=colors_gradient, alpha=0.9, width=0.6)\n",
        "\n",
        "    # Add value labels on top of bars\n",
        "    for bar, loss in zip(bars, metrics['log_loss']):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{loss:.4f}', ha='center', va='bottom', fontweight='bold', color='black')\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('Model Error: Log Loss Comparison', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.ylabel('Log Loss (Lower is Better)', fontsize=12, labelpad=10)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.xticks(rotation=15, ha='right')\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/enhanced_logloss_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 4. MODEL SIZE VS PERFORMANCE\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Create scatter plot with size based on parameters\n",
        "    sizes = np.array(metrics['params']) / 10000  # Scale down for better visualization\n",
        "\n",
        "    scatter = plt.scatter(metrics['auc'], metrics['relaimpr'], s=sizes,\n",
        "                         c=metrics['log_loss'], cmap='coolwarm_r', alpha=0.7)\n",
        "\n",
        "    # Add model names as annotations\n",
        "    for i, model in enumerate(metrics['model_names']):\n",
        "        plt.annotate(model, (metrics['auc'][i], metrics['relaimpr'][i]),\n",
        "                    xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('Model Performance Analysis: AUC vs RelaImpr', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.xlabel('AUC Score', fontsize=12, labelpad=10)\n",
        "    plt.ylabel('RelaImpr (%)', fontsize=12, labelpad=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add colorbar for log loss\n",
        "    cbar = plt.colorbar(scatter)\n",
        "    cbar.set_label('Log Loss (Lower is Better)', rotation=270, labelpad=20)\n",
        "\n",
        "    # Add size legend\n",
        "    sizes_legend = [100000, 150000, 200000]\n",
        "    labels = [f'{s:,} params' for s in sizes_legend]\n",
        "\n",
        "    # Create dummy scatter points for the legend\n",
        "    legend_elements = []\n",
        "    for size, label in zip(sizes_legend, labels):\n",
        "        legend_elements.append(plt.Line2D([0], [0], marker='o', color='w',\n",
        "                              label=label, markerfacecolor='gray',\n",
        "                              markersize=np.sqrt(size/10000)))\n",
        "\n",
        "    plt.legend(handles=legend_elements, title=\"Model Size\", loc=\"upper left\")\n",
        "\n",
        "    # Add reference lines\n",
        "    plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/model_performance_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # 5. COMBINED METRICS RADAR CHART\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Prepare metrics for radar chart\n",
        "    # We need to normalize all metrics to 0-1 scale\n",
        "    model_count = len(metrics['model_names'])\n",
        "    metrics_for_radar = [\n",
        "        'AUC',\n",
        "        'Inv. Log Loss',  # Inverse of log loss so higher is better\n",
        "        'RelaImpr',\n",
        "        'Inv. Model Size'  # Inverse of model size so smaller is better\n",
        "    ]\n",
        "\n",
        "    # Normalize metrics\n",
        "    max_log_loss = max(metrics['log_loss'])\n",
        "    min_log_loss = min(metrics['log_loss'])\n",
        "    max_relaimpr = max(metrics['relaimpr'])\n",
        "    min_relaimpr = min(metrics['relaimpr'])\n",
        "    max_params = max(metrics['params'])\n",
        "    min_params = min(metrics['params'])\n",
        "\n",
        "    # Create radar chart data\n",
        "    radar_data = []\n",
        "    for i, model in enumerate(metrics['model_names']):\n",
        "        # Normalize all values to 0-1 range where 1 is best\n",
        "        auc_norm = metrics['auc'][i]\n",
        "\n",
        "        # For log loss (lower is better), so invert the normalization\n",
        "        log_loss_norm = 1 - ((metrics['log_loss'][i] - min_log_loss) / (max_log_loss - min_log_loss)\n",
        "                             if max_log_loss != min_log_loss else 0)\n",
        "\n",
        "        # For RelaImpr, handle special case where all values might be negative\n",
        "        if max_relaimpr <= 0:\n",
        "            # All negative, so higher (less negative) is better\n",
        "            relaimpr_norm = (metrics['relaimpr'][i] - min_relaimpr) / (max_relaimpr - min_relaimpr) if max_relaimpr != min_relaimpr else 0\n",
        "        else:\n",
        "            # Some positive values exist\n",
        "            if min_relaimpr < 0:\n",
        "                # Map from min_relaimpr to max_relaimpr to 0-1 range\n",
        "                relaimpr_range = max_relaimpr - min_relaimpr\n",
        "                relaimpr_norm = (metrics['relaimpr'][i] - min_relaimpr) / relaimpr_range if relaimpr_range != 0 else 0\n",
        "            else:\n",
        "                # All positive, simply normalize\n",
        "                relaimpr_norm = (metrics['relaimpr'][i] - min_relaimpr) / (max_relaimpr - min_relaimpr) if max_relaimpr != min_relaimpr else 0\n",
        "\n",
        "        # For model size (lower is better), so invert the normalization\n",
        "        params_norm = 1 - ((metrics['params'][i] - min_params) / (max_params - min_params) if max_params != min_params else 0)\n",
        "\n",
        "        radar_data.append([auc_norm, log_loss_norm, relaimpr_norm, params_norm])\n",
        "\n",
        "    # Radar chart angles\n",
        "    angles = np.linspace(0, 2*np.pi, len(metrics_for_radar), endpoint=False).tolist()\n",
        "    angles += angles[:1]  # Close the loop\n",
        "\n",
        "    # Set up radar chart\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "\n",
        "    # Draw radar chart for each model\n",
        "    colormap = plt.cm.get_cmap('tab10', len(metrics['model_names']))\n",
        "\n",
        "    for i, model in enumerate(metrics['model_names']):\n",
        "        values = radar_data[i]\n",
        "        values += values[:1]  # Close the loop\n",
        "        ax.plot(angles, values, linewidth=2, linestyle='solid', label=model, color=colormap(i))\n",
        "        ax.fill(angles, values, alpha=0.1, color=colormap(i))\n",
        "\n",
        "    # Set radar chart labels\n",
        "    ax.set_thetagrids(np.degrees(angles[:-1]), metrics_for_radar)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_rlabel_position(0)\n",
        "    plt.yticks([0.2, 0.4, 0.6, 0.8], [\"0.2\", \"0.4\", \"0.6\", \"0.8\"], color=\"grey\", size=8)\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    # Add styling\n",
        "    plt.title('Model Comparison: Multi-Metric Radar Analysis', fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "\n",
        "    # Add metadata\n",
        "    plt.figtext(0.02, 0.02, f\"Created: {current_timestamp} | User: {current_user}\",\n",
        "               fontsize=8, color='gray')\n",
        "\n",
        "    # Save figure\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results/visualizations/radar_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"âœ… Enhanced visualizations created successfully!\")\n",
        "    print(f\"ðŸ“‚ Saved to: evaluation_results/visualizations/\")\n",
        "    print(f\"ðŸ“Š Visualizations include:\")\n",
        "    print(f\"    - Enhanced AUC comparison\")\n",
        "    print(f\"    - Enhanced RelaImpr comparison\")\n",
        "    print(f\"    - Enhanced Log Loss comparison\")\n",
        "    print(f\"    - Model performance analysis (AUC vs RelaImpr)\")\n",
        "    print(f\"    - Multi-metric radar analysis\")\n",
        "\n",
        "    return {\n",
        "        'success': True,\n",
        "        'visualization_path': 'evaluation_results/visualizations/',\n",
        "        'plots_created': 5\n",
        "    }\n",
        "\n",
        "# Execute enhanced visualizations\n",
        "print(f\"Creating enhanced visualizations for model comparison...\")\n",
        "try:\n",
        "    visualization_results = create_enhanced_visualizations()\n",
        "\n",
        "    if visualization_results['success']:\n",
        "        print(f\"\\nðŸŽ¨ VISUALIZATION COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"ðŸ“ˆ {visualization_results['plots_created']} high-quality plots created\")\n",
        "        print(f\"ðŸ“ Results saved to: {visualization_results['visualization_path']}\")\n",
        "    else:\n",
        "        print(f\"âŒ Visualization failed: {visualization_results.get('error', 'Unknown error')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Visualization error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "eMAyEE-FEi3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c809a5-e221-48cd-e4e1-59c8adaf62e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CELL 9: ENHANCED MODEL VISUALIZATIONS\n",
            "============================================================\n",
            "Creating enhanced visualizations for model comparison...\n",
            "ðŸ“Š Creating enhanced visualizations...\n",
            "âœ… Enhanced visualizations created successfully!\n",
            "ðŸ“‚ Saved to: evaluation_results/visualizations/\n",
            "ðŸ“Š Visualizations include:\n",
            "    - Enhanced AUC comparison\n",
            "    - Enhanced RelaImpr comparison\n",
            "    - Enhanced Log Loss comparison\n",
            "    - Model performance analysis (AUC vs RelaImpr)\n",
            "    - Multi-metric radar analysis\n",
            "\n",
            "ðŸŽ¨ VISUALIZATION COMPLETED SUCCESSFULLY!\n",
            "ðŸ“ˆ 5 high-quality plots created\n",
            "ðŸ“ Results saved to: evaluation_results/visualizations/\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0# =====================================================================\n",
        "# CELL: DIN SCENARIO IMPLEMENTATION (BASELINE, HISTORICAL)\n",
        "# =====================================================================\n",
        "\n",
        "# Impor library yang mungkin belum ada (asumsi)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Asumsi variabel-variabel ini sudah ada dari sel sebelumnya\n",
        "# model_data = ...\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DIN SCENARIO IMPLEMENTATION (BASELINE, HISTORICAL)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Definisikan fungsi untuk membuat model DIN dengan variasi fitur\n",
        "def create_din_model_with_features(features_to_use, best_params=None):\n",
        "    \"\"\"\n",
        "    Membuat model DIN dengan kombinasi fitur yang berbeda.\n",
        "\n",
        "    Args:\n",
        "        features_to_use: List fitur yang digunakan ['user_id', 'item_id', 'sequence']\n",
        "        best_params: Dictionary berisi parameter hasil tuning untuk menimpa default.\n",
        "\n",
        "    Returns:\n",
        "        Model DIN yang telah dikonfigurasi dan parameter yang digunakan.\n",
        "    \"\"\"\n",
        "    # 1. Mulai dengan parameter default.\n",
        "    params = {\n",
        "        'attention_hidden': 16,\n",
        "        'dropout_rate': 0.5,\n",
        "        'l2_reg': 1e-5,\n",
        "        'l2_dense': 1e-5,\n",
        "        'dice_alpha_init': 0.4,\n",
        "        'dice_beta_init': 1.5,\n",
        "        'dice_epsilon': 1e-9,\n",
        "        'learning_rate': 1e-4,\n",
        "        'batch_size': 4096,\n",
        "        'label_smoothing': 0.1,\n",
        "        'hidden_units': [64, 32]\n",
        "    }\n",
        "\n",
        "    # 2. Jika best_params diberikan, timpa default dengan SEMUA nilai dari best_params.\n",
        "    if best_params:\n",
        "        print(\"Menggunakan parameter dari hasil tuning (best_params) untuk menimpa default.\")\n",
        "        params.update(best_params)\n",
        "    else:\n",
        "        print(\"Menggunakan parameter default karena tidak ada best_params yang diberikan.\")\n",
        "\n",
        "    # Parameter Model\n",
        "    n_users = model_data['model_params']['n_users']\n",
        "    n_items = model_data['model_params']['n_items']\n",
        "    embedding_dim = 32\n",
        "    hidden_units = params['hidden_units']\n",
        "    attention_hidden = params['attention_hidden']\n",
        "    max_seq_len = 8\n",
        "    dense_feature_dim = model_data['model_params']['dense_feature_dim']\n",
        "    dropout_rate = params['dropout_rate']\n",
        "    l2_reg = params['l2_reg']\n",
        "    l2_dense = params['l2_dense']\n",
        "\n",
        "    # Parameter untuk aktivasi DICE\n",
        "    dice_params = {\n",
        "        'alpha_init': params['dice_alpha_init'],\n",
        "        'beta_init': params['dice_beta_init'],\n",
        "        'epsilon': params['dice_epsilon']\n",
        "    }\n",
        "\n",
        "    # Definisikan nama model berdasarkan fitur yang digunakan\n",
        "    if set(features_to_use) == set(['user_id', 'item_id']):\n",
        "        model_name = 'din_baseline'\n",
        "        print(f\"Membuat Baseline DIN (Hanya User ID, Item ID)\")\n",
        "    elif set(features_to_use) == set(['user_id', 'item_id', 'sequence']):\n",
        "        model_name = 'din_historical'\n",
        "        print(f\"Membuat Historical DIN (User ID, Item ID, Sequence)\")\n",
        "    else:\n",
        "        model_name = 'din_custom'\n",
        "        print(f\"Membuat Custom DIN dengan fitur: {features_to_use}\")\n",
        "\n",
        "    # Siapkan input layers\n",
        "    inputs = {}\n",
        "    inputs['user_id'] = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='user_id')\n",
        "    inputs['item_id'] = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='item_id')\n",
        "\n",
        "    if 'sequence' in features_to_use:\n",
        "        inputs['sequence'] = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32, name='sequence')\n",
        "        inputs['seq_length'] = tf.keras.layers.Input(shape=(), dtype=tf.int32, name='seq_length')\n",
        "\n",
        "    # EMBEDDING LAYERS\n",
        "    user_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_users, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='user_embedding'\n",
        "    )\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(\n",
        "        n_items, embedding_dim,\n",
        "        embeddings_regularizer=tf.keras.regularizers.l2(l2_reg),\n",
        "        name='item_embedding'\n",
        "    )\n",
        "\n",
        "    user_emb = user_embedding_layer(inputs['user_id'])\n",
        "    target_item_emb = item_embedding_layer(inputs['item_id'])\n",
        "    feature_list = [user_emb, target_item_emb]\n",
        "\n",
        "    if 'sequence' in features_to_use:\n",
        "        sequence_emb = item_embedding_layer(inputs['sequence'])\n",
        "\n",
        "        # Asumsi DINAttention dan SequencePooling sudah didefinisikan di tempat lain\n",
        "        attention_scores, attended_emb = DINAttention(\n",
        "            hidden_units=attention_hidden, max_seq_len=max_seq_len, activation_type='dice',\n",
        "            dice_alpha_init=dice_params['alpha_init'], dice_beta_init=dice_params['beta_init'],\n",
        "            dice_epsilon=dice_params['epsilon'], name='din_attention'\n",
        "        )([sequence_emb, target_item_emb])\n",
        "\n",
        "        pooled_sequence = SequencePooling(name='sequence_pooling')(\n",
        "            [attention_scores, attended_emb, inputs['seq_length']]\n",
        "        )\n",
        "        feature_list.append(pooled_sequence)\n",
        "\n",
        "    all_features = tf.keras.layers.Concatenate(name='feature_concat')(feature_list)\n",
        "    x = all_features\n",
        "    for i, units in enumerate(hidden_units):\n",
        "        x = tf.keras.layers.Dense(\n",
        "            units, name=f'dense_{i+1}',\n",
        "            kernel_regularizer=tf.keras.regularizers.l2(l2_dense)\n",
        "        )(x)\n",
        "        # Asumsi DiceActivation sudah didefinisikan di tempat lain\n",
        "        x = DiceActivation(\n",
        "            name=f'dice_{i+1}', alpha_init=dice_params['alpha_init'],\n",
        "            beta_init=dice_params['beta_init'], epsilon=dice_params['epsilon']\n",
        "        )(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rate, name=f'dropout_{i+1}')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(name=f'bn_{i+1}')(x)\n",
        "\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='output',\n",
        "                                  kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "    model = tf.keras.Model(inputs=list(inputs.values()), outputs=output, name=model_name)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'], clipnorm=0.5)\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=params['label_smoothing'])\n",
        "    metrics = [\n",
        "        tf.keras.metrics.AUC(name='auc'),\n",
        "    ]\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "    print(f\"Model {model_name} berhasil dibuat!\")\n",
        "    print(f\"Total parameter: {model.count_params():,}\")\n",
        "\n",
        "    return model, params\n",
        "\n",
        "# 2. Fungsi untuk melatih model dengan skenario fitur tertentu\n",
        "def train_din_scenario(scenario_name, features_to_use, best_params=None, epochs=15):\n",
        "    \"\"\"\n",
        "    Melatih model DIN dengan skenario fitur spesifik.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TRAINING {scenario_name}\")\n",
        "    print(f\"Fitur: {features_to_use}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    model, params = create_din_model_with_features(features_to_use, best_params)\n",
        "\n",
        "    train_x, val_x, test_x = {}, {}, {}\n",
        "    train_x['user_id'] = model_data['splits']['train']['user_ids']\n",
        "    train_x['item_id'] = model_data['splits']['train']['item_ids']\n",
        "    val_x['user_id'] = model_data['splits']['val']['user_ids']\n",
        "    val_x['item_id'] = model_data['splits']['val']['item_ids']\n",
        "    test_x['user_id'] = model_data['splits']['test']['user_ids']\n",
        "    test_x['item_id'] = model_data['splits']['test']['item_ids']\n",
        "\n",
        "    if 'sequence' in features_to_use:\n",
        "        train_x['sequence'] = model_data['splits']['train']['sequences']\n",
        "        train_x['seq_length'] = model_data['splits']['train']['seq_lengths']\n",
        "        val_x['sequence'] = model_data['splits']['val']['sequences']\n",
        "        val_x['seq_length'] = model_data['splits']['val']['seq_lengths']\n",
        "        test_x['sequence'] = model_data['splits']['test']['sequences']\n",
        "        test_x['seq_length'] = model_data['splits']['test']['seq_lengths']\n",
        "\n",
        "    train_y = model_data['splits']['train']['labels']\n",
        "    val_y = model_data['splits']['val']['labels']\n",
        "    test_y = model_data['splits']['test']['labels']\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True, mode='max'),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, min_lr=1e-6, mode='max')\n",
        "    ]\n",
        "\n",
        "    os.makedirs(f'results/{scenario_name}', exist_ok=True)\n",
        "    checkpoint_path = f'results/{scenario_name}/model_checkpoint.weights.h5'\n",
        "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_auc', mode='max', save_best_only=True, save_weights_only=True)\n",
        "    callbacks.append(model_checkpoint)\n",
        "\n",
        "    csv_path = f'results/{scenario_name}/training_history.csv'\n",
        "    csv_logger = tf.keras.callbacks.CSVLogger(csv_path)\n",
        "    callbacks.append(csv_logger)\n",
        "\n",
        "    batch_size = params['batch_size']\n",
        "    print(f\"\\nMemulai training untuk {scenario_name}...\")\n",
        "    print(f\"Training dengan parameter: {json.dumps(params, indent=4)}\")\n",
        "\n",
        "    history = model.fit(\n",
        "        x=train_x, y=train_y,\n",
        "        validation_data=(val_x, val_y),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(f\"\\nEvaluasi {scenario_name} pada test set...\")\n",
        "    test_results = model.evaluate(test_x, test_y, verbose=1)\n",
        "    test_metrics = {\n",
        "        'test_loss': test_results[0], 'test_auc': test_results[1],\n",
        "    }\n",
        "\n",
        "    test_preds = model.predict(test_x, batch_size=batch_size)\n",
        "    test_metrics['test_logloss'] = log_loss(test_y, test_preds)\n",
        "\n",
        "    metrics_path = f'results/{scenario_name}/test_metrics.json'\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        json.dump(test_metrics, f, indent=4)\n",
        "\n",
        "    print(f\"\\nMetrik tes untuk {scenario_name}:\")\n",
        "    for metric, value in test_metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "    return model, history, test_metrics\n",
        "\n",
        "# 3. Jalankan eksperimen untuk setiap skenario\n",
        "# Gunakan parameter terbaik dari hasil tuning yang Anda berikan\n",
        "din_best_params = {\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"batch_size\": 4096,\n",
        "    \"dropout_rate\": 0.4,\n",
        "    \"l2_reg\": 1e-05,\n",
        "    \"l2_dense\": 0.0001,\n",
        "    \"dice_alpha_init\": 0.35,\n",
        "    \"dice_beta_init\": 1.0,\n",
        "    \"dice_epsilon\": 1e-09,\n",
        "    \"attention_hidden\": 16,\n",
        "    \"label_smoothing\": 0.15,\n",
        "    \"hidden_units\": [128, 64]\n",
        "}\n",
        "\n",
        "# 3.1 Baseline DIN\n",
        "baseline_model, baseline_history, baseline_metrics = train_din_scenario(\n",
        "    scenario_name=\"baseline_din\",\n",
        "    features_to_use=['user_id', 'item_id'],\n",
        "    best_params=din_best_params,\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "# 3.2 Historical DIN\n",
        "historical_model, historical_history, historical_metrics = train_din_scenario(\n",
        "    scenario_name=\"historical_din\",\n",
        "    features_to_use=['user_id', 'item_id', 'sequence'],\n",
        "    best_params=din_best_params,\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "# 4. Visualisasikan dan analisis hasil (kode ini tetap sama seperti sebelumnya)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HASIL PERBANDINGAN SKENARIO DIN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "scenarios = ['Baseline DIN', 'Historical DIN']\n",
        "test_aucs = [baseline_metrics['test_auc'], historical_metrics['test_auc']]\n",
        "test_loglosses = [baseline_metrics['test_logloss'], historical_metrics['test_logloss']]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(scenarios, test_aucs, color=['lightblue', 'lightgreen'])\n",
        "plt.ylabel('Test AUC')\n",
        "plt.title('Perbandingan AUC antar Skenario DIN')\n",
        "plt.ylim(bottom=max(0, min(test_aucs) - 0.05), top=min(1.0, max(test_aucs) + 0.05))\n",
        "for i, v in enumerate(test_aucs):\n",
        "    plt.text(i, v + 0.002, f'{v:.4f}', ha='center')\n",
        "plt.tight_layout()\n",
        "plt.savefig('results/din_scenarios_auc_comparison.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "results_summary = pd.DataFrame({\n",
        "    'Scenario': scenarios,\n",
        "    'Test AUC': test_aucs,\n",
        "    'Test Log Loss': test_loglosses,\n",
        "})\n",
        "\n",
        "print(\"\\nPerbandingan Metrik antar Skenario:\")\n",
        "print(results_summary.to_string(index=False))\n",
        "results_summary.to_csv('results/din_scenarios_comparison.csv', index=False)\n",
        "print(\"\\nHasil perbandingan disimpan di: results/din_scenarios_comparison.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EKSPERIMEN SKENARIO DIN SELESAI\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "6CZK3WF8ILW_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b271032-08ee-4758-ca7c-a47a4351b922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DIN SCENARIO IMPLEMENTATION (BASELINE, HISTORICAL)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TRAINING baseline_din\n",
            "Fitur: ['user_id', 'item_id']\n",
            "============================================================\n",
            "Menggunakan parameter dari hasil tuning (best_params) untuk menimpa default.\n",
            "Membuat Baseline DIN (Hanya User ID, Item ID)\n",
            "Model din_baseline berhasil dibuat!\n",
            "Total parameter: 63,651,137\n",
            "\n",
            "Memulai training untuk baseline_din...\n",
            "Training dengan parameter: {\n",
            "    \"attention_hidden\": 16,\n",
            "    \"dropout_rate\": 0.4,\n",
            "    \"l2_reg\": 1e-05,\n",
            "    \"l2_dense\": 0.0001,\n",
            "    \"dice_alpha_init\": 0.35,\n",
            "    \"dice_beta_init\": 1.0,\n",
            "    \"dice_epsilon\": 1e-09,\n",
            "    \"learning_rate\": 0.0001,\n",
            "    \"batch_size\": 4096,\n",
            "    \"label_smoothing\": 0.15,\n",
            "    \"hidden_units\": [\n",
            "        128,\n",
            "        64\n",
            "    ]\n",
            "}\n",
            "Epoch 1/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 17ms/step - auc: 0.5022 - loss: 0.7156 - val_auc: 0.5719 - val_loss: 0.4026 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 16ms/step - auc: 0.5308 - loss: 0.3973 - val_auc: 0.6443 - val_loss: 0.3713 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 16ms/step - auc: 0.6491 - loss: 0.3693 - val_auc: 0.6529 - val_loss: 0.3652 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 16ms/step - auc: 0.6821 - loss: 0.3638 - val_auc: 0.6527 - val_loss: 0.3657 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 16ms/step - auc: 0.7031 - loss: 0.3626 - val_auc: 0.6335 - val_loss: 0.3703 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 16ms/step - auc: 0.7623 - loss: 0.3574 - val_auc: 0.5977 - val_loss: 0.3779 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 16ms/step - auc: 0.8242 - loss: 0.3474 - val_auc: 0.5489 - val_loss: 0.3848 - learning_rate: 5.0000e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 16ms/step - auc: 0.8321 - loss: 0.3442 - val_auc: 0.5426 - val_loss: 0.3889 - learning_rate: 5.0000e-05\n",
            "\n",
            "Evaluasi baseline_din pada test set...\n",
            "\u001b[1m82994/82994\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 3ms/step - auc: 0.6526 - loss: 0.3660\n",
            "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\n",
            "Metrik tes untuk baseline_din:\n",
            "  test_loss: 0.3659\n",
            "  test_auc: 0.6523\n",
            "  test_logloss: 0.2276\n",
            "\n",
            "============================================================\n",
            "TRAINING historical_din\n",
            "Fitur: ['user_id', 'item_id', 'sequence']\n",
            "============================================================\n",
            "Menggunakan parameter dari hasil tuning (best_params) untuk menimpa default.\n",
            "Membuat Historical DIN (User ID, Item ID, Sequence)\n",
            "Model din_historical berhasil dibuat!\n",
            "Total parameter: 63,657,570\n",
            "\n",
            "Memulai training untuk historical_din...\n",
            "Training dengan parameter: {\n",
            "    \"attention_hidden\": 16,\n",
            "    \"dropout_rate\": 0.4,\n",
            "    \"l2_reg\": 1e-05,\n",
            "    \"l2_dense\": 0.0001,\n",
            "    \"dice_alpha_init\": 0.35,\n",
            "    \"dice_beta_init\": 1.0,\n",
            "    \"dice_epsilon\": 1e-09,\n",
            "    \"learning_rate\": 0.0001,\n",
            "    \"batch_size\": 4096,\n",
            "    \"label_smoothing\": 0.15,\n",
            "    \"hidden_units\": [\n",
            "        128,\n",
            "        64\n",
            "    ]\n",
            "}\n",
            "Epoch 1/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 22ms/step - auc: 0.5023 - loss: 0.7359 - val_auc: 0.5697 - val_loss: 0.4063 - learning_rate: 1.0000e-04\n",
            "Epoch 2/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 20ms/step - auc: 0.5296 - loss: 0.3994 - val_auc: 0.6434 - val_loss: 0.3715 - learning_rate: 1.0000e-04\n",
            "Epoch 3/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 20ms/step - auc: 0.6472 - loss: 0.3695 - val_auc: 0.6532 - val_loss: 0.3652 - learning_rate: 1.0000e-04\n",
            "Epoch 4/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 20ms/step - auc: 0.6810 - loss: 0.3640 - val_auc: 0.6538 - val_loss: 0.3658 - learning_rate: 1.0000e-04\n",
            "Epoch 5/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 20ms/step - auc: 0.7052 - loss: 0.3628 - val_auc: 0.6338 - val_loss: 0.3706 - learning_rate: 1.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 19ms/step - auc: 0.7669 - loss: 0.3580 - val_auc: 0.5591 - val_loss: 0.3841 - learning_rate: 1.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 19ms/step - auc: 0.8450 - loss: 0.3450 - val_auc: 0.5350 - val_loss: 0.3911 - learning_rate: 1.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 19ms/step - auc: 0.8479 - loss: 0.3447 - val_auc: 0.5248 - val_loss: 0.3937 - learning_rate: 5.0000e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m5188/5188\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 19ms/step - auc: 0.8585 - loss: 0.3411 - val_auc: 0.5188 - val_loss: 0.3989 - learning_rate: 5.0000e-05\n",
            "\n",
            "Evaluasi historical_din pada test set...\n",
            "\u001b[1m82994/82994\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 3ms/step - auc: 0.6533 - loss: 0.3665\n",
            "\u001b[1m649/649\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
            "\n",
            "Metrik tes untuk historical_din:\n",
            "  test_loss: 0.3664\n",
            "  test_auc: 0.6533\n",
            "  test_logloss: 0.2259\n",
            "\n",
            "============================================================\n",
            "HASIL PERBANDINGAN SKENARIO DIN\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perbandingan Metrik antar Skenario:\n",
            "      Scenario  Test AUC  Test Log Loss\n",
            "  Baseline DIN  0.652334       0.227606\n",
            "Historical DIN  0.653310       0.225878\n",
            "\n",
            "Hasil perbandingan disimpan di: results/din_scenarios_comparison.csv\n",
            "\n",
            "============================================================\n",
            "EKSPERIMEN SKENARIO DIN SELESAI\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k6HC2kfKX26p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}