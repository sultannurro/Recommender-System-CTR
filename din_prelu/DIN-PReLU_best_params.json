{
    "learning_rate": 0.0001,
    "batch_size": 2048,
    "dropout_rate": 0.3,
    "l2_reg": 5e-05,
    "l2_dense": 5e-05,
    "prelu_alpha_init": 0.35,
    "attention_hidden": 8,
    "label_smoothing": 0.15,
    "hidden_units": [
        128,
        64
    ]
}